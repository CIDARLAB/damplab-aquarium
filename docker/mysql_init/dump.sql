-- MySQL dump 10.13  Distrib 5.7.22, for Linux (x86_64)
--
-- Host: localhost    Database: development
-- ------------------------------------------------------
-- Server version	5.7.22

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `account_logs`
--

DROP TABLE IF EXISTS `account_logs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `account_logs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `row1` int(11) DEFAULT NULL,
  `row2` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `note` text,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_account_log_associations_on_user_id` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `account_logs`
--

LOCK TABLES `account_logs` WRITE;
/*!40000 ALTER TABLE `account_logs` DISABLE KEYS */;
/*!40000 ALTER TABLE `account_logs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `accounts`
--

DROP TABLE IF EXISTS `accounts`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `accounts` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `transaction_type` varchar(255) DEFAULT NULL,
  `amount` float DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `category` varchar(255) DEFAULT NULL,
  `job_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text,
  `labor_rate` float DEFAULT NULL,
  `markup_rate` float DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_accounts_on_user_id` (`user_id`),
  KEY `index_accounts_on_budget_id` (`budget_id`),
  KEY `index_accounts_on_job_id` (`job_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `accounts`
--

LOCK TABLES `accounts` WRITE;
/*!40000 ALTER TABLE `accounts` DISABLE KEYS */;
/*!40000 ALTER TABLE `accounts` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `allowable_field_types`
--

DROP TABLE IF EXISTS `allowable_field_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `allowable_field_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `field_type_id` int(11) DEFAULT NULL,
  `sample_type_id` int(11) DEFAULT NULL,
  `object_type_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_allowable_field_types_on_field_type_id` (`field_type_id`),
  KEY `index_allowable_field_types_on_sample_type_id` (`sample_type_id`),
  KEY `index_allowable_field_types_on_object_type_id` (`object_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=72 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `allowable_field_types`
--

LOCK TABLES `allowable_field_types` WRITE;
/*!40000 ALTER TABLE `allowable_field_types` DISABLE KEYS */;
INSERT INTO `allowable_field_types` VALUES (1,9,1,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(2,12,2,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(3,12,4,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(4,12,3,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(5,12,5,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(6,13,1,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(7,14,1,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(8,17,4,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(9,18,5,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(10,19,2,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(11,19,3,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(12,20,2,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(13,21,NULL,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(14,24,1,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(15,25,1,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(16,29,1,1,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(17,30,1,1,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(18,31,2,2,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(19,31,3,3,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(20,31,2,4,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(21,31,2,5,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(22,31,3,6,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(23,32,3,7,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(24,34,3,8,'2018-07-17 20:29:32','2018-07-17 20:29:32'),(25,35,3,7,'2018-07-17 20:29:32','2018-07-17 20:29:32'),(26,37,3,8,'2018-07-17 20:29:38','2018-07-17 20:29:38'),(27,38,3,9,'2018-07-17 20:29:38','2018-07-17 20:29:38'),(28,39,3,9,'2018-07-17 20:29:44','2018-07-17 20:29:44'),(29,40,3,3,'2018-07-17 20:29:44','2018-07-17 20:29:44'),(30,41,3,3,'2018-07-17 20:29:57','2018-07-17 20:29:57'),(31,42,2,10,'2018-07-17 20:29:57','2018-07-17 20:29:57'),(32,43,2,10,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(33,43,2,11,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(34,43,2,5,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(35,43,2,2,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(36,44,2,12,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(37,45,4,13,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(38,46,2,12,'2018-07-17 20:30:21','2018-07-17 20:30:21'),(39,47,2,14,'2018-07-17 20:30:21','2018-07-17 20:30:21'),(40,48,2,14,'2018-07-17 20:30:28','2018-07-17 20:30:28'),(41,49,2,15,'2018-07-17 20:30:28','2018-07-17 20:30:28'),(42,50,2,15,'2018-07-17 20:30:42','2018-07-17 20:30:42'),(43,50,2,16,'2018-07-17 20:30:42','2018-07-17 20:30:42'),(44,51,2,17,'2018-07-17 20:30:42','2018-07-17 20:30:42'),(45,52,2,17,'2018-07-17 20:30:50','2018-07-17 20:30:50'),(46,53,2,2,'2018-07-17 20:30:50','2018-07-17 20:30:50'),(47,54,2,2,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(48,54,3,3,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(49,55,1,1,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(50,56,2,18,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(51,56,3,18,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(52,57,2,18,'2018-07-17 20:31:08','2018-07-17 20:31:08'),(53,58,2,2,'2018-07-17 20:31:17','2018-07-17 20:31:17'),(54,59,2,15,'2018-07-17 20:31:17','2018-07-17 20:31:17'),(55,60,2,17,'2018-07-17 20:31:24','2018-07-17 20:31:24'),(56,61,2,16,'2018-07-17 20:31:24','2018-07-17 20:31:24'),(57,63,3,19,'2018-07-17 20:31:36','2018-07-17 20:31:36'),(58,65,1,20,'2018-07-17 20:31:41','2018-07-17 20:31:41'),(59,33,NULL,8,'2018-07-17 22:55:34','2018-07-17 22:55:34'),(60,36,NULL,8,'2018-07-17 23:06:59','2018-07-17 23:06:59'),(61,70,7,25,'2018-07-18 22:24:59','2018-07-18 22:24:59'),(62,71,7,26,'2018-07-18 22:24:59','2018-07-18 22:24:59'),(63,72,4,29,'2018-07-18 23:22:06','2018-07-18 23:22:06'),(64,73,4,30,'2018-07-18 23:22:06','2018-07-18 23:22:06'),(65,74,7,31,'2018-07-18 23:22:06','2018-07-18 23:22:06'),(66,75,7,32,'2018-07-18 23:23:13','2018-07-18 23:23:13'),(67,76,7,33,'2018-07-18 23:23:13','2018-07-18 23:23:13'),(68,77,4,30,'2018-07-18 23:23:21','2018-07-18 23:23:21'),(69,78,7,32,'2018-07-18 23:23:21','2018-07-18 23:23:21'),(70,79,4,13,'2018-07-18 23:23:21','2018-07-18 23:23:21'),(71,80,7,33,'2018-07-18 23:23:21','2018-07-18 23:23:21');
/*!40000 ALTER TABLE `allowable_field_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `announcements`
--

DROP TABLE IF EXISTS `announcements`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `announcements` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(255) DEFAULT NULL,
  `message` text,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `announcements`
--

LOCK TABLES `announcements` WRITE;
/*!40000 ALTER TABLE `announcements` DISABLE KEYS */;
INSERT INTO `announcements` VALUES (1,'Welcome to Aquarium','This Aquarium instance comes pre-loaded with all the Operation Types, Sample Types, and Object Types necessary for a basic cloning workflow.\r\n<br>\r\nTo learn how to use Aquarium effectively, visit the <a href=\"http://klavinslab.org/aquarium/\">Aquarium Documentation</a>.',1,'2018-07-17 20:17:49','2018-07-19 19:55:16');
/*!40000 ALTER TABLE `announcements` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `budgets`
--

DROP TABLE IF EXISTS `budgets`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `budgets` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `overhead` float DEFAULT NULL,
  `contact` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text,
  `email` varchar(255) DEFAULT NULL,
  `phone` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `budgets`
--

LOCK TABLES `budgets` WRITE;
/*!40000 ALTER TABLE `budgets` DISABLE KEYS */;
INSERT INTO `budgets` VALUES (1,'My First Budget',NULL,'Joe','2018-07-17 22:10:05','2018-07-17 22:10:05','An example budget','joe@nasa.org','8675309');
/*!40000 ALTER TABLE `budgets` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `codes`
--

DROP TABLE IF EXISTS `codes`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `codes` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `content` text,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=204 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `codes`
--

LOCK TABLES `codes` WRITE;
/*!40000 ALTER TABLE `codes` DISABLE KEYS */;
INSERT INTO `codes` VALUES (77,'protocol','class Protocol\r\n  \r\n  # io\r\n  CELLS = \"Comp Cells\"\r\n  INPUT = \"Plasmid\"\r\n  OUTPUT = \"Transformed E Coli\"\r\n  \r\n  # debug\r\n  DEBUG_WITH_REPLACEMENT = true\r\n  \r\n  # specs\r\n  RESUSPENSION_VOL = 900 # how much to resuspend transformed cells in\r\n    \r\n  def main\r\n    # Detract comp cells from batches, store how many of each type of comp cell there are, and figure out how many Amp vs Kan plates will be needed \r\n    \r\n    # Determine replacements of e coli comp cell batch\r\n    determine_replacements\r\n\r\n    # Detract from running batches\r\n    operations.running.each { |op| op.input(CELLS).collection.remove_one op.input(CELLS).sample }\r\n\r\n    # Exit early if there are no more running operations\r\n    if operations.empty?\r\n      show do\r\n        title \"All operations have errored\"\r\n        note \"All operations have errored out.\"\r\n      end\r\n      return {}\r\n    end\r\n  \r\n    # Make \r\n    operations.running.retrieve(only: [\"Plasmid\"]).make\r\n   \r\n    # Prepare electroporator \r\n    prepare_electroporator\r\n      \r\n    # Measure plasmid stock concentrations\r\n    ops_for_dilution = operations.running.select { |op| op.input(INPUT).object_type.name == \"Plasmid Stock\" }\r\n    ops_for_measurement = ops_for_dilution.select { |op| op.input(INPUT).item.get(:concentration).to_f == 0.0 }\r\n    measure_plasmid_stock ops_for_measurement\r\n\r\n    # Dilute plasmid stocks\r\n    dilute_plasmid_stocks ops_for_dilution\r\n  \r\n    # Get comp cells and cuvettes \r\n    get_cold_items  \r\n      \r\n    # Label aliquots\r\n    label_aliquots  \r\n      \r\n    index = 0\r\n  \r\n    # Display table to tech\r\n    display_table index\r\n      \r\n    #plate pre heating\r\n    plate_preheating  \r\n    \r\n    # Incubate transformants\r\n    incubate_transformants \r\n\r\n    # Clean up\r\n    clean_up\r\n      \r\n    # Move items\r\n      operations.running.each do |op|\r\n        op.output(OUTPUT).item.move \"37C shaker\"\r\n      end\r\n      \r\n    # Store dna stocks\r\n      all_stocks = operations.running.map { |op| [op.input(INPUT).item, op.temporary[:old_stock]] }.flatten.uniq\r\n      all_stocks.compact!\r\n      release all_stocks, interactive: true, method: \"boxes\"\r\n      \r\n    return {}\r\n  end\r\n  \r\n  def prepare_electroporator\r\n    show do\r\n      title \"Prepare bench\"\r\n      note \"If the electroporator is off (no numbers displayed), turn it on using the ON/STDBY button.\"\r\n      note \"Set the voltage to 1250V by clicking the up and down buttons.\"\r\n      note \" Click the time constant button to show 0.0.\"\r\n      image \"Actions/Transformation/initialize_electroporator.jpg\"\r\n      check \"Retrieve and label #{operations.running.length} 1.5 mL tubes with the following ids: #{operations.running.collect { |op| \"#{op.output(OUTPUT).item.id}\"}.join(\",\")} \"\r\n      check \"Set your 3 pipettors to be 2 uL, 42 uL, and 900 uL.\"\r\n      check \"Prepare 10 uL, 100 uL, and 1000 uL pipette tips.\"      \r\n      check \"Grab a Bench SOC liquid aliquot (sterile) and loosen the cap.\"\r\n    end\r\n  end\r\n  \r\n  def measure_plasmid_stock ops_for_measurement\r\n    if ops_for_measurement.any?\r\n      conc_table = Proc.new { |ops|\r\n        ops.start_table\r\n          .input_item(INPUT)\r\n          .custom_input(:concentration, heading: \"Concentration (ng/ul)\", type: \"number\") { |op| \r\n            x = op.temporary[:concentration] || -1\r\n            x = rand(10..100) if debug\r\n            x\r\n          }\r\n          .validate(:concentration) { |op, v| v.between?(0,10000) }\r\n          .validation_message(:concentration) { |op, k, v| \"Concentration must be non-zero!\" }\r\n          .end_table.all\r\n      }\r\n      \r\n      show_with_input_table(ops_for_measurement, conc_table) do\r\n        title \"Measure concentrations\"\r\n        note \"The concentrations of some plasmid stocks are unknown.\"\r\n        check \"Go to the nanodrop and measure the concentrations for the following items.\"\r\n        check \"Write the concentration on the side of each tube\"\r\n      end\r\n      \r\n      ops_for_measurement.each do |op|\r\n        op.input(INPUT).item.associate :concentration, op.temporary[:concentration]\r\n      end\r\n    end\r\n  end\r\n  \r\n  def get_cold_items  \r\n    show do \r\n      title \"Get cold items\"\r\n      note \"Retrieve a styrofoam ice block and an aluminum tube rack. Put the aluminum tube rack on top of the ice block.\"\r\n      image \"arrange_cold_block\"\r\n      check \"Retrieve #{operations.length} cuvettes and put inside the styrofoam touching ice block.\"\r\n      note \"Retrieve the following electrocompetent aliquots from the M80 and place them on an aluminum tube rack: \"\r\n      operations.group_by { |op| op.input(CELLS).item }.each do |batch, grouped_ops|\r\n        check \"#{grouped_ops.size} aliquot(s) of #{grouped_ops.first.input(CELLS).sample.name} from batch #{batch.id}\"\r\n      end\r\n      image \"Actions/Transformation/handle_electrocompetent_cells.jpg\"\r\n    end\r\n  end\r\n  \r\n  def label_aliquots  \r\n    show do \r\n      title \"Label aliquots\"\r\n      aliquotsLabeled = 0\r\n      operations.group_by { |op| op.input(CELLS).item }.each do |batch, grouped_ops|\r\n        if grouped_ops.size == 1\r\n          check \"Label the electrocompetent aliquot of #{grouped_ops.first.input(CELLS).sample.name} as #{aliquotsLabeled + 1}.\"\r\n        else\r\n          check \"Label each electrocompetent aliquot of #{grouped_ops.first.input(CELLS).sample.name} from #{aliquotsLabeled + 1}-#{grouped_ops.size + aliquotsLabeled}.\"\r\n        end\r\n        aliquotsLabeled += grouped_ops.size\r\n      end\r\n      note \"If still frozen, wait till the cells have thawed to a slushy consistency.\"\r\n      warning \"Transformation efficiency depends on keeping electrocompetent cells ice-cold until electroporation.\"\r\n      warning \"Do not wait too long\"\r\n      image \"Actions/Transformation/thawed_electrocompotent_cells.jpg\"\r\n    end\r\n  end\r\n  \r\n  def display_table index\r\n    show do\r\n      title \"Add plasmid to electrocompetent aliquot, electroporate and rescue \"\r\n      note \"Repeat for each row in the table:\"\r\n      check \"Pipette 2 uL plasmid/gibson result into labeled electrocompetent aliquot, swirl the tip to mix and place back on the aluminum rack after mixing.\"\r\n      check \"Transfer 42 uL of e-comp cells to electrocuvette with P100\"\r\n      check \"Slide into electroporator, press PULSE button twice, and QUICKLY add #{RESUSPENSION_VOL} uL of SOC\"\r\n      check \"pipette cells up and down 3 times, then transfer #{RESUSPENSION_VOL} uL to appropriate 1.5 mL tube with P1000\"\r\n      table operations.running.start_table \r\n        .input_item(\"Plasmid\")\r\n        .custom_column(heading: \"Electrocompetent Aliquot\") { index = index + 1 }\r\n        .output_item(\"Transformed E Coli\", checkable: true)\r\n        .end_table\r\n    end\r\n  end\r\n  \r\n  def incubate_transformants \r\n    show do \r\n      title \"Incubate transformants\"\r\n      check \"Grab a glass flask\"\r\n      check \"Place E. coli transformants inside flask laying sideways and place flask into shaking 37 C incubator.\"\r\n      #Open google timer in new window\r\n      note \"Transformants with an AMP marker should incubate for only 30 minutes. Transformants with a KAN, SPEC, or CHLOR marker needs to incubate for 60 minutes.\"\r\n      note \"<a href=\\\'https://www.google.com/search?q=30%20minute%20timer\\\' target=\\\'_blank\\\'>Use a 30 minute Google timer</a> or <a href=\\\'https://www.google.com/search?q=60%20minute%20timer\\\' target=\\\'_blank\\\'>a 60 minute Google timer</a> to set a reminder to retrieve the transformants, at which point you will start the \\\'Plate Transformed Cells\\\' protocol.\"\r\n      image \"Actions/Transformation/37_c_shaker_incubator.jpg\"\r\n      note \"While the transformants incubate, finish this protocol by completing the remaining tasks.\"\r\n    end\r\n  end\r\n  \r\n  def plate_preheating  \r\n    show do \r\n      title \"Pre-heat plates\"\r\n      note \"Retrieve the following plates, and place into still 37C incubator.\"    \r\n      grouped_by_marker = operations.running.group_by { |op|\r\n        op.input(INPUT).sample.properties[\"Bacterial Marker\"].upcase\r\n      }\r\n      grouped_by_marker.each do |marker, ops|\r\n        check \"#{ops.size} LB + #{marker} plates\"\r\n      end\r\n      image \"Actions/Plating/put_plate_incubator.JPG\"\r\n    end\r\n  end\r\n  \r\n  def clean_up\r\n    show do\r\n      title \"Clean up\"\r\n      check \"Put all cuvettes into biohazardous waste.\"\r\n      check \"Discard empty electrocompetent aliquot tubes into waste bin.\"\r\n      check \"Return the styrofoam ice block and the aluminum tube rack.\"\r\n      image \"Actions/Transformation/dump_dirty_cuvettes.jpg\"\r\n    end\r\n  end\r\n  \r\n  def determine_replacements\r\n    operations.running.each do |op|\r\n      # If current batch is empty\r\n      if op.input(CELLS).collection.empty? || (debug and DEBUG_WITH_REPLACEMENT)\r\n        old_batch = op.input(CELLS).collection\r\n        \r\n        # Find replacement batches\r\n        all_batches = Collection.where(object_type_id: old_batch.object_type.id).select { |b| !b.empty? && !b.deleted? && (b.matrix[0].include? op.input(CELLS).sample.id) }\r\n        # batches_of_cells = all_batches.select { |b| b.include? op.input(CELLS).sample && !b.deleted? }.sort { |x| x.num_samples }\r\n        batches_of_cells = all_batches.reject { |b| b == old_batch }.sort { |x| x.num_samples } # debug specific rejection to force replacement\r\n        \r\n        # Error if not enough\r\n        if batches_of_cells.empty?\r\n          op.error :not_enough_comp_cells, \"There were not enough comp cells of #{op.input(CELLS).sample.name} to complete the operation.\"\r\n        else\r\n          # Set input to new batch\r\n          \r\n          op.input(CELLS).set collection: batches_of_cells.last\r\n          # Display warning\r\n          op.associate :comp_cell_batch_replaced, \"There were not enough comp cells for this operation. Replaced batch #{old_batch.id} with batch #{op.input(CELLS).collection.id}\"\r\n        end\r\n      end\r\n    end\r\n  end\r\n  \r\n  def dilute_plasmid_stocks ops_for_dilution\r\n    if ops_for_dilution.any?\r\n      show do\r\n        title \"Prepare plasmid stocks\"\r\n        \r\n        ops_for_dilution.each do |op|\r\n          i = produce new_sample op.input(INPUT).sample.name, of: op.input(INPUT).sample_type, as: \"1 ng/L Plasmid Stock\"\r\n          \r\n          op.temporary[:old_stock] = op.input(INPUT).item\r\n          op.input(INPUT).item.associate :from, op.temporary[:old_stock].id\r\n          vol = 0.5\r\n          c = op.temporary[:old_stock].get(:concentration).to_f\r\n          op.temporary[:water_vol] = (vol * c).round(1)\r\n          op.temporary[:vol] = vol\r\n          op.input(INPUT).set item: i\r\n          op.associate :plasmid_stock_diluted, \"Plasmid stock #{op.temporary[:old_stock].id} was diluted and a 1 ng/ul Plasmid Stock was created: #{op.input(INPUT).item.id}\"\r\n        end\r\n        \r\n        check \"Grab <b>#{ops_for_dilution.size}</b> 1.5 mL tubes and place in rack\"\r\n        note \"According to the table below:\"\r\n        check \"Label all tubes with the corresponding Tube id\"\r\n        check \"Pipette MG H20\"\r\n        check \"Pipette DNA\"\r\n        table ops_for_dilution.start_table\r\n          .input_item(INPUT, heading: \"Tube id\", checkable: true)\r\n          .custom_column(heading: \"MG H20\", checkable: true) { |op| \"#{op.temporary[:water_vol]} ul\" }\r\n          .custom_column(heading: \"Plasmid Stock (ul)\", checkable: true) { |op| \"#{op.temporary[:vol]} ul of #{op.temporary[:old_stock].id}\" }\r\n          .end_table\r\n      end\r\n      \r\n      show do\r\n        title \"Set aside old plasmid stocks\"\r\n        \r\n        note \"The following plasmid stocks will no longer be needed for this protocol.\"\r\n        check \"Set aside the old plasmid stocks:\"\r\n        ops_for_dilution.each do |op|\r\n          check \"#{op.temporary[:old_stock]}\"\r\n        end\r\n      end\r\n    end\r\n  end\r\nend ',7,'OperationType','2018-07-17 20:59:34','2018-07-17 20:59:34',1),(102,'protocol','class Protocol\n\n  def main\n    # Take plates  \n    operations.retrieve\n    \n    # Count the number of colonies\n    info = get_colony_numbers\n    \n    # Update plate data\n    update_item_data info\n    \n    # Delete and discard any plates that have 0 colonies\n    discard_bad_plates if operations.any? { |op| op.temporary[:delete] }\n    \n    # Parafilm and label plates \n    parafilm_plates\n    \n    # Return plates\n    operations.store\n    \n    return {}\n  end\n  \n  \n  # Count the number of colonies and select whether the growth is normal, contaminated, or a lawn\n  def get_colony_numbers\n    show do\n      title \"Estimate colony numbers\"\n      \n      operations.each do |op|\n        plate = op.input(\"Plate\").item\n        get \"number\", var: \"n#{plate.id}\", label: \"Estimate how many colonies are on #{plate}\", default: 5\n        select [\"normal\", \"contamination\", \"lawn\"], var: \"s#{plate}\", label: \"Choose whether there is contamination, a lawn, or whether it\'s normal.\"\n      end\n    end    \n  end\n  \n  # Alter data of the virtual item to represent its actual state\n  def update_item_data info\n    operations.each do |op|\n      plate = op.input(\"Plate\").item\n      if info[\"n#{plate.id}\".to_sym] == 0\n        plate.mark_as_deleted\n        plate.save\n        op.temporary[:delete] = true\n        op.error :no_colonies, \"There are no colonies for plate #{plate.id}\"\n      else\n        plate.associate :num_colonies, info[\"n#{plate.id}\".to_sym]\n        plate.associate :status, info[\"s#{plate.id}\".to_sym]\n        \n        checked_ot = ObjectType.find_by_name(\"Checked E coli Plate of Plasmid\")\n        plate.store if plate.object_type_id != checked_ot.id\n        plate.object_type_id = checked_ot.id\n        plate.save\n        op.output(\"Plate\").set item: plate\n        \n        op.plan.associate \"plate_#{op.input(\"Plate\").sample.id}\", plate.id\n      end\n    end\n  end\n  \n  # discard any plates that have 0 colonies\n  def discard_bad_plates\n      show do \n        title \"Discard Plates\"\n        \n        discard_plate_ids = operations.select { |op| op.temporary[:delete] }.map { |op| op.input(\"Plate\").item.id }\n        note \"Discard the following plates with 0 colonies: #{discard_plate_ids}\"\n      end\n  end\n  \n  # Parafilm and label any plates that have suitable growth\n  def parafilm_plates\n    show do \n      title \"Label and Parafilm\"\n      \n      plates_to_parafilm = operations.reject { |op| op.temporary[:delete] }.map { |op| op.input(\"Plate\").item.id }\n      note \"Perform the steps with the following plates: #{plates_to_parafilm}\"\n      note \"Label the plates with their item ID numbers on the side, and parafilm each one.\"\n      note \"Labelling the plates on the side makes it easier to retrieve them from the fridge.\"\n    end\n  end\nend',9,'OperationType','2018-07-17 21:17:49','2018-07-17 21:17:49',1),(116,'protocol','needs \"Cloning/StandardCloning\"\n\nclass Protocol\n\n  include StandardCloning\n  \n  def main\n    operations.retrieve.make\n    \n    # Print out labels\n    print_labels\n\n    # Pipette glycerol into cryo tubes\n    pipette_glycerol\n\n    # Transfer into cryo tubes\n    transfer_into_cryo_tubes\n\n    # Sequencing results\n    sequencing_results\n\n    # Discard overnights  \n    discard_overnights\n\n    operations.store\n    \n    return {}\n  end\n  \n  \n  def print_labels\n    show do\n        title \"Print out labels\"\n        \n        note \"On the computer near the label printer, open Excel document titled \'Glycerol stock label template\'.\" \n        note \"Copy and paste the table below to the document and save.\"\n        \n        table operations.start_table \n            .output_item(\"Stock\") \n            .custom_column(heading: \"Sample ID\") { |op| op.output(\"Stock\").sample.id } \n            .custom_column(heading: \"Sample Name\") { |op| op.output(\"Stock\").sample.name[0,16] }\n        .end_table\n\n        note \"Ensure that the correct label type is loaded in the printer: B33-181-492 should show up on the display. \n          If not, get help from a lab manager to load the correct label type.\"\n        note \"Open the LabelMark 6 software and select \'Open\' --> \'File\' --> \'Glycerol stocks.l6f\'\"\n        note \"A window should pop up. Under  \'Start\' enter #{operations.first.output(\"Stock\").item.id} and set \'Total\' to #{operations.length}. Select \'Finish.\'\"\n        note \"Click on the number in the top row of the horizontal side label and select \'Edit External Data\'. A window should pop up. Select \'Finish\'.\"\n        note \"Select \'File\' --> \'Print\' and set the printer to \'BBP33\'.\"\n        note \"Collect labels.\"\n    end\n  end\n  \n  def pipette_glycerol\n    show do \n        title \"Pipette Glycerol into Cryo Tubes\"\n        \n        check \"Take #{operations.length} Cryo #{\"tube\".pluralize(operations.length)}\"\n        check \"Label each tube with the printed out labels\"\n        check \"Pipette 900 uL of 50 percent Glycerol into each tube.\"\n        warning \"Make sure not to touch the inner side of the Glycerol bottle with the pipetter.\"\n    end\n  end\n  \n  \n  def transfer_into_cryo_tubes\n    show do \n        title \"Transfer Into Cryo Tubes\"\n        \n        note \"Transfer <b>900 uL</b> of culture according to the following table:\"\n        \n        table operations.start_table\n            .custom_column(heading: \"Overnight\") { |op| op.input(\"Overnight\").item.id } \n            .custom_column(heading: \"Glycerol Stock ID\", checkable: true) { |op| op.output(\"Stock\").item.id }  \n        .end_table\n        \n        note \"Cap the Cryo tube and then vortex on a table top vortexer for about 20 seconds.\"\n    end\n  end\n  \n  def sequencing_results\n    operations.each do |op|\n        on = op.input(\"Overnight\").item\n        gs = op.output(\"Stock\").item\n        \n        pass_data \"sequencing results\", \"sequence_verified\", from: on, to: gs\n        \n        on.mark_as_deleted\n        on.save\n    end\n  end\n  \n  def discard_overnights\n    show do \n        title \"Discard overnights\"\n        \n        note \"Please discard all of the following overnights in the dishwashing area:\"\n        note operations.map { |op| op.input(\"Overnight\").item.id }.to_sentence\n    end\n  end\nend\n',15,'OperationType','2018-07-17 21:25:30','2018-07-17 21:25:30',1),(117,'protocol','class Protocol\n    \n  def main\n    # debuggin\'\n    if debug\n        operations.each do |op| \n            op.plan.associate \"Item #{op.input(\"Stock\").item.id} sequencing ok?\", [\"yes somestuff\", \"no foo\", \"resequence bar\"].sample\n        end\n    end\n\n    operations.retrieve interactive: false \n    \n    # Gather user responses\n    gather_user_responses\n\n    # Discard plates for yes\n    discard_plates_good\n\n    # Discard plasmid stocks for no\n    discard_plates_bad\n\n    return {}\n  end\n  \n\n  def gather_user_responses\n    operations.select { |op| op.plan.get(\"Item #{op.input(\"Stock\").item.id} sequencing ok?\") }.each do |op|\n        ans = op.plan.get(\"Item #{op.input(\"Stock\").item.id} sequencing ok?\").downcase\n        if ans.include? \"yes\"\n            op.plan.associate \"seq_notice_#{op.input(\"Stock\").item.id}\".to_sym, \"Plate #{op.input(\"Plate\").item.id} has been discarded.\"\n            \n            op.temporary[:yes] = true\n        elsif ans.include? \"resequence\"\n            op.plan.associate \"seq_notice_#{op.input(\"Stock\").item.id}\".to_sym, \"Plasmid stock not verified; please resubmit this stock for sequencing.\"\n            \n            op.temporary[:resequence] = true\n        else\n            op.plan.associate \"seq_notice_#{op.input(\"Stock\").item.id}\".to_sym, \"Plasmid stock #{op.input(\"Stock\").item.id} has been discarded.\"\n            \n            op.temporary[:no] = true\n        end\n    end\n  end\n  \n  def discard_plates_good\n    show do \n        title \"Discard plates from good sequencing results\"\n        \n        note \"Please discard the following plates: \"\n        operations.select { |op| op.temporary[:yes] }.each do |op|\n            pl = op.input(\"Plate\").item\n            note \"Plate #{pl.id} at #{pl.location}\"\n            pl.mark_as_deleted\n            pl.save\n        end\n    end if operations.any? { |op| op.temporary[:yes] }\n  end\n  \n  def discard_plates_bad\n    show do\n        title \"Discard Plasmid Stocks from bad sequencing results\"\n        \n        note \"Please discard the following Plasmid Stocks:\"\n        operations.select { |op| op.temporary[:no] }.each do |op|\n            stock = op.input(\"Stock\").item\n            note \"Plasmid Stock #{stock.id} at #{stock.location}\"\n            stock.mark_as_deleted\n            stock.save\n        end\n    end if operations.any? { |op| op.temporary[:no] }\n  end\nend\n',14,'OperationType','2018-07-17 21:26:00','2018-07-17 21:26:00',1),(118,'protocol','needs \"Cloning/StandardCloning\"\n\nclass Protocol\n\n  include StandardCloning\n\n  def main\n    # Find all overnights and take them\n        operations.retrieve\n\n    # Verify whether each overnight has growth\n        verify_growth = show do\n            title \"Check if overnights have growth\"\n            note \"Choose No for the overnight that does not have growth and throw them away or put in the clean station.\"\n            operations.each do |op|\n                item_id = op.input(\"Plasmid\").child_item.id\n                select [\"Yes\", \"No\"], var: \"#{item_id}\", label: \"Does tube #{item_id} have growth?\"\n            end\n        end\n        \n    # if no growth, delete the overnight    \n        operations.each do |op|\n            item = op.input(\"Plasmid\").child_item\n            if verify_growth[\"#{item.id}\".to_sym] == \"No\"\n                item.mark_as_deleted\n                op.error :no_growth, \"The overnight has no growth.\" \n            end\n        end\n        \n    operations.running.make\n    \n    #transfer each overnight into 1.5 mL tube\n        show do \n            title \"Transfer Overnights into 1.5 mL Tubes\"\n            note \"Grab #{operations.length} 1.5 mL tubes and label from 1 to #{operations.length}\"\n            note \"Transfer 1.5 mL of the overnight into the corresponding 1.5 mL tube.\"\n            index = 0\n            table operations.start_table\n                .input_item(\"Plasmid\")\n                .custom_column(heading: \"Tube Number\") { index = index + 1 }\n            .end_table\n        end\n        \n    #Spin down cells and remove supernatant\n        show do \n           title \"Spin down the cells\"\n           check \"Spin at 5,800 xg for 2 minutes, make sure to balance.\"\n           check \"Remove the supernatant. Pour off the supernatant into liquid waste, being sure not to upset the pellet. Pipette out the residual supernatant.\"\n        end\n        \n    # Resuspend in P1, P2, N3\n        show do\n          title \"Resuspend in P1, P2, N3\"\n          check \"Add 250 uL of P1 into each tube and vortex strongly to resuspend.\"\n          check \"Add 250 uL of P2 and gently invert 5-10 times to mix, tube contents should turn blue.\"\n          check \"Pipette 350 uL of N3 into each tube and gently invert 5-10 times to mix. Tube contents should turn colorless.\"\n          warning \"Time between adding P2 and N3 should be minimized. Cells should not be exposed to active P2 for more than 5 minutes\"\n        end\n\n    # Centrifuge and add to miniprep columns        \n        show do\n            title \"Centrifuge and add to columns\"\n            check \"Spin tubes at 17,000 xg for 10 minutes\"\n            warning \"Make sure to balance the centrifuge.\"\n            check \"Grab #{operations.running.length} blue miniprep spin columns and label with 1 to #{operations.running.length}.\"\n            check \"Remove the tubes from centrifuge and carefully pipette the supernatant (up to 750 uL) into the same labeled columns.\"\n            warning \"Be careful not to disturb the pellet.\"\n            check \"Discard the used 1.5 mL tubes into waste bin.\"\n        end\n        \n    # Spin and wash        \n        show do \n            title \"Spin and Wash\"\n            check \"Spin all columns at 17,000 xg for 1 minute. Make sure to balance.\"\n            check \"Remove the columns from the centrifuge and discard the flow through into a liquid waste container\"\n            check \"Add 750 uL of PE buffer to each column. Make sure the PE bottle that you are using has ethanol added!\"\n            check \"Spin the columns at 17,000 xg for 1 minute\"\n            check \"Remove the columns from the centrifuge and discard the flow through into a liquid waste container.\"\n            check \"Perform a final spin: spin all columns at 17,000 xg for 1 minute.\"\n        end\n\n    #Elute w water\n        show do \n            title \"Elute with water\"\n            check \"Grab  #{operations.length} new 1.5 mL tubes and label top of the tube with 1 to  #{operations.length}.\"\n            check \"Remove the columns from the centrifuge\"\n            check \"Inidividually take each column out of the flowthrough collector and put it into the labeled 1.5 mL tube with the same number, discard the flowthrough collector.\"\n            warning \"For this step, use a new pipette tip for each sample to avoid cross contamination\"\n            check \"Pipette 50 uL of water into the CENTER of each column\"\n            check \"Let the tubes sit on the bench for 2 minutes\"\n            check \"Spin the columns at 17,000 xg for 1 minute\"\n            check \"Remove the tubes and discard the columns\"    \n        end \n        \n    # Relabel tubes w output ids\n        show do \n            title \"Relabel Tubes\"\n            note \"Relabel each tube with the corresponding item ID\"\n            index = 0\n            table operations.start_table \n                .custom_column(heading: \"Tube Number\") { index = index + 1 }\n                .output_item(\"Plasmid\")\n            .end_table\n        end\n    \n    # nanodrop and get concentration\n        show do \n            title \"Nanodrop and Enter Concentration\"\n            note \"Nanodrop each plasmid and enter the concentration below\"\n            table operations.start_table\n                .output_item(\"Plasmid\")\n                .get(:concentration, type: \"number\", heading: \"Concentration\", default: 200)\n            .end_table\n        end\n        \n    # set concentration of plasmid stock and change location of overnights\n        operations.running.each do | op |\n            op.set_output_data \"Plasmid\", :concentration, op.temporary[:concentration]\n            op.set_output_data \"Plasmid\", :from, op.input(\"Plasmid\").item.id\n            op.plan.associate \"overnight_#{op.input(\"Plasmid\").sample.id}\", op.input(\"Plasmid\").item.id\n            op.plan.associate :plasmid, op.output(\"Plasmid\").item.id\n            op.input(\"Plasmid\").child_item.store\n                    \n            pass_data \"sequencing results\", \"sequence_verified\", from: op.input(\"Plasmid\").item, to: op.output(\"Plasmid\").item\n        end\n         \n        operations.running.store\n        return {}\n  end\n\nend\n',11,'OperationType','2018-07-17 21:26:43','2018-07-17 21:26:43',1),(122,'protocol','needs \"Standard Libs/UploadHelper\"\nclass Protocol\n    \n    include UploadHelper\n        \n    # I/O\n    FRAGMENT=\"Fragment\"\n    FRAGMENT_OUT=\"Fragment\"\n    \n    # upload stuff\n    DIRNAME=\"<where are gel files on computer>\"\n    TRIES=3\n    \n    # gel stuff\n    MIN_WEIGHT = 0.0\n    MAX_WEIGHT = 10.0\n    CORRECT=[\"y\",\"n\"] # values for debug\n\n    def main\n        # Sort operations by gels and columns (these can get out of order from PCR)\n        operations.sort! do |op1, op2| \n            fv1 = op1.input(FRAGMENT)\n            fv2 = op2.input(FRAGMENT)\n            [fv1.item.id, fv1.row, fv1.column] <=> [fv2.item.id, fv2.row, fv2.column]\n        end\n        \n        operations.retrieve(interactive: false)\n        \n        # get gel images\n        gels = operations.map { |op| op.input(FRAGMENT).collection}.uniq\n        gels.each { |gel|\n        \n            grouped_ops=operations.select { |op| op.input(FRAGMENT).collection == gel }\n            image_name = \"gel_#{gel.id}\"\n            \n            # image gel\n            image_gel gel, image_name\n            \n            # upload image\n            ups = uploadData(\"#{DIRNAME}/#{image_name}\", 1, TRIES) # 1 file per gel\n            # associate to plan, op \n            up=nil\n            if(!(ups.nil?))\n                up=ups[0]\n                grouped_ops.first.plan.associate(image_name, {}, up)\n                gel.associate(image_name, {}, up)\n                grouped_ops.each do |op| # associate to all operations connected to gel\n                    op.associate(image_name, {}, up)\n                end\n                # can\'t associate to outputs yet because they are only made if lengths are verified\n            end\n            \n            # check lengths of fragments in gel\n            check_frag_length gel, grouped_ops\n            # grouped_ops.map { |op| op.temporary[:correct] = CORRECT.rotate!.first } if debug\n            \n            \n            # check whether fragment matched length\n            grouped_ops.each { |op|\n              if(op.temporary[:correct].upcase.start_with?(\"N\"))\n                op.error :incorrect_length, \"The fragment did not match the expected length.\"\n              end\n            }\n            \n            # get grouped_ops that have not errored\n            \n            grouped_ops.select! { |op| op.status == \"running\"  }\n\n            show { note \"Making the following ops: #{grouped_ops.map { |op| op.id }}\"}\n            grouped_ops.make    # contains only running ops from here on !!!\n            show { note \"#{grouped_ops.map { |op| op.output(FRAGMENT_OUT).item }}\" }\n\n            \n            if(grouped_ops.any?)\n              # cut fragments\n              cut_fragments grouped_ops  \n  \n              # weigh fragments\n              weigh_fragments grouped_ops\n             \n              # associate gel image, fragment lane with fragment and weight with the gel slices to output\n              grouped_ops.each { |op|\n                op.output(FRAGMENT_OUT).item.associate(image_name, \"Your fragment is in row #{op.input(FRAGMENT).row + 1} and column #{op.input(FRAGMENT).column + 1}\", up) \n                op.output(FRAGMENT_OUT).item.associate(:weight, op.temporary[:weight]) \n              }\n              \n            else \n              # do we want this? ask cami/sam\n              show {\n                  title \"Your lucky day!\"\n                  note \"No fragments to extract from gel #{gel}.\"\n              }\n            end # grouped_ops.any?\n            \n            # clean up after gel\n            clean_up gel, gels\n            \n            # delete collection\n            gel.mark_as_deleted\n            \n        } # gels.each\n        \n        ok_ops=operations.running\n        operations=ok_ops\n    \n        # are we cleaning from gel now?\n        choice = show {\n            title \"What Next?\"\n            select [\"Yes\", \"No\"], var: \"choice\", label: \"Would you like to purify the gel slices immediately?\"\n        }\n        plans = operations.map { |op| op.plan }.uniq\n        plans.each { |plan|\n            plan.associate :choice, choice[:choice]\n        }\n        if(choice[:choice] == \"Yes\")\n            show {\n              title \"Keep Gel Slices\"\n              note \"Keep the gel slices #{operations.map{ |op| op.output(FRAGMENT_OUT).item}.to_sentence} on your bench to use in the next protocol.\"\n            }\n        else\n            operations.store\n        end\n    \n        return {}\n    end\n    \n    def image_gel gel, image_name\n      show do\n        title \"Image gel #{gel}\"\n        check \"Clean the transilluminator with ethanol.\"\n        check \"Put the gel #{gel} on the transilluminator.\"\n        check \"Turn off the room lights before turning on the transilluminator.\"\n        check \"Put the camera hood on, turn on the transilluminator and take a picture using the camera control interface on computer.\"\n        check \"Check to see if the picture matches the gel before uploading.\"\n        check \"Rename the picture you just took exactly as <b>#{image_name}</b>.\"\n      end\n    end\n    \n    def check_frag_length gel, grouped_ops\n      show {\n        title \"Verify Fragment Lengths for gel #{gel}\"\n        table grouped_ops.start_table\n          .custom_column(heading: \"Gel ID\") { |op| op.input(FRAGMENT).item.id }\n          .custom_column(heading: \"Row\") { |op| op.input(FRAGMENT).row + 1 }\n          .custom_column(heading: \"Column\", checkable: true) { |op| op.input(FRAGMENT).column + 1 }\n          .custom_column(heading: \"Expected Length\") { |op| op.output(FRAGMENT_OUT).sample.properties[\"Length\"] }\n          .get(:correct, type: \'text\', heading: \"Does the band match the expected length? (y/n)\", default: \'y\')\n        .end_table\n      }\n    end   \n    \n    def cut_fragments grouped_ops  \n      show {\n        title \"Cut Out Fragments\"\n        note \"Take out #{grouped_ops.length} 1.5 mL tubes and label accordingly: #{grouped_ops.map { |op| \"#{op.output(\"Fragment\").item}\" }.to_sentence}\"\n        note \"Now, cut out the bands and place them into the 1.5 mL tubes according to the following table:\"\n        table grouped_ops.start_table \n          .custom_column(heading: \"Gel ID\") { |op| \"#{op.input(FRAGMENT).item}\" }\n          .custom_column(heading: \"Row\") { |op| op.input(FRAGMENT).row + 1 }\n          .custom_column(heading: \"Column\", checkable: true) { |op| op.input(FRAGMENT).column + 1 }\n          .custom_column(heading: \"1.5 mL Tube ID\") { |op| \"#{op.output(FRAGMENT_OUT).item}\" }\n          .custom_column(heading: \"Length\") { |op| op.output(FRAGMENT_OUT).sample.properties[\"Length\"] }\n        .end_table\n      }\n    end\n    \n    def weigh_fragments grouped_ops\n      show {\n        title \"Weigh Gel Slices\"\n        note \"Perform this step using the scale inside the gel room.\"\n        check \"Zero the scale with an empty 1.5 mL tube.\"\n        check \"Weigh each slice and enter the weights in the following table:\"\n        table grouped_ops.start_table\n          .custom_column(heading: \"1.5 mL Tube ID\") { |op| \"#{op.output(FRAGMENT_OUT).item}\" }\n          .get(:weight, type: \'number\', heading: \"Weight (g)\",  default: MIN_WEIGHT)\n          .end_table\n      }\n    end\n    \n    def clean_up gel, gels\n      show {\n        title \"Clean Up\"\n        check \"Turn off the transilluminator.\"\n        check \"Dispose of the gel #{gel} and any gel parts by placing it in the waste container. Spray the surface of the transilluminator with ethanol and wipe until dry using a paper towel.\"\n        check \"Clean up the gel box and casting tray by rinsing with water. Return them to the gel station.\"\n        if(gel==gels.last)\n            check \"Dispose gloves after leaving the room.\"\n        end\n      }\n    end\nend',4,'OperationType','2018-07-17 21:27:49','2018-07-17 21:27:49',1),(126,'protocol','needs \"Cloning/StandardCloning\"\nneeds \"Cloning/GradientPCR\"\n\nclass Protocol\n    \n  # I/O\n  FWD = \"Forward Primer\"\n  REV = \"Reverse Primer\"\n  TEMPLATE = \"Template\"\n  FRAGMENT = \"Fragment\"\n  \n  # other\n  SEC_PER_KB = 30 # sec, extension timer per KB for KAPA\n  \n  # get the gradient PCR magic\n  include StandardCloning\n  include GradientPCR\n\n  def main\n    if debug\n      operations.retrieve interactive: false\n      item = operations[0].input(FWD).item\n      operations.each do |op|\n        if rand(2) < 1\n          op.input(REV).set item: item\n          op.input(FWD).set item: item\n        end\n      end\n    end\n    # grab all necessary items\n    dilute_stocks_and_retrieve TEMPLATE\n    kapa_stock_item = find(:sample, name: \"Kapa HF Master Mix\")[0].in(\"Enzyme Stock\")[0]\n    take [kapa_stock_item], interactive: true,  method: \"boxes\"\n    \n    #check the volumes of input primers for all operations, and ensure they are sufficient\n    operations.each { |op| op.temporary[:primer_vol] = 2.5 }\n    check_volumes [FWD, REV], :primer_vol, :make_aliquots_from_stock, check_contam: true\n    \n    # build a pcrs hash that groups pcr by T Anneal\n    pcrs = build_pcrs_hash\n\n    # show the result of the binning algorithm\n    pcrs.each_with_index do |pcr, idx|\n      show { title \"pcr #{idx}\"}\n      log_bin_info pcr\n    end if debug\n\n    # generate a table for stripwells\n    stripwell_tab = build_stripwell_table pcrs\n    \n    # prepare and label stripwells for PCR\n    prepare_stripwells stripwell_tab\n    \n    # add templates to stripwells for pcr\n    load_templates pcrs\n    \n    # add primers to stripwells\n    load_primers pcrs\n\n    # add kapa master mix to stripwells\n    add_mix stripwell_tab, kapa_stock_item\n    \n    # run the thermocycler\n    start_pcr pcrs\n    \n    # store \n    operations.running.store io: \"input\", interactive: true, method: \"boxes\"\n    release [kapa_stock_item], interactive: true\n    \n    return {}\n  end\n  \n  # dilute to 1ng/uL stocks if necessary\n  def dilute_stocks_and_retrieve input\n  \n    # only use inputs that haven\'t been diluted and that don\'t have diluted stocks already\n    ops_w_undiluted_template = operations.reject { true }\n    operations.each do |op|\n        next if op.input(input).object_type.name.include?(\"1 ng/µL\")\n        \n        sample = op.input(input).sample\n        ot_name = op.input(input).object_type.name.include?(\"Unverified\") ? \"1 ng/µL Plasmid Stock\" : \"1 ng/µL \" + sample.sample_type.name + \" Stock\"\n        diluted_stock = sample.in(ot_name).first\n        \n        if diluted_stock\n            op.input(input).set item: diluted_stock\n        else\n            new_stock = produce new_sample sample.name, of: sample.sample_type.name, as: ot_name\n            op.temporary[:diluted_stock] = new_stock\n            \n            ops_w_undiluted_template.push op\n        end\n    end\n    \n    # retrieve operation inputs (doesn\'t include the stocks replaced by diluted stocks above)\n    ops_w_undiluted_template.retrieve\n    \n    # all stocks may be diluted already\n    if ops_w_undiluted_template.empty?\n        operations.retrieve\n        return\n    end\n    \n    # ensure concentrations\n    check_concentration ops_w_undiluted_template, input\n    \n    # dilute stocks\n    show do\n      title \"Make 1 ng/L Template Stocks\"\n      \n      check \"Grab #{ops_w_undiluted_template.length} 1.5 mL tubes, label them with #{ops_w_undiluted_template.map { |op| op.temporary[:diluted_stock].id }.join(\", \")}\"\n      check \"Add template stocks and water into newly labeled 1.5 mL tubes following the table below\"\n      \n      table ops_w_undiluted_template\n          .start_table\n          .custom_column(heading: \"Newly-labeled tube\") { |op| op.temporary[:diluted_stock].id }\n          .input_item(input, heading: \"Template stock, 1 L\", checkable: true)\n          .custom_column(heading: \"Water volume\", checkable: true) { |op| op.input(input).item.get(:concentration).to_f - 1 }\n          .end_table\n      check \"Vortex and then spin down for a few seconds\"\n    end\n    \n    # return input stocks\n    release ops_w_undiluted_template.map { |op| op.input(input).item }, interactive: true, method: \"boxes\"\n    \n    # retrieve the rest of the inputs\n    operations.reject { |op| ops_w_undiluted_template.include? op }.retrieve\n    \n    # set diluted stocks as inputs\n    ops_w_undiluted_template.each { |op| op.input(input).set item: op.temporary[:diluted_stock] }\n  end\n  \n  \n  # TODO dilute from stock if item is aliquot\n  # Callback for check_volume.\n  # takes in lists of all ops that have input aliquots with insufficient volume, sorted by item,\n  # and takes in the inputs which were checked for those ops.\n  # Deletes bad items and remakes each from primer stock\n  def make_aliquots_from_stock bad_ops_by_item, inputs\n    # bad_ops_by_item is accessible by bad_ops_by_item[item] = [op1, op2, op3...]\n    # where each op has a bad volume reading for the given item\n    \n    # Construct list of all stocks needed for making aliquots. Error ops for which no primer stock is available\n    # for every non-errored op that has low item volume,\n    # replace the old aliquot item with a new one. \n    aliquots_to_make = 0\n    stocks = []\n    ops_by_fresh_item = Hash.new(0)\n    stock_table = [[\"Primer Stock ID\", \"Primer Aliquot ID\"]]\n    transfer_table = [[\"Old Aliquot ID\", \"New Aliquot ID\"]]\n    bad_ops_by_item.each do |item, ops|\n      stock = item.sample.in(\"Primer Stock\").first ######## items is a string?\n      if stock.nil?\n        ops.each { |op| op.error :no_primer, \"You need to order a primer stock for primer sample #{item.sample.id}.\" }\n        bad_ops_by_item.except! item\n      else\n        stocks.push stock\n        aliquots_to_make += 1\n        item.mark_as_deleted\n        fresh_item = produce new_sample item.sample.name, of: item.sample.sample_type.name, as: item.object_type.name\n        bad_ops_by_item.except! item\n        ops_by_fresh_item[fresh_item] = ops\n        ops.each do |op| \n          input = inputs.find { |input| op.input(input).item == item }\n          op.input(input).set item: fresh_item\n        end\n        stock_table.push [stock.id, {content: fresh_item.id, check: true}]\n        if item.get(:contaminated) != \"Yes\"\n          transfer_table.push [item.id, {content: fresh_item.id, check: true}]    \n        end\n      end\n    end\n    \n    bad_ops_by_item.merge! ops_by_fresh_item\n    take stocks, interactive: true\n    \n    # label new aliquot tubes and dilute\n    show do \n      title \"Grab 1.5 mL tubes\"\n      \n      note \"Grab #{aliquots_to_make} 1.5 mL tubes\"\n      note \"Label each tube with the following ids: #{bad_ops_by_item.keys.map { |item| item.id }.sort.to_sentence}\"\n      note \"Using the 100 uL pipette, pipette 90uL of water into each tube\"\n    end\n  \n    # make new aliquots\n    show do \n      title \"Transfer primer stock into primer aliquot\"\n      \n      note \"Pipette 10 uL of the primer stock into the primer aliquot according to the following table:\"\n      table stock_table\n    end\n    \n    \n    if transfer_table.length > 1\n      show do\n        title \"Transfer Residual Primer\"\n        \n        note \"Transfer primer residue from the low volume aliquots into the fresh aliquots according to the following table:\"\n        table transfer_table\n      end\n    end\n    \n    release stocks, interactive: true\n  end\n  \n  # build a pcrs hash that groups pcr by T Anneal\n  def build_pcrs_hash\n    pcrs = distribute_pcrs operations.running, 4\n    pcrs.each do |pcr|\n      lengths = pcr[:ops_by_bin].values.flatten.collect { |op| op.output(FRAGMENT).sample.properties[\"Length\"] }\n      extension_time = (lengths.max)/1000.0*SEC_PER_KB\n      # adding more extension time for longer size PCR.\n      if lengths.max < 2000\n        extension_time += 30\n      elsif lengths.max < 3000\n        extension_time += 60\n      else\n        extension_time += 90\n      end\n      extension_time = 3 * 60 if extension_time < 3 * 60\n      pcr[:mm], pcr[:ss] = (extension_time.to_i).divmod(60)\n      pcr[:mm] = \"0#{pcr[:mm]}\" if pcr[:mm].between?(0, 9)\n      pcr[:ss] = \"0#{pcr[:ss]}\" if pcr[:ss].between?(0, 9)\n\n      # set up stripwells (one for each temperature bin)\n      pcr[:ops_by_bin].each do |bin, ops|\n          ops.make\n          pcr[:stripwells] += ops.output_collections[FRAGMENT]\n      end\n    end\n    pcrs\n  end\n  \n  # generate a table for stripwells\n  def build_stripwell_table pcrs\n    stripwells = pcrs.collect { |pcr| pcr[:stripwells] }.flatten\n    stripwell_tab = [[\"Stripwell\", \"Wells to pipette\"]] + stripwells.map { |sw| [\"#{sw.id} (#{sw.num_samples <= 6 ? 6 : 12} wells)\", { content: sw.non_empty_string, check: true }] }\n  end\n  \n  # prepare and label stripwells for PCR\n    def prepare_stripwells stripwell_tab\n    show do\n      title \"Label and prepare stripwells\"\n      \n      note \"Label stripwells, and pipette 19 L of molecular grade water into each based on the following table:\"\n      table stripwell_tab\n      stripwell_tab\n    end\n  end\n  \n  # add templates to stripwells for pcr\n  def load_templates pcrs\n    pcrs.each_with_index do |pcr, idx|\n      show do\n        title \"Load templates for PCR ##{idx + 1}\"\n        \n        pcr[:ops_by_bin].each do |bin, ops|\n          table ops\n              .start_table\n              .output_collection(FRAGMENT, heading: \"Stripwell\")\n              .custom_column(heading: \"Well\") { |op| op.output(FRAGMENT).column + 1 }\n              .input_item(TEMPLATE, heading: \"Template, 1 L\", checkable: true)\n              .end_table\n        end\n        warning \"Use a fresh pipette tip for each transfer.\".upcase\n      end\n    end\n  end\n  \n  # add primers to stripwells\n  def load_primers pcrs\n    pcrs.each_with_index do |pcr, idx|\n      show do\n        title \"Load primers for PCR ##{idx + 1}\"\n        \n        pcr[:ops_by_bin].each do |bin, ops|\n          table ops.start_table\n              .output_collection(FRAGMENT, heading: \"Stripwell\")\n              .custom_column(heading: \"Well\") { |op| op.output(FRAGMENT).column + 1 }\n              .input_item(FWD, heading: \"Forward Primer, 2.5 L\", checkable: true)\n              .input_item(REV, heading: \"Reverse Primer, 2.5 L\", checkable: true)\n              .end_table\n        end\n        warning \"Use a fresh pipette tip for each transfer.\".upcase\n      end\n    end\n  end\n  \n  # add kapa master mix to stripwells\n  def add_mix stripwell_tab, kapa_stock_item\n      show do\n          title \"Add Master Mix\"\n          \n          note \"Pipette 25 L of master mix (#{kapa_stock_item}) into stripwells based on the following table:\"\n          table stripwell_tab\n          warning \"USE A NEW PIPETTE TIP FOR EACH WELL AND PIPETTE UP AND DOWN TO MIX.\"\n          check \"Cap each stripwell. Press each one very hard to make sure it is sealed.\"\n      end\n  end\n  \n  # run the thermocycler and update the positions of the stripwells\n  def start_pcr pcrs\n      pcrs.each_with_index do |pcr, idx|\n        is_gradient = pcr[:bins].length > 1\n        # log_bin_info pcr # use for debugging bad binning behavior\n        thermocycler = show do\n          if !is_gradient\n            title \"Start PCR ##{idx + 1} at #{pcr[:bins].first} C\"\n            \n            check \"Place the stripwell(s) #{pcr[:stripwells].collect { |sw| \"#{sw}\" }.join(\", \")} into an available thermal cycler and close the lid.\"\n            get \"text\", var: \"name\", label: \"Enter the name of the thermocycler used\", default: \"TC1\"\n            check \"Click \'Home\' then click \'Saved Protocol\'. Choose \'YY\' and then \'CLONEPCR\'.\"\n            check \"Set the anneal temperature to #{pcr[:bins].first}. This is the 3rd temperature.\"\n          else\n            title \"Start PCR ##{idx + 1} (gradient) over range #{pcr[:bins].first}-#{pcr[:bins].last} C\"\n            check \"Click \'Home\' then click \'Saved Protocol\'. Choose \'YY\' and then \'CLONEPCR\'.\"\n            check \"Click on annealing temperature -> options, and check the gradient checkbox.\"\n            check \"Set the annealing temperature range to be #{pcr[:bins].first}-#{pcr[:bins].last} C.\"\n            note \"The following stripwells are ordered front to back.\"\n            pcr[:stripwells].map.with_index do |sw, idx|\n              #TODO FIX v\n              #pcr[ops_by_bin].keys and pcr[:bins] are not always equivalent. Sometimes pcr[ops_by_bin].keys has items that are not in pcr[:bins]\n              temp = pcr[:ops_by_bin].keys[idx].to_f\n              row_num = pcr[:bins].index temp\n              row_letter = (\'H\'.ord - row_num).chr\n              row_letter = \'A\' if pcr[:bins].length == 2 && idx == 1\n              check \"Place the stripwell #{sw} into Row #{row_letter} (#{temp} C) of an available thermal cycler.\"\n            end\n            get \"text\", var: \"name\", label: \"Enter the name of the thermocycler used\", default: \"TC1\"\n          end\n          check \"Set the 4th time (extension time) to be #{pcr[:mm]}:#{pcr[:ss]}.\"\n          check \"Press \'Run\' and select 50 L.\"\n        end\n        \n        # set the location of the stripwell\n        pcr[:stripwells].flatten.each do |sw|\n          sw.move thermocycler[:name]\n        end\n      end\n  end\n\n  def log_bin_info pcr\n    show do\n      title \"bin info\"\n      note \"ops_by_bin\"\n      pcr[:ops_by_bin].each do |bin, ops|\n        opids = ops.map { |op| op.id }\n        check \"#{bin.to_s}  =>  #{opids.to_s}\"\n      end\n\n      note \"bins\"\n      pcr[:bins].each do |bin|\n        check \"#{bin.to_s}\"\n      end\n    end\n  end\nend',1,'OperationType','2018-07-17 22:52:59','2018-07-17 22:52:59',1),(127,'protocol','require \'matrix\'\nneeds \"Cloning/StandardCloning\"\n\n    # math behind the equimolar volume calculation\n    # Assume that there are n fragment stocks, each with concentrations c1,..., cn, and lengths l1,...,ln. The volumes of each fragment stocks to add in the Gibson reaction is denoted as v1,...,vn. Assuming that the molecular weight (g/mol) of the fragment is proportional to the lenght of the fragment, to ensure equimolar of these n fragment stocks, the following must satisfy:\n    # v1 + ... + vn = 5 (the total gibson reaction volume)\n    # v1 * c1 / l1 = ... = vn * cn / ln (they\'re equimolar)\n    # unit of v is uL, unit of c is g/uL, unit of l1 (molecular weight) is g/mol\n    # thus v * c / l represent the moles of the fragment stock, and esuring v1 * c1 / l1 = ... = vn * cn / ln lead to equimolar fragment stocks.\n    # These mathmatical constraints can be reformated as:\n    # v1 + ... + vn = 5\n    # v1 * c1 / l1 - v2 * c2 / l2 = 0\n    # v1 * c1 / l1 - v3 * c3 / l3 = 0\n    #          ...\n    # v1 * c1 / l1 - vn * cn / ln = 0\n    # The following matrix equations hold:\n    # coefficient_matrix * fragment_volumes = total_vector,\n    # where \n    # coefficient_matrix = [\n    # [1, 1, ..., 1]\n    # [c1 / l1, -c2 / l2, ..., 0]\n    # [c1 / l1, 0, - c3 / l3 ..., 0]\n    # ...\n    # [c1 / l1, 0, ..., - vn * cn / ln]\n    # ]  (n x n matrix)\n    # fragment_volumes = [[v1], [v2], ..., [vn]] (n x 1 matrix)\n    # total_vector = [[5], [0], ..., [0]] (n x 1 matrix)\n    # matrix multiplication\n    # coefficient_matrix.inv * coefficient_matrix * fragment_volumes = coefficient_matrix.inv * total_vector\n    # Therefore we have\n    # fragment_volumes = coefficient_matrix.inv * total_vector\n\nclass Protocol\n    \n    include StandardCloning\n    debug = false\n    \n    # this builds a matrix with 1\'s in the first row\n    # the concentration over length (c / l) of the fragment when row = column\n    # (with alternating sign) and 0\'s everywhere else\n    def main\n        # Take fragments\n        operations.retrieve.make\n\n        check_concentration operations, \"Fragment\"\n        \n        # Check for valid fragment lengths\n        operations.each do |op|\n          fragments_fv = op.input_array(\"Fragment\")\n          fragments_fv.each do |fragment|\n              if fragment.item.sample.properties[\"Length\"].nil?\n                  op.error :invalid_length, \"This fragment\'s length is not valid.\"\n              end\n          end\n        end\n        \n        temp = operations.running\n        operations = temp\n        \n        #TODO: refactor gibson batch finding algorithm, gib_batch instantiation is uneccessarily long\n        # determine which batches to grab gibson aliquots from\n        gib_batch = Collection.where(\"data IS NOT NULL\").where(object_type_id: ObjectType.find_by_name(\"Gibson Aliquot Batch\").id).where(\'location != ?\', \"deleted\").to_a.keep_if { |b| b.data[12,13][0,5] == Sample.find_by_name(\"Gibson Aliquot\").id.to_s}[0]\n        if gib_batch.nil?\n            operations.each { |op| op.error :not_enough_gibson, \"There were not enough gibson aliquots to complete the operation.\" }\n            raise \"not enough gibson\"\n        end\n        batch_id_array = [gib_batch.id]\n        total_aliquots = gib_batch.num_samples\n        aliquots_needed = operations.length\n        i = 0\n        while total_aliquots < aliquots_needed\n            gib_batch.mark_as_deleted \n            i += 1\n            gib_batch = Collection.where(\"data IS NOT NULL\").where(object_type_id: ObjectType.find_by_name(\"Gibson Aliquot Batch\").id).where(\'location != ?\', \"deleted\").to_a.keep_if { |b| b.data[12,13][0,5] == Sample.find_by_name(\"Gibson Aliquot\").id.to_s}[0]\n            if gib_batch.nil?\n                operations.each { |op| op.error :not_enough_gibson, \"There were not enough gibson aliquots to complete the operation.\" }\n                raise \"Aquarium cannot find any gibson aliquot batches in the system\"\n            end\n            batch_id_array.push(gib_batch.id)\n            total_aliquots += gib_batch.num_samples\n        end\n    \n        #fetch gibson aliquots\n        get_gibson_aliquots batch_id_array\n        \n        # Go through and pipette fragments into aliquots\n        to_discard = []\n        \n        # Keep track of fragment stocks to return on errored ops.\n        to_return = [];\n        \n        operations.each do |op|# calculate how much of each fragment is needed in aliquot\n          tot_f_vol, f_vol = calc_gibson_volumes op\n          vol_table = [[\"Fragment Stock IDs\", \"Volume\"]].concat(op.input_array(\"Fragment\").items.collect { |f| f.id}.zip f_vol.map { |v| { content: v, check: true }})\n          \n          # ask tech if there is enough volume\n          vol_checking = show do \n            title \"Checking Volumes\"\n            tot_f_vol.each do |id, v|\n                select [\"Yes\", \"No\"], var: \"v#{id}\", label: \"Does #{id} have at least #{v} uL?\", default: 0\n            end\n          end\n          \n          # find replacements\n          replacement = {}\n          \n          tot_f_vol.each do |id, v|\n              if vol_checking[\"v#{id}\".to_sym] == \"No\"\n                  find_replacements replacement, to_discard, id, v\n              end\n          end\n          \n          # associate replacements with operation inputs\n          find_replacement = []\n          associate_replacements find_replacement, replacement, op\n          \n          if op.status != \"error\"\n            # take find_replacement, interactive: true if find_replacement.any?\n            check_concentration [op], \"Fragment\"\n            \n            #feature addition: make an extra column for this table to show whether a p2 pipette is required depending on if vol < 0.5\n            if find_replacement.any?\n              tot_f_vol, f_vol = calc_gibson_volumes op\n              vol_table = [[\"Fragment Stock IDs\", \"Volume\"]].concat(op.input_array(\"Fragment\").items.collect { |f| f.id}.zip f_vol.map { |v| { content: v, check: true }})\n            end\n            load_gibson_reaction op, vol_table\n          else\n              \n            # Keep track of what items need to be returned in the case of an error.\n            current_fv = op.input_array(\"Fragment\")\n            current_fv.each do |fv|\n                if fv.item.location != \"deleted\"\n                    to_return.push(fv.item)\n                end\n            end\n            \n            show do\n              title \"Gibson canceled\"\n              note \"Sorry it had to be this way. :/\"\n            end\n          end\n        end\n    \n        # put on heat block\n        heat_block\n        \n        #return gibson aliquots\n        data = return_gibson_aliquots aliquots_needed, batch_id_array\n        aliquots_returned = data[:n]\n        \n        #updating gibson batches\n        gibsons_used = aliquots_needed - aliquots_returned.to_i\n        update_gibson_batches gibsons_used, batch_id_array\n  \n        # return aluminum tube rack, ice block\n        return_aluminumTubeRack_and_iceBlock\n        \n        # return fragments\n        release(to_return, interactive: true)\n        operations.store(io: \"input\", interactive: true, method: \"boxes\")\n        \n          show do\n              title \"Discard depleted stocks\"\n              note \"Discard the following stocks: #{to_discard.map { |s| s.id }}\"\n          end if to_discard.any?\n    return {}\n  end\n  \n    def gibson_coefficients row, col, conc_over_length\n      # TODO fix this commented out section (only causes error when not debugging)\n      # if !debug\n        if row == 0\n          return 1\n        elsif col == 0\n          return conc_over_length[0]\n        elsif row == col\n          return -conc_over_length[row]\n        else\n          return 0\n        end\n      # end\n    end\n\n    # this creates the \"total_volume\" row vector\n    def gibson_vector row\n      if row == 0\n        return 5.0\n      else\n        return 0\n      end\n    end\n    \n    def calc_gibson_volumes op\n      tot_f_vol = Hash.new(0)\n      \n      conc_over_length = op.input_array(\"Fragment\").items.collect { |f| f.get(:concentration).to_f  / f.sample.properties[\"Length\"]}\n      \n      n = conc_over_length.length\n      total_vec = Matrix.build(n, 1) { |r, c| gibson_vector r }\n      coef_m = Matrix.build(n, n) { |r, c| gibson_coefficients r, c, conc_over_length }\n      vol_vec = (coef_m.inv * total_vec).each.to_a.collect! { |x| x.round(2) }\n      f_vol = vol_vec.each.to_a.collect! { |x| x < 0.20 ? 0.20 : x }\n      \n      # this is to ensure that the rxn isn\'t > 5uL\n      max = f_vol.max\n      total = f_vol.reduce(:+)\n      f_vol[f_vol.index(max)] = (max - (total - 5)).round(2) if total > 5\n      \n      # collect all volumes to ask tech if enough stock is present \n      op.input_array(\"Fragment\").items.each_with_index do |f, i|\n        tot_f_vol[f.id] = f_vol[i]\n      end\n      \n      return tot_f_vol, f_vol\n    end\n\n  \n  def heat_block\n    if operations.running.any?\n        show do \n            title \"Put Reactions on Heat Block\"\n            warning \"Vortex and spin all Gibson Reactions before putting them on the heat block!\"\n            note \"Put all #{operations.length} on the 50 C heat block\"\n            note\"<a href=\'https://www.google.com/search?q=1+hr+timer&oq=1+hr+timer&aqs=chrome..69i57j0l5.1684j0j7&sourceid=chrome&es_sm=122&ie=UTF-8#q=1+hour+timer\' target=\'_blank\'>\n                Set a 1 hr timer on Google</a> to set a reminder to start the ecoli_transformation protocol and retrieve the Gibson Reactions.\"\n        end\n    end\n  end\n  \n  def find_replacements replacement, to_discard, id, v\n    f = Item.find(id)\n    replacement[f.id] = f\n    is_bad_replacement = true\n    \n    # Keep finding replacements if previous replacement doesn\'t have enough volume\n    while(is_bad_replacement)\n        to_discard.push replacement[f.id]\n        replacement[f.id].move_to(\"deleted\")\n        replacement[f.id].save \n        replacement[f.id] = Item.where(sample_id: f.sample_id).where(object_type_id: f.object_type_id).where(\"location != ?\", \"deleted\").to_a.first\n        # Only do this if there exists a replacement\n        # has the tech confirm if the new replacement has enough volume\n        if replacement[f.id]\n            loop_check = show do\n                title \"Find replacements\"\n                note \"Retrieve #{replacement[f.id].id} from #{replacement[f.id].location}\"\n                select [\"Yes\", \"No\"], var: \"v#{id}\", label: \"Does #{replacement[f.id].id} have at least #{v} uL?\", default: 0\n            end\n            is_bad_replacement = !(loop_check[\"v#{id}\".to_sym] == \"Yes\")\n        else #exit the loop if there are no replacements available\n            show do\n                title \"We couldnt find replacements.\"\n            end\n            is_bad_replacement = false;\n        end\n    end   \n  end\n  \n  def get_gibson_aliquots batch_id_array\n    show do\n        title \"Grab Gibson aliquots\"\n        note \"Grab an ice block and aluminum tray from the fridge\"\n        note \"Grab #{operations.length} Gibson aliquots from batch#{\"es\" if batch_id_array.length > 1} #{batch_id_array}, located in the M20\"\n    end\n  end\n  \n  def load_gibson_reaction op, vol_table\n    show do\n      title \"Load Gibson Reaction #{op.output(\"Assembled Plasmid\").item.id}\"\n      note \"Label an unused aliquot with #{op.output(\"Assembled Plasmid\").item.id}\"\n      note \"Make sure the Gibson aliquot is thawed before pipetting\"\n      warning \"Please use the P2 for any volumes below 0.5 uL\"\n      table vol_table\n    end\n  end  \n  \n  def return_aluminumTubeRack_and_iceBlock\n    show do\n      title \"Return ice block and aluminum tube rack\"\n      check \"Return the ice block and aluminum tube rack.\"\n      check \"discard the used up gibson aliquot batch.\"\n    end    \n  end\n  \n  def return_gibson_aliquots aliquots_needed, batch_id_array\n    data = show do\n        title \"Return unused gibson aliquots\"\n        note \"#{aliquots_needed} aliquots were needed for this protocol, but you might have not used all of them.\"\n        note \"Return any unused aliquots to batch#{\"es\" if batch_id_array.length > 1} #{batch_id_array.reverse} in the M20\"\n        get \"number\", var: \"n\", label: \"How many gibson aliquots will be returned?\", default: \"0\"\n        note \"If you used more aliquots than predicted, indicate with a negative value.\"\n    end\n    data #return\n  end\n  \n  def associate_replacements find_replacement, replacement, op\n    replacement.each do |id, item|\n\n      if item\n\n        op.input_array(\"Fragment\").find { |fv| fv.item.id == id }.set item: item\n        find_replacement.push(item)\n      else\n        op.error :volume, \"Insufficient fragment stock volume for Gibson reaction.\" \n        break\n      end\n    end\n  end\n  \n    def update_gibson_batches gibsons_used, batch_id_array\n        i = 0\n        gib_batch = Collection.find batch_id_array[i]\n        while gibsons_used > 0\n            if gib_batch.empty?\n                gib_batch.mark_as_deleted\n                i += 1\n                gib_batch = Collection.find batch_id_array[i]\n            end\n            \n            gibsons_used -= 1\n            gib_batch.remove_one\n        end\n        gib_batch\n    end\nend',6,'OperationType','2018-07-17 22:59:14','2018-07-17 22:59:14',1),(130,'protocol','needs \"Cloning/StandardCloning\"\n\nclass Protocol\n    \n  include StandardCloning\n\n  def main\n    operations.retrieve(interactive: false)\n    \n    # Increase the number of colonies picked the plate. If no picked number is present,\n    # set it equal to one. Note that setting the status to \"error\" will remove the operation\n    # from operations.running, so it will not be listed in tables, etc.\n    operations.select { |op| op.input(\"Plasmid\").item.object_type_id == ObjectType.where(name: \"Checked E coli Plate of Plasmid\").first.id }.each do |op|\n       nc = (op.input_data \"Plasmid\", :num_colonies).to_i\n       np = (op.input_data \"Plasmid\", :num_picked).to_i\n       if debug && !nc && rand(2) == 1\n         op.set_input_data \"Plasmid\", :num_colonies, 1\n         op.set_input_data \"Plasmid\", :num_picked, 1\n       elsif !debug && (!nc || nc == 0 || ( np && np >= nc ))\n         op.error :missing_data, \"No colonies left on plate or colony number not defined\"\n       else\n         op.set_input_data \"Plasmid\", :num_picked, (np || 0) + 1\n       end\n    end\n    \n    # Error out operations whose samples don\'t have bacterial marker data. Tell technician\n    # which ones are not being used. Quit if there are no samples left.\n    operations.each do |op|\n      unless op.input(\"Plasmid\").child_sample.properties[\"Bacterial Marker\"]\n        if debug && rand(2) == 1\n          op.input(\"Plasmid\").child_sample.set_property \"Bacterial Marker\", \"Amp\"\n        else\n          op.set_status \"error\"\n          op.associate :missing_marker, \"No bacterial marker associated with plasmid\"\n        end\n      end\n    end\n    \n    operations.make\n    \n    p_ot = ObjectType.where(name: \"Checked E coli Plate of Plasmid\").first \n    \n    raise \"Could not find object type \'Checked E coli Plate of Plasmid\'\" unless p_ot\n    \n    plate_inputs = operations.running.select { |op| op.input(\"Plasmid\").item.object_type_id == p_ot.id }\n    \n    g_ot = ObjectType.where(name: \"Plasmid Glycerol Stock\").first \n    \n    raise \"Could not find object type \'Plasmid Glycerol Stock\'\" unless g_ot \n    \n    glycerol_stock_inputs = operations.running.select { |op| op.input(\"Plasmid\").item.object_type_id == g_ot.id }\n    \n    overnight_steps plate_inputs, \"Checked E coli Plate of Plasmid\" if plate_inputs.any?\n    overnight_steps glycerol_stock_inputs, \"Plasmid Glycerol Stock\" if glycerol_stock_inputs.any?\n    \n    # Associate input id with from data for overnight.\n    operations.running.each do |op|\n      gs = op.input(\"Plasmid\").item\n      on = op.output(\"Overnight\").item\n      \n      on.associate :from, gs.id\n      pass_data \"sequencing results\", \"sequence_verified\", from: gs, to: on\n    end\n    \n    operations.running.each do |op|\n      op.output(\"Overnight\").child_item.move \"37 C shaker incubator\"\n    end\n    \n    operations.store\n    \n    return {}\n  end \n\n\n  def overnight_steps(ops, ot)\n    if ot == \"Plasmid Glycerol Stock\"\n      ops.retrieve interactive: false\n    else\n      ops.retrieve\n    end\n    \n    # Sorting ops by the bacterial marker attribute\n    temp = ops.sort do |op1,op2|\n      op1.input(\"Plasmid\").child_sample.properties[\"Bacterial Marker\"].upcase <=> op2.input(\"Plasmid\").child_sample.properties[\"Bacterial Marker\"].upcase\n    end\n    ops = temp\n    \n    ops.extend(OperationList)\n   \n    #Label and load overnight tubes \n    label_load_tubes ops\n\n    #Inoculation\n    inoculate ot, ops\n      \n  end\n    \n    \n  def label_load_tubes ops\n    show do\n      title \"Label and load overnight tubes\"\n      note \"In the Media Bay, collect #{ops.length} 14mL tubes\"\n      note \"Write the overnight id on the corresponding tube and load with the correct media type.\"\n      table ops.start_table\n        .output_item(\"Overnight\", checkable: true)\n        .custom_column(heading: \"Media\") { |op| \"TB+\" + op.input(\"Plasmid\").child_sample.properties[\"Bacterial Marker\"].upcase }\n        .custom_column(heading: \"Quantity\") { |op| \"3 mL\" }\n        .end_table\n    end\n  end\n  \n  def inoculate ot, ops\n    show {\n      title \"Inoculation from #{ot}\"\n      note \"Use 10 uL sterile tips to inoculate colonies from plate into 14 mL tubes according to the following table.\" if ot == \"Checked E coli Plate of Plasmid\"\n      check \"Mark each colony on the plate with corresponding overnight id. If the same plate id appears more than once in the table, inoculate different isolated colonies on that plate.\" if ot == \"Checked E coli Plate of Plasmid\"\n      note \"Use 100 uL pipette to inoculate cells from glycerol stock into the 14 mL tube according to the following table.\" if ot == \"Plasmid Glycerol Stock\"\n      table ops.start_table\n        .input_item(\"Plasmid\", heading: ot)\n        .custom_column(heading: \"#{ot} Location\") { |op| op.input(\"Plasmid\").item.location }\n        .output_item(\"Overnight\", checkable: true)\n        .end_table      \n    } \n  end\nend ',10,'OperationType','2018-07-17 23:17:29','2018-07-17 23:17:29',1),(132,'protocol','needs \"Cloning/StandardCloning\"\r\n\r\nclass Protocol\r\n  include StandardCloning\r\n\r\n  PLASMID = \"Plasmid\"\r\n  PRIMER = \"Sequencing Primer\"\r\n  SEQ_RESULT = \"Plasmid for Sequencing\"\r\n  GENEWIZ_USER = Parameter.get(\"Genewiz User\")\r\n  GENEWIZ_PASS = Parameter.get(\"Genewiz Password\")\r\n\r\n  def main\r\n    operations.retrieve\r\n    \r\n    # Raise error if fragment length is invalid\r\n    \r\n    # Check for valid fragment lengths\r\n    operations.each do |op|\r\n      if op.input(PLASMID).item.sample.properties[\"Length\"].nil?\r\n        raise \"This fragment\'s length is not valid.\"\r\n      end\r\n    end\r\n      \r\n    check_concentration operations, PLASMID\r\n    \r\n    # calculate required input volumes based on Genewiz guide, store in values of op.temporary[<input>_vol]\r\n    calculate_volumes\r\n\r\n    # volume check using the volumes calculated in the previously called \'calculate_volumes\' method\r\n    check_volumes [PLASMID], :stock_vol, :your_plasmid_sucks, check_contam: true\r\n    check_volumes [PRIMER], :primer_vol, :make_aliquots_from_stock, check_contam: true\r\n\r\n    if operations.running.empty?\r\n        show do\r\n            title \"It\'s your lucky day!\"\r\n            \r\n            note \"There\'s no sequencing to do. :)\"\r\n        end\r\n        operations.store\r\n        return {}\r\n    end\r\n    \r\n    operations.make\r\n    \r\n    stripwells = operations.output_collections[\"Plasmid for Sequencing\"]\r\n    \r\n    \r\n    # label sequencing stripwell(s)\r\n    prepare_stripwells stripwells\r\n    \r\n    # load stripwells with molecular grade water\r\n    load_water stripwells\r\n    \r\n    # load stripwells with stock\r\n    load_stock stripwells\r\n    \r\n    # load stripwells with primer\r\n    load_primer stripwells\r\n    \r\n    # delete stripwells\r\n    stripwells.each { |sw| sw.mark_as_deleted }\r\n    \r\n    operations.store\r\n    \r\n    # create Genewiz order\r\n    genewiz = genewiz_order\r\n    \r\n    # store stripwells in dropbox\r\n    store_stripwells\r\n    \r\n    # save order data in stripwells\r\n    save_order_data genewiz\r\n    \r\n    operations.store(interactive: false)\r\n    return {}\r\n  end\r\n  \r\n\r\n\r\n  def calculate_volumes\r\n    ng_by_length_plas = [500.0, 800.0, 1000.0].zip [6000, 10000]\r\n    ng_by_length_frag = [10.0, 20.0, 40.0, 60.0, 80.0].zip [500, 1000, 2000, 4000]\r\n    samples_list = []\r\n    \r\n    operations.each do |op|\r\n      stock = op.input(PLASMID).item\r\n      length = stock.sample.properties[\"Length\"]\r\n      conc = stock.get(:concentration).to_f || rand(300) / 300\r\n      conc = rand(4000..6000) / 10.0 if debug\r\n      samples_list.push(op.input(\"Plasmid\").sample)\r\n      \r\n      ng_by_length = stock.sample.sample_type.name == \"Plasmid\" ? ng_by_length_plas : ng_by_length_frag\r\n      plas_vol = ng_by_length.find { |ng_l| ng_l[1].nil? ? true : length < ng_l[1] }[0] / conc\r\n      plas_vol = plas_vol < 0.5 ? 0.5 : plas_vol > 12.5 ? 12.5 : plas_vol\r\n      \r\n      water_vol_rounded = (((12.5 - plas_vol) / 0.2).floor * 0.2).round(1)\r\n      plas_vol_rounded = ((plas_vol / 0.2).ceil * 0.2).round(1)\r\n      primer_vol_rounded = 2.5\r\n      \r\n      op.temporary[:water_vol] = water_vol_rounded\r\n      op.temporary[:stock_vol] = plas_vol_rounded\r\n      op.temporary[:primer_vol] = primer_vol_rounded\r\n    end\r\n  end\r\n\r\n  def prepare_stripwells stripwells\r\n    show do\r\n      title \"Prepare stripwells for sequencing reaction\"\r\n      \r\n      stripwells.each_with_index do |sw, idx|\r\n        if idx < stripwells.length - 1\r\n          check \"Label the first well of an unused stripwell with MP#{idx * 12 + 1} and last\r\n                 well with MP#{idx * 12 + 12}\"\r\n        else\r\n          number_of_wells = operations.running.length - idx * 12\r\n          check \"Prepare a #{number_of_wells}-well stripwell, and label the first well with \r\n                 UB#{idx * 12 + 1} and the last well with UB#{operations.running.length}\"\r\n        end\r\n      end\r\n    end\r\n  end\r\n\r\n  def load_water stripwells\r\n    show do\r\n      title \"Load stripwells #{stripwells.map { |sw| sw.id }.join(\", \")} with molecular grade water\"\r\n      \r\n      stripwells.each_with_index do |sw, idx|\r\n        note \"Stripwell #{idx + 1}\"\r\n        table operations.running.select { |op| op.output(\"Plasmid for Sequencing\").collection == sw }.start_table\r\n          .custom_column(heading: \"Well\") { |op| op.output(\"Plasmid for Sequencing\").column + 1 }\r\n          .custom_column(heading: \"Molecular Grade Water (uL)\", checkable: true) { |op| op.temporary[:water_vol] }\r\n          .end_table\r\n      end\r\n    end\r\n  end\r\n\r\n  def load_stock stripwells\r\n    show do\r\n      title \"Load stripwells #{stripwells.map { |sw| sw.id }.join(\", \")} with plasmid stock\"\r\n      \r\n      stripwells.each_with_index do |sw, idx|\r\n        note \"Stripwell #{idx + 1}\"\r\n        table operations.running.select { |op| op.output(\"Plasmid for Sequencing\").collection == sw }.start_table\r\n          .custom_column(heading: \"Well\") { |op| op.output(\"Plasmid for Sequencing\").column + 1 }\r\n          .input_item(PLASMID, heading: \"Stock\")\r\n          .custom_column(heading: \"Volume (uL)\", checkable: true) { |op| op.temporary[:stock_vol] }\r\n          .end_table\r\n      end\r\n    end\r\n  end\r\n\r\n  def load_primer stripwells\r\n    show do\r\n      title \"Load stripwells #{stripwells.map { |sw| sw.id }.join(\", \")} with Primer\"\r\n      \r\n      stripwells.each_with_index do |sw, idx|\r\n        note \"Stripwell #{idx + 1}\"\r\n        table operations.running.select { |op| op.output(\"Plasmid for Sequencing\").collection == sw }.start_table\r\n          .custom_column(heading: \"Well\") { |op| op.output(\"Plasmid for Sequencing\").column + 1 }\r\n          .input_item(PRIMER, heading: \"Primer Aliquot\")\r\n          .custom_column(heading: \"Volume (uL)\", checkable: true) { |op| op.temporary[:primer_vol] }\r\n          .end_table\r\n      end\r\n    end\r\n  end\r\n\r\n  def genewiz_order\r\n    operations.running.each do |op|\r\n        stock = op.input(PLASMID).item\r\n        primer = op.input(PRIMER).sample\r\n        order_name_base = \"#{stock.id}-#{stock.sample.user.name.gsub(/[^a-z]/i, \'_\')}\"\r\n        \r\n        op.temporary[:seq_order_name_wo_primer] = order_name_base\r\n        op.output(SEQ_RESULT).item.associate \"seq_order_name_#{op.output(SEQ_RESULT).column}\".to_sym, (order_name_base + \"-#{primer.id}\")\r\n    end\r\n    \r\n    show_return = {:tracking_num=>\"REPLACE ME!\", :timestamp=>1531758796000}\r\n    while show_return[:tracking_num] == \"REPLACE ME!\" && !debug do\r\n      show_return = show do\r\n        title \"Create a Genewiz order\"\r\n        \r\n        check \"Go the <a href=\'https://clims3.genewiz.com/default.aspx\' target=\'_blank\'>GENEWIZ website</a>, log in with lab account (Username: #{GENEWIZ_USER}, password is #{GENEWIZ_PASS}).\"\r\n        check \"Click Create Sequencing Order, choose Same Day, Online Form, Pre-Mixed, #{operations.running.length} samples, then Create New Form\"\r\n        check \"Enter DNA Name and My Primer Name according to the following table, choose DNA Type to be Plasmid\"\r\n        \r\n        table operations.start_table\r\n          .custom_column(heading: \"DNA Name\") { |op| op.temporary[:seq_order_name_wo_primer] }\r\n          .custom_column(heading: \"DNA Type\") { |op| op.input(PLASMID).sample.sample_type.name == \"Plasmid\" ? \"Plasmid\" : \"Purified PCR\" }\r\n          .custom_column(heading: \"DNA Length\") { |op| op.input(PLASMID).sample.properties[\"Length\"] }\r\n          .custom_column(heading: \"My Primer Name\") { |op| op.input(PRIMER).sample.id }\r\n          .end_table\r\n        \r\n        check \"Click Save & Next, Review the form and click Next Step\"\r\n        check \"Enter Quotation Number MS0721101, click Next Step\"\r\n        check \"Print out the form and enter the Genewiz tracking number below\"\r\n        get \"text\", var: \"tracking_num\", label: \"Enter the Genewiz tracking number\", default: \"REPLACE ME!\"\r\n        check \"Confirm that you properly entered the tracking number above\"\r\n      end\r\n    end\r\n    show_return\r\n  end  \r\n\r\n  def store_stripwells\r\n    show do\r\n      title \"Put all stripwells in the Genewiz dropbox\"\r\n      check \"Cap all of the stripwells.\"\r\n      check \"Wrap the stripwells in parafilm.\"\r\n      check \"Put the stripwells into a zip-lock bag along with the printed Genewiz order form.\"\r\n      check \"Ensure that the bag is sealed, and put it into the Genewiz dropbox.\"\r\n    end\r\n  end\r\n\r\n  def save_order_data genewiz\r\n    order_date = Time.now.strftime(\"%-m/%-d/%y %I:%M:%S %p\")\r\n    operations.each do |op|\r\n      op.set_output_data SEQ_RESULT, :tracking_num, genewiz[:tracking_num]\r\n      op.set_output_data SEQ_RESULT, :order_date, order_date\r\n    end\r\n  end\r\n\r\n  def your_plasmid_sucks bad_ops_by_item, inputs\r\n    show do\r\n      title \"discard contaminated DNA\"\r\n      \r\n      note \"discard the following contaminated DNA stock items: #{bad_ops_by_item.keys.select {|item| item.get(:contaminated) == \"Yes\" }.map { |item| item.id}.to_sentence }\"\r\n    end if bad_ops_by_item.keys.select {|item| item.get(:contaminated) == \"Yes\" }.any?\r\n    \r\n    bad_ops_by_item.each do |item, ops| \r\n      bad_ops_by_item[item].each { |op| op.error :not_enough_volume, \"Plasmid stock  #{item.id} did not have enough volume, or was contaminated. Please make another!\" }\r\n      bad_ops_by_item.except! item\r\n      if item.get(:contaminated) == \"Yes\"\r\n        item.mark_as_deleted\r\n      end\r\n    end\r\n  end\r\nend',12,'OperationType','2018-07-17 23:23:56','2018-07-17 23:23:56',1),(141,'protocol','class Protocol\n  INPUT = \"Bases\"\n  OUTPUT = \"gBlock Fragment\"\n  IDT_USER = Parameter.get(\"IDT User\")\n  IDT_PASS = Parameter.get(\"IDT Password\")\n\ndef main\n    operations.retrieve\n\n    # Setup random sequence\n    if debug\n      operations.running.each do |op|\n        set_fv_parameter op.input(INPUT), generate_random_sequence\n      end\n    end\n    \n    # Prepare to order primer\n    prepare_to_order\n    \n    # Go to the gBlock webpage\n    go_to_gBlock\n    \n    # Validate sequences\n    validate_sequences \n  \n    # Enter gBlock sequences into a table\n    sequence_table\n\n    create_table = Proc.new {|ops|\n      ops.start_table\n        .custom_column(heading: \"Name\", checkable: true) {|op| op.output(OUTPUT).sample.name}\n        .custom_input(:idt_errors, heading: \"Errors\", type: \"string\") {|op| op.temporary[:idt_errors] || \'\'}\n        .end_table.all\n    }\n    \n    # order gBlocks\n    order_gBlocks create_table\n\n    num_errors = operations.running.count {|op| !op.temporary[:idt_errors].strip.empty?}\n    \n    # confirm selection\n    confirm_selection create_table, num_errors\n\n    idt_error_ops = operations.running.select {|op| !op.temporary[:idt_errors].strip.empty?}\n\n    if idt_error_ops.any?\n      remove_errored_entries\n    end\n\n    idt_error_ops.each do |op|\n      op.error :idt_sequence_error, op.temporary[:idt_errors]\n    end\n    \n    # Answer the IDT Biohazard Disclosure\n    answer_disclosure\n    \n    # Finish order\n    data = finish_order\n\n    operations.running.make\n\n    operations.running.each {|op| op.set_output_data(OUTPUT, :order_number, data[:order_number])}\n    operations.running.each {|op| op.set_output_data(OUTPUT, :ng, op.temporary[:amount])}\n    operations.running.store interactive: false\n\n    return {}\n  end\n  \n\n  def set_fv_parameter fv, val\n    op = Operation.find_by_id(fv.parent_id)\n    op.set_property fv.name, val, fv.field_type.role, false, fv.allowable_field_type\n  end\n\n  def generate_random_sequence\n    seq = 200.times.map {\'agtc AGTC\'.chars.sample}.join(\'\')\n  end\n\n  def get_sequence op\n    sequence = op.input(\"Bases\").val\n    sequence = sequence[:original_value] if sequence.is_a?(Hash)\n    sequence = sequence.gsub(/\\s+/, \"\").upcase\n    sequence\n  end\n\n  def prepare_to_order\n    show do\n      title \"Prepare to order primer\"\n\n      check \"Go to the <a href=\'https://www.idtdna.com/site/account\' target=\'_blank\'>IDT website</a>, log in with the lab account. (Username: #{IDT_USER}, password is #{IDT_PASS}).\"\n      warning \"Ensure that you are logged in to this exact username and password!\"\n    end\n  end\n\n  def go_to_gBlock\n    show do\n      title \"Go to gBlock webpage\"\n\n      check \"Go to the <a href=\'https://www.idtdna.com/site/Order/gblockentry\' target=\'_blank\'>gBlock Ordering</a> website.\"\n    end\n  end\n  \n  def validate_sequences \n    operations.running.each do |op|\n      sequence = get_sequence op\n\n      # validate sequence\n      remain = sequence.chars.uniq - \'AGTC\'.chars\n      if remain.include?(\'N\') or remain.include?(\'K\')\n        op.error :invalid_sequence, \"#{remain} are invalid nucleotides. Contact Manager about supporting N or K degenerate bases.\"\n      elsif remain.any?\n        op.error :invalid_sequence, \"#{remain} are invalid nucleotides.\"\n      end\n\n      if sequence.size < 125 or sequence.size > 3000\n        op.error :invalid_sequence_length, \"Only 125-3000 bp are supported. Input sequence was #{sequence.size} bp. \"\n      end\n      op.temporary[:sequence] = sequence\n\n      amount = 0.0\n      if sequence.size >= 125 and sequence.size <= 250\n        amount = 250.0\n      elsif sequence.size >= 251 and sequence.size <= 750\n        amount = 500.0\n      elsif sequence.size >= 751 and sequence.size <= 3000\n        amount = 1000.0\n      end\n      op.temporary[:amount] = amount\n    end\n  end\n  \n  def sequence_table\n    tab = operations.running.map do |op|\n      [op.output(OUTPUT).sample.name, \"<font size=\\\"1\\\">#{op.temporary[:sequence]}</font>\"]\n    end\n    show do\n      title \"Enter gBlock sequences\"\n\n      check \"Click \'Bulk Input\"\n      check \"Select and copy/paste the following table into the \'Bulk Input\' box\"\n      warning \"Please do not select the \'Name\' and \'Sequence\' headers.\"\n      warning \"Be sure that \'Choose a delmiter: Tab/Excel\' is checked\"\n\n      table tab\n      # table here\n    end\n  end\n  \n  def order_gBlocks create_table\n    show_with_input_table(operations.running, create_table) do\n      title \"Order gBlocks\"\n\n      check \"Click add to order\"\n      check \"If any of the entries contain errors, copy and paste the error into the following table. Leave blank if there were no errors.\"\n    end\n  end\n  \n  def confirm_selection create_table, num_errors\n    show_with_input_table(operations.running, create_table) do\n      title \"Confirm selection\"\n\n      warning \"Confirm there were #{num_errors} entries that errored.\"\n      check \"Recheck the website and confirm the error selection.\"\n    end\n  end\n  \n  def remove_errored_entries\n    show do\n      title \"Remove errored entries\"\n  \n      check \"Remove the following entries from the IDT webform by clicking the small trash can on the right-hand side.\"\n  \n      table idt_error_ops.start_table\n              .custom_column(heading: \"Name\", checkable: true) {|op| op.output(OUTPUT).sample.name}\n              .end_table\n    end\n  end\n\n  def answer_disclosure\n    show do\n      title \"Answer the IDT Biohazard Disclosure\"\n\n      check \"Click Add to Order\"\n      check \"Answer the disclosure\"\n      check \"Sign your name and click add to cart.\"\n    end\n  end\n \n  def finish_order\n    data = show do\n      title \"Finish order\"\n\n      check \"Review the shopping cart to double check that you entered correctly. There should be #{operations.running.size} fragments in the cart.\"\n      check \"Click Checkout, then click Continue.\"\n      check \"Enter the payment information.\"\n      # check \"Enter the payment information, click the oligo card tab, select the Card1 in Choose Payment and then click Submit Order.\"\n      check \"Go back to the main page, let it sit for 5-10 minutes, return and refresh, and find the order number for the order you just placed.\"\n\n      get \"text\", var: \"order_number\", label: \"Enter the IDT order number below\", default: 100\n      data\n    end\n  end\nend',16,'OperationType','2018-07-17 23:36:11','2018-07-17 23:36:11',1),(142,'protocol','class Protocol\n  IDT_USER = Parameter.get(\"IDT User\")\n  IDT_PASS = Parameter.get(\"IDT Password\")\n\n  def main\n    operations.retrieve.make\n    \n    # login to idt and prepare to order\n    idt_login\n\n    # make primer table\n    primer_tab = build_primer_table\n\n    # make lists of primers categorized by lengths\n    primers_over_60, primers_over_90  = build_primer_lists\n    \n    # order primers using primer table, and update IDT order numbers for output Primer items\n    show_primer_table primer_tab, primers_over_60, primers_over_90\n    \n    return {}\n  end\n\n\n  def idt_login\n    show do\n      title \"Prepare to order primer\"\n      \n      check \"Go to the <a href=\'https://www.idtdna.com/site/account\' target=\'_blank\'>IDT website</a>, log in with the lab account. (Username: #{IDT_USER}, password is #{IDT_PASS}).\"\n      warning \"Ensure that you are logged in to this exact username and password!\"\n    end\n  end\n  \n  def build_primer_table\n    operations.map do |op|\n      primer = op.output(\"Primer\").sample\n      [primer.id.to_s + \" \" + primer.name, primer.properties[\"Overhang Sequence\"] + primer.properties[\"Anneal Sequence\"]]\n    end\n  end\n  \n  def build_primer_lists\n    operations.each { |op| op.temporary[:length] = (op.output(\"Primer\").sample.properties[\"Overhang Sequence\"] + op.output(\"Primer\").sample.properties[\"Anneal Sequence\"]).length }\n    \n    primers_over_60 = operations.select do |op| \n      length = op.temporary[:length]\n      length > 60 && length <= 90\n    end.map do |op| \n        primer = op.output(\"Primer\").sample\n        \"#{primer} (##{operations.index(op) + 1})\"\n    end.join(\", \")\n    \n    primers_over_90 = operations.select do |op| \n      length = op.temporary[:length]\n      length > 90\n    end.map do |op| \n        primer = op.output(\"Primer\").sample\n        \"#{primer} (##{operations.index(op) + 1})\"\n    end.join(\", \")\n    \n    [primers_over_60, primers_over_90]\n  end\n  \n  def show_primer_table primer_tab, primers_over_60, primers_over_90\n    data = show do\n      title \"Create an IDT DNA oligos order\"\n      \n      warning \"Oligo concentration for primer(s) #{primers_over_60} will have to be set to \\\"100 nmole DNA oligo.\\\"\" if primers_over_60 != \"\"\n      warning \"Oligo concentration for primer(s) #{primers_over_90} will have to be set to \\\"250 nmole DNA oligo.\\\"\" if primers_over_90 != \"\"\n      \n      #check \"Click Custom DNA Oligos, click Bulk Input. Copy paste the following table and then click the Update button.\"\n      \n      check \"Under \\\"Custom DNA Oligos\\\", click \\\"DNA Oligos\\\", then click \\\"Order now\\\", and click \\\"Bulk input\\\". Copy and paste the following table there. \"\n      table primer_tab\n      \n      check \"Click Add to Order, review the shopping cart to double check that you entered correctly. There should be #{operations.length} primers in the cart.\"\n      check \"Click Checkout, then click Continue.\"\n      check \"Enter the payment information, click the oligo card tab, select the Card1 in Choose Payment and then click Submit Order.\"\n      check \"Go back to the main page, let it sit for 5-10 minutes, return and refresh, and find the order number for the order you just placed.\"\n      \n      get \"text\", var: \"order_number\", label: \"Enter the IDT order number below\", default: 100\n    end\n\n    operations.each { |op| op.set_output_data(\"Primer\", :order_number, data[:order_number]) }\n  end\nend',17,'OperationType','2018-07-17 23:36:24','2018-07-17 23:36:24',1),(159,'documentation','This protocol creates a batch of agar plates of indeterminite size, using up 800mL of readied agar to do so.',20,'OperationType','2018-07-18 22:30:06','2018-07-18 22:30:06',1),(160,'protocol','class Protocol\n    \n  def main\n    operations.retrieve.make\n    markers_new = Hash.new { | h, k | h[k] = {} } \n    \n    # group plates + transformed aliquots \n    markers = group_plates_and_aliquots markers_new\n      \n    # tell tech to grab x amount of plates and plate the aliquots\n    # also detract from plate batches\n    calculate_and_operate markers\n    operations.store(io: \"output\", interactive: true)\n    \n    return {}\n  end\n  \n  \n  def name_initials str\n    full_name = str.split\n    begin\n      cap_initials = full_name[0][0].upcase + full_name[1][0].upcase\n    rescue\n      cap_initials = \"\"\n    end\n    return cap_initials\n  end\n  \n  def grab_plates plates, batch_num, ids, k\n    show do\n      title \"Grab #{plates.length} of #{k} plates\"\n      note \"Grab #{plates.length} plates from batch #{batch_num.join(\"and\")}\"\n      check \"Label the top of the plates with your intials, the date, and the following ids: #{ids.join(\", \")}\"\n    end\n  end\n\n  def plate_transformed_aliquots k, aliquots, plates\n    show do \n      title \"Plate transformed E coli aliquots\"\n      check \"Use sterile beads to plate THE ENTIRE VOLUME (~200 uL) from the transformed aliquots (1.5 mL tubes) onto the plates, following the table below.\"\n      warning \"Note the change in plating volume!\"\n      check \"Discard used transformed aliquots after plating.\"\n      table [[\"1.5 mL tube\", \"#{k} Plate\"]].concat(aliquots.zip plates)\n    end\n  end\n  \n  def spin_tubes\n    show do\n      title \"Spin down tubes and resuspend\"\n      check \"Remove the transformed cells in 1.5 mL tubes from the 250 mL flask.\"\n      check \"Centrifuge for 4,000 x g for 1 minute.\"\n      check \"Carefully remove most of the supernatant using a P1000 pipette. Leave 200uL of supernatant in each tube.\"\n      check \" Resuspend the cells in the remaining supernatant by vortexing.\"\n    end\n  end\n     \n  def group_plates_and_aliquots markers_new\n    operations.each do | op | \n      p = op.input(\"Plasmid\").item\n      marker_key = \"LB\"\n      p.sample.properties[\"Bacterial Marker\"].split(/[+,]/).each do |marker|\n        marker_key = marker_key + \" + \" + marker.strip[0, 3].capitalize\n      end\n      \n      if Sample.find_by_name(marker_key)\n        markers_new[marker_key][p] = op.output(\"Plate\").item\n      else\n        show do \n          note \"Sample doesn\'t exist #{marker_key}\"\n        end\n        op.error :no_marker, \"There is no marker associated with this sample, so we can\'t plate it. Please input a marker.\"\n      end\n    end\n    markers_new\n  end  \n  \n  def calculate_and_operate markers\n    markers.each do | k, v| \n      aliquots = []\n      plates = []\n      ids = []\n        \n      v.each do | al, pl|\n        ids.push(\"#{pl.id} \" + name_initials(pl.sample.user.name))\n        aliquots.push(al.id)\n        al.mark_as_deleted\n        plates.push(pl.id)\n        pl.location = \"37 C incubator\"\n      end\n        \n      b = Collection.where(\"data IS NOT NULL\").where(object_type_id: ObjectType.find_by_name(\"Agar Plate Batch\").id).to_a\n                    .keep_if { |b| b.data[12,13][0,5] == \"#{Sample.find_by_name(k).id}\"}[0]\n\n      if b.nil? # no agar plate batches exist\n        raise \"No agar plate batches for #{k} could be found in the Inventory. Pour some plates before continuing (Manager/Pour Plates)\"\n      end\n      batch_num = [b.id]\n      n = b.num_samples\n      num_p = plates.length\n      if n < num_p\n        num_p = num_p - n\n        b.apportion 10, 10\n        b = Collection.where(\"data IS NOT NULL\").where(object_type_id: ObjectType.find_by_name(\"Agar Plate Batch\").id).to_a\n                      .keep_if { |b| b.data[12,13][0,5] ==\"#{Sample.find_by_name(k).id}\"}[0]\n        n = b.num_samples\n        batch_num.push(b.id)\n      end\n          \n        m = b.matrix\n        x = 0\n    \n        (0..m.length-1).reverse_each do |i|\n          (0..m[i].length-1).reverse_each do |j|\n            if m[i][j] != -1 && x < num_p\n              m[i][j] = -1\n              x += 1\n            end\n          end\n        end\n        \n        # Grab and label plates\n        grab_plates plates, batch_num, ids, k\n        \n        # Spin down tubes and resuspend\n        spin_tubes\n        \n        # Plate transformed E. coli aliquots\n        plate_transformed_aliquots k, aliquots, plates\n    end\n  end\nend',8,'OperationType','2018-07-18 22:32:58','2018-07-18 22:32:58',1),(167,'protocol','class Protocol\n  def main\n      \n    debug = false\n\n    operations.retrieve interactive: false\n\n    arrange_gels_by_stripwells operations.reject { |op| op.virtual? }\n\n    # Don\'t use generic operations.make\n    operations.each do |op|\n        op.output(\"Fragment\").make_part(\n            op.input(\"Gel\").collection,\n            op.input(\"Gel\").row,\n            op.input(\"Gel\").column\n        )\n    end\n    \n    gels = operations.map { |op| op.input(\"Gel\").collection }.uniq\n    stripwells = operations.map { |op| op.input(\"Fragment\").collection }.uniq.sort { |sw1, sw2| sw1.id <=> sw2.id }\n    \n    # Find a ladder\n    ladder_100 = Sample.find_by_name(\"100 bp Ladder\")\n    ladder_1k = Sample.find_by_name(\"1 kb Ladder\")\n    dye = Sample.find_by_name(\"6X Loading Dye\")\n    items = [ladder_100.in(\"Ladder Aliquot\").first,\n             ladder_1k.in(\"Ladder Aliquot\").first,\n             Item.where(sample_id: dye.id).reject { |i| i.deleted? }.first]\n    \n    if items.any? { |i| i.nil? }\n        raise \"There are insufficient reagents in the inventory to run a gel. Make sure there is 100 bp Ladder, 1 kp Ladder, and 6X Loading Dye available\"\n    end\n    take items + gels.collect { |i| Item.find_by_id(i.id) } + stripwells.collect { |i| Item.find_by_id(i.id) }, interactive: true\n    \n    setup_power_supply\n    \n    setup_gel_box\n    \n    add_dye stripwells\n    \n    #ONLY DO 100 BP IF THERE IS FRAGMENT W LENGTH < 500 BP\n    add_ladders_to_gel gels, ladder_1k, ladder_100\n\n   \n    # TO DO: Fix loading if ladders exist\n    transfer_result_to_lane\n    \n    start_electrophoresis\n\n    discard_stripwells\n    \n    release items, interactive: true\n    \n    set_timer\n    return {}\n  end\n    \n    # PCR puts stripwells out of operations order. This sorts gel lanes by stripwell to make tables nicer\n    def arrange_gels_by_stripwells ops\n        # get stripwell vals\n        stripwells = ops.map { |op| op.input(\"Fragment\").collection }.uniq.sort { |sw1, sw2| sw1.id <=> sw2.id }\n        sw_size = stripwells.first.object_type.columns\n        wells = ops.map do |op|\n            sw_offset = stripwells.index(op.input(\"Fragment\").collection) * sw_size\n            op.temporary[:sw_val] = sw_offset + op.input(\"Fragment\").column\n            op.temporary[:sw_val]\n        end\n        # show { note \"wells #{wells}\" }\n        \n        # get lane vals\n        gels = ops.map { |op| op.input(\"Gel\").collection }.uniq.sort { |g1, g2| g1.id <=> g2.id }\n        gel_size = gels.first.object_type.rows * gels.first.object_type.columns\n        gel_columns = gels.first.object_type.columns\n        lanes = ops.map do |op| \n            gel_offset = gels.index(op.input(\"Gel\").collection) * gel_size\n            row_offset = op.input(\"Gel\").row * gel_columns\n            gel_offset + row_offset + op.input(\"Gel\").column\n        end\n        # show { note \"lanes #{lanes}\" }\n        \n        # sort lanes by stripwells\n        wells_sorted = wells.sort\n        lanes_sorted = lanes.sort\n        well_to_lane = lanes_sorted.each_with_index.each_with_object({}) do |(l, i), hsh|\n        	hsh[wells_sorted[i]] = l\n        end\n        # show { note \"well_to_lane #{well_to_lane.to_s}\" }\n        \n        lanes_ordered_by_well = wells.map { |well| well_to_lane[well] }\n        # show { note \"lanes_ordered_by_well #{lanes_ordered_by_well}\" }\n        \n        # associate operations with new gel, rows & columns\n        ops.each_with_index do |op, idx|\n            gel_idx = lanes_ordered_by_well[idx] / gel_size\n            lane = lanes_ordered_by_well[idx] - gel_idx * gel_size\n            row = lane / gel_columns\n            column = lane % gel_columns\n            \n            gel_fv = op.input(\"Gel\")\n            gel_fv.set collection: gels[gel_idx]\n            gel_fv.row = row\n            gel_fv.column = column\n            gel_fv.save\n            \n            # show { note \"op #{idx}: col: #{op.input(\"Gel\").collection.id}, row: #{op.input(\"Gel\").row}, column: #{op.input(\"Gel\").column}\" }\n        end\n    end\n    \n    def setup_power_supply\n        show do\n            title \"Set up the power supply\"\n            \n            note  \"In the gel room, obtain a power supply and set it to 80 V and with a 40 minute timer.\"\n            note  \"Attach the electrodes of an appropriate gel box lid to the power supply.\"\n            \n            image \"Items/gel_power_settings.JPG\" \n        end\n    end\n    \n    def setup_gel_box\n        show do\n            title \"Set up the gel box(s).\"\n            \n            check \"Remove the casting tray(s) (with gel(s)) and place it(them) on the bench.\"\n            check \"Using the graduated cylinder, fill the gel box(s) with 200 mL of 1X TAE. TAE should just cover the center of the gel box(s).\"\n            check \"With the gel box(s) electrodes facing away from you, place the casting tray(s) (with gel(s)) back in the gel box(s). The top lane(s) should be on your left, as the DNA will move to the right.\"\n            check \"Using the graduated cylinder, add 50 mL of 1X TAE so that the surface of the gel is covered.\"\n            check \"Remove the comb(s) and place them in the appropriate box(s).\"\n            check \"Put the graduated cylinder back.\"\n            \n            image \"Items/gel_fill_TAE_to_line.JPG\"\n        end  \n    end\n    \n    def transfer_result_to_lane\n        show do \n            title \"Transfer 50 uL of each PCR result into indicated gel lane\"\n            note \"Transfer samples from each stripwell to the gel(s) according to the following table:\"\n            table operations.reject { |op| op.virtual? }.sort { |op1, op2| [op1.input(\"Fragment\").item.id, (op1.input(\"Fragment\").column + 1)] <=> [op2.input(\"Fragment\").item.id, (op2.input(\"Fragment\").column + 1)] }.extend(OperationList).start_table\n                .input_collection(\"Fragment\", heading: \"Stripwell\")\n                .custom_column(heading: \"Well Number\") { |op| (op.input(\"Fragment\").column + 1)  }\n                .input_collection(\"Gel\", heading: \"Gel\")\n                .custom_column(heading: \"Gel Row\") { |op| (op.input(\"Gel\").row + 1) }\n                .custom_column(heading: \"Gel Column\", checkable: true) { |op| (op.input(\"Gel\").column + 1) }\n            .end_table\n        end\n    end\n    \n    def start_electrophoresis\n        show do\n            title \"Start Electrophoresis\"\n            note \"Carefully attach the gel box lid(s) to the gel box(es). Attach the red electrode to the red terminal of the power supply, and the black electrode to the neighboring black terminal. Hit the start button on the gel boxes.\"\n            note \"Make sure the power supply is not erroring (no E* messages) and that there are bubbles emerging from the platinum wires in the bottom corners of the gel box.\"\n            image \"Items/gel_check_for_bubbles.JPG\"\n        end\n    end\n    \n    def discard_stripwells\n        show do \n            title \"Discard Stripwells\"\n            note \"Discard all the empty stripwells\"\n            operations.each do |op|\n                op.input(\"Fragment\").item.mark_as_deleted\n            end\n        end\n    end\n    \n    def set_timer\n        show do\n            title \"Set a timer\"\n            \n            check \"When you get back to your bench, set a 40 minute timer.\" \n            check \"When the 40 minute timer is up, grab a lab manager to check on the gel. The lab manager may have you set another timer after checking the gel.\"\n        end\n    end\n    \n    def add_dye stripwells\n        show do \n            title \"Add Dye to Each Well\"\n            stripwells.each do |s|\n                note \"Add 10 uL dye to stripwell #{s.id} from wells #{s.non_empty_string}\"\n            end\n        end\n    end\n    \n    def add_ladders_to_gel gels, ladder_1k, ladder_100\n        gels.each do |gel|\n            gel.set 0,0,ladder_1k.id\n            gel.set 0,1, ladder_100.id\n            gel.set 1,0, ladder_1k.id\n            gel.set 1,1, ladder_100.id\n            show do\n                title \"Add Ladders to Gel\"\n                note \"Pipette 10 uL of the 1 kb ladder to positions (1,1) and (2,1) of gel #{gel.id}\"\n                note \"Pipette 10 uL of the 100bp ladder to positions (1,2) and (2,2) of gel #{gel.id}\"\n            end\n        end\n    end\nend\n',3,'OperationType','2018-07-18 23:08:34','2018-07-18 23:08:34',1),(175,'documentation','Temporary protocol to allow for comp cell batches until a flexible \'Make media\' protocol is finished',23,'OperationType','2018-07-18 23:23:13','2018-07-18 23:23:13',1),(188,'protocol','class Protocol\n\n  ORDER = \"Plasmid\"\n  GENEWIZ_USER = Parameter.get(\"Genewiz User\")\n  GENEWIZ_PASS = Parameter.get(\"Genewiz Password\")\n  AQ_URL = Parameter.get(\"URL\")\n\n  def main\n    add_debug_defaults\n    tracking_num = ensure_same_tracking_number\n    return {} if tracking_num.nil?\n    \n    operations.retrieve interactive: false\n    \n    return {} if !check_if_results_arrived(tracking_num)\n    upload_batched_results tracking_num\n    upload_individual_results tracking_num\n    \n    operations.each do |op|\n      # Query user for next step\n      op.plan.associate \"Item #{op.temporary[:seq_name].split(\'-\')[0]} sequencing ok?\", \"yes - discard plate, and mark plasmid stock as sequence verified; resequence - keep plate and plasmid stock; no - discard plasmid stock\"\n    end\n    \n    add_clean_up_sequencings\n    notify_users\n    \n    return {}\n  end\n  \n  \n  def add_debug_defaults\n    if debug\n      operations.each do |op|\n        sw = op.input(ORDER).item\n        sw.associate :tracking_num, [12345, 23523].sample if !sw.get(:tracking_num)\n        \n        key = \"seq_order_name_#{op.input(ORDER).column}\"\n        if !sw.associations.any? { |k, v| k == key }\n          stock = Item.where(object_type_id: ObjectType.find_by_name(\"Plasmid Stock\")).all.sample\n          primer = Item.where(object_type_id: ObjectType.find_by_name(\"Primer Stock\")).all.sample.sample\n          show { note \"#{stock} --- #{primer}\"}          \n          sw.associate key.to_sym, \"#{stock.id}-#{stock.sample.user.name}-#{primer.id}\"\n        end\n      end\n    end\n  end\n  \n  def ensure_same_tracking_number\n    ops_by_num = Hash.new { |h, k| h[k] = [] }\n    operations.each { |op| ops_by_num[op.input(ORDER).item.get(:tracking_num)].push op }\n    \n    if ops_by_num.keys.one?\n      return operations.first.input(ORDER).item.get :tracking_num\n    else\n      show do\n        title \"Not all tracking numbers match\"\n        \n        note \"All operations have been set to pending. Please consider the suggested batching option.\"\n        \n        ops_by_num.each do |num, ops|\n          note \"Tracking number: #{num}\"\n          \n          table ops.extend(OperationList).start_table\n            .custom_column(heading: \"Operation ID\") { |op| op.id }\n            .custom_column(heading: \"Plan ID\") { |op| op.plan.id }\n          .end_table\n        end\n      end\n      \n      operations.each { |op| op.change_status \"pending\" }\n      \n      return nil\n    end\n  end\n\n  def check_if_results_arrived tracking_num\n    results_info = show do\n      title \"Check if Sequencing results arrived?\"\n      \n      check \"Go the Genewiz website, log in with lab account (Username: #{GENEWIZ_USER}, password is #{GENEWIZ_PASS}).\"\n      note \"In Recent Results table, click Tracking Number #{tracking_num}, and check if the sequencing results have shown up yet.\"\n      \n      select [\"Yes\", \"No\"], var: \"results_back_or_not\", label: \"Do the sequencing results show up?\", default: 0\n    end\n    \n    if results_info[:results_back_or_not] == \"No\"\n        show do \n            title \"No Results\"\n            note \"Sequencing results are not yet available, wait a while and then run this job again.\"\n        end\n        operations.each do |op| \n            op.change_status \"pending\"\n        end\n        return false\n    end\n    \n    return true\n  end\n\n\n# USERS DO NOT NEED FULL BATCH OF SEQUENCING RESULTS, THEY ONLY WANT THEIR OWN RESULTS ASSOCIATED WITH THEIR PLAN\n  def upload_batched_results tracking_num\n    show do\n      title \"Download Genewiz Sequencing Results zip file\"\n      \n      note \"Click the button \'Download All Selected Trace Files\' (Not Download All Sequence Files), which should download a zip file named #{tracking_num}-some-random-number.zip.\"\n    #   note \"Upload the #{tracking_num}_ab1.zip file here.\"\n      \n    #   upload var: \"sequencing_results\"\n    end\n    \n    # uploads = sequencing_uploads_zip[:sequencing_results]\n    # if uploads\n    #   u = Upload.find(uploads.first[:id])\n    #   operations.each do |op|\n    #       op.plan.associate \"Order #{tracking_num} batched sequencing results\", \"Fresh out of the oven!\", u\n    #       op.input(\"Plasmid\").item.associate \"Order #{tracking_num} batched sequencing results\", \"Fresh out of the oven!\", u\n    #   end\n    # end\n  end  \n  \n  def upload_individual_results tracking_num\n    operations.each { |op| op.temporary[:upload_confirmed] = false }\n    \n    5.times do\n      ops = operations.select { |op| !op.temporary[:upload_confirmed] }\n      break if ops.empty?\n      ops.each { |op| op.temporary[:seq_name] = op.input(ORDER).item.get \"seq_order_name_#{op.input(ORDER).column}\".to_sym }\n      \n      sequencing_uploads = show do\n        title \"Upload individual sequencing results\"\n        \n        note \"Unzip the downloaded zip file named #{tracking_num}_ab1.zip.\"\n        note \"If you are on a Windows machine, right click the #{tracking_num}-some-random-number.zip file, click Extract All, then click Extract.\"\n        note \"Upload all the unzipped ab1 file below by navigating to the upzipped folder.\"\n        note \"You can click Command + A on Mac or Ctrl + A on Windows to select all files.\"\n        note \"Wait until all the uploads finished (a number appears at the end of file name).\"\n        \n        upload var: \"sequencing_results\"\n        \n        table ops.start_table\n          .custom_column(heading: \"Expected Filenames\") { |op| op.temporary[:seq_name] + \".ab1\" }\n        .end_table\n      end\n      \n      # TODO remove hacky way and replace with correct way\n      op_to_file_hash = match_upload_to_operations ops, :seq_name, job_id=self.jid\n      op_to_file_hash.each do |op, u|\n          op.plan.associate \"#{op.input(ORDER).sample.name} in Item #{op.temporary[:seq_name]} sequencing results\", \"How do they look?\", u\n          stock = Item.find(op.temporary[:seq_name].split(\'-\')[0].to_i)\n          stock.associate \"Item #{op.temporary[:seq_name]} sequencing results\", \"How do they look?\", u\n          if stock.get(:from)\n              overnight = Item.find(stock.get(:from))\n              overnight.associate \"Item #{op.temporary[:seq_name]} sequencing results\", \"How do they look?\", u\n              if overnight.get(:from)\n                  gs = Item.find(overnight.get(:from))\n                  gs.associate \"Item #{op.temporary[:seq_name]} sequencing results\", \"How do they look?\", u if gs.object_type.name.include? \"Glycerol Stock\"\n              end\n          end\n          \n          op.temporary[:upload_confirmed] = u.present?\n      end\n    end\n  end\n\n  # method that matches uploads to operations with a temporary[filename_key]\n  def match_upload_to_operations ops, filename_key, job_id=nil, uploads=nil\n      def extract_basename filename\n          ext = File.extname(filename)\n          basename = File.basename(filename, ext)\n      end\n      \n      op_to_upload_hash = Hash.new\n      uploads ||= Upload.where(\"job_id\"=>job_id).to_a if job_id\n          if uploads\n              ops.each do |op|\n                  upload = uploads.select do |u|\n                      basename = extract_basename(u[:upload_file_name])\n                      basename.strip.include? op.temporary[filename_key].strip\n                  end.first || nil\n                  op_to_upload_hash[op] = upload\n              end\n          end\n      op_to_upload_hash\n  end\n  \n  # resolve plasmid stock and associated plate based on user feedback\n  def add_clean_up_sequencings\n      operations.each do |op|\n          if op.plan\n              stock = Item.find(op.temporary[:seq_name].split(\'-\')[0].to_i)\n              overnight = Item.find(stock.get(:from)) if stock.get(:from)\n              plate = Item.find(overnight.get(:from)) if overnight && overnight.get(:from)\n              \n              # Ensure no Clean Up Sequencing operation exists for this plasmid stock\n              cus_ops = op.plan.operations.select { |op| op.name == \"Clean Up Sequencing\" }\n              if cus_ops.map { |op| op.input(\"Stock\").item }.exclude?(stock)\n                  # Make new Clean Up Sequencing for this stock and associated plate\n                  ot = OperationType.find_by_name(\"Clean Up Sequencing\")\n                  new_op = ot.operations.create(\n                      status: \"waiting\",\n                      user_id: op.user_id\n                  )\n                  op.plan.plan_associations.create operation_id: new_op.id\n              \n                  aft = ot.field_types.find { |ft| ft.name == \"Stock\" }.allowable_field_types[0]\n                  new_op.set_property \"Stock\", stock.sample, \"input\", false, aft\n                  new_op.input(\"Stock\").set item: stock\n                  \n                  aft = ot.field_types.find { |ft| ft.name == \"Plate\" }.allowable_field_types[0]\n                  new_op.set_property \"Plate\", stock.sample, \"input\", false, aft\n                  new_op.input(\"Plate\").set item: plate\n                  \n                  op.plan.reload\n                  new_op.reload\n              end\n          end\n      end\n  end\n  \n  def notify_users\n      user_to_op = Hash.new { |hash, key| user_to_op[key] = [] }\n      operations.each do |op|\n        user_to_op[op.user].push(op)\n      end\n      \n      user_to_op.each do |user, oplist|\n          plans = oplist.map { |op| op.plan }.uniq\n          subject = \"Sequencing Results Ready\"\n          message = \"<p>Hello #{user.name},<br>You have sequencing results ready in Aquarium. Please check your results, and be sure to mark whether your items are verified or not on the planner page in order for your #{\"plan\".pluralize(plans.length)} to move along.\"\n          plans.each do |plan|\n            message += \"<br><a href=\'#{AQ_URL}/launcher?plan_id=#{plan.id}\'>#{plan.id} - #{plan.name}</a>\"\n          end\n          message += \"</p> <p>Thanks!<br> </p> <p>This is an automated message</p>\"\n          \n          user.send_email subject, message unless debug\n      end\n  end\nend',13,'OperationType','2018-07-18 23:37:16','2018-07-18 23:37:16',1),(189,'protocol','class Protocol\n\n  def labor_rate\n    Parameter.get_float(\'labor rate\')\n  end\n  \n  def main\n    if !operations.one?\n      show do\n        title \"Too many batched!\"\n        \n        note \"Right now, this protocol only supports one Direct Purchase at a time. Please re-batch in jobs of one.\"\n      end\n      \n      return {}\n    end\n    \n    operations.first.plan.budget_id = 123 \n    \n    \n    @object_types = ObjectType.all\n    @user = operations.first.user\n    user = @user # Can\'t put @user in show, becuase it would refer to the wrong object\n    show do\n        note \"#{operations.first.plan.budget_id}\"\n    end\n\n    result = show do\n      title \"Choose a budget\"\n      note \"User: #{user.name} (#{user.login})\"\n      select user.budget_info.collect { |bi| bi[:budget].name }, var: \"choice\", label: \"Choose a budget\", default: 0\n      note \"#{operations.first.plan.budget_id}\"\n    end\n    \n    @budget = Budget.find_by_name(result[:choice])\n    @overhead = Parameter.get_float(\"markup rate\")\n    operations.first.plan.budget_id = @budget.id\n    operations.first.plan.save\n    show do\n        note \"#{operations.first.plan.budget_id}\"\n    end\n\n\n    @transactions = []\n    \n    again = true\n    \n    while again \n    \n      result = show do\n        title \"Select Category\"\n        note \"Basics: tubes, tip boxes, ...\"\n        note \"Samples: media, ...\"\n        note \"Batched: Gibson Aliquots, plates, ...\"\n        select [ \"Basics\", \"Samples\", \"Batched\" ], var: \"choice\", label: \"Choose something\", default: 0\n      end\n      \n      case result[:choice]\n        when \"Basics\"then basic_chooser\n        when \"Samples\" then sample_chooser \n        when \"Batched\" then batched_chooser\n      end\n      \n      tab = [ [ \"Description\", \"Amount\" ] ]\n      tab += @transactions.collect do |t| \n        [\n          t[:description],\n          currency((1 + @overhead) * t[:amount])\n        ]\n      end\n      \n      result = show do\n        title  \"Summary\"\n        table tab if tab.length > 1 \n        note \"No purchases made\" unless tab.length > 1\n        select [ \"No\", \"Yes\" ], var: \"again\", label: \"Would you like to make another purchase?\", default: 0\n      end\n    \n      again = ( result[:again] == \"Yes\" )\n      \n    end\n    \n    operations.first.associate :transactions, @transactions\n    \n    return {}\n   end\n\n  def choose_object_from objects, number=false\n    result = show do\n      title \"Choose Object\"\n      select objects.collect { |ot| ot.name }, var: \"choice\", label: \"Choose object:\", default: 0\n      get \"number\", var: \"n\", label: \"How many?\", default: 5 if number\n    end\n\n    return objects.find { |b| b.name == result[:choice] } unless number\n    return [ objects.find { |b| b.name == result[:choice] }, result[:n] ] if number\n  end\n  \n  ###############################################################################################################\n  def basic_chooser \n    \n    basics = @object_types.select { |ot| basic? ot }      \n    ot = choose_object_from basics\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n\n    vol = {}\n  \n    m = ot.data_object[:materials]\n    l = ot.data_object[:labor]\n    u = ot.data_object[:unit] \n    vol[:n] = 1\n \n    vol = show do\n      title \"Choose Amount\"\n      get \"number\", var: \"n\", label: \"How many #{u.pluralize} of #{ot.name}?\", default: 5\n    end\n\n    message = \"Purchase #{vol[:n]} #{ot.name.pluralize}\"\n    if confirm message, currency((1+@overhead) * ((m* vol[:n])+(l * labor_rate* vol[:n])) ) \n      transaction = make_purchase message, m*vol[:n], l*vol[:n]\n    end        \n    \n  end\n\n  ###############################################################################################################\n  def sample_chooser \n   \n    samples = @object_types.select { |ot| sample? ot }   \n    ot = choose_object_from samples\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n\n    result = show do\n      title \"Choose Sample\"\n      select ot.data_object[:samples].collect { |s| s[:name] }, var: \"choice\", label: \"Choose sample\", default: 2\n    end\n    \n    descriptor = ot.data_object[:samples].find { |d| d[:name] == result[:choice] }\n    m = descriptor[:materials]\n    l = descriptor[:labor] \n    u = descriptor[:unit]\n    s = descriptor[:name] \n    vol = {}\n\n    items = Sample.find_by_name(s).items.reject { |i| i.deleted? }.reject {|i| i.object_type.name != ot.name }\n    \n    if items.length > 0\n      item = choose_item items, \"Choose #{ot.name} of #{s}\"\n\n      if ot.name.include?(\"Agar\")\n        vol[:n] = descriptor[:total_volume]\n      else\n        vol = show do\n          title \"Choose Volume\"\n          get \"number\", var: \"n\", label: \"How many #{u.pluralize} of #{s}?\", default: 5 \n          select [\"No\", \"Yes\"], var: \"delete\", label: \"Are you purchasing the whole container or is the container now empty?\", default: \"No\"\n        end\n      end\n\n\n      cost = currency((1+@overhead)*((m* vol[:n])+(l * labor_rate* vol[:n]))) \n      message = \"Purchase #{ot.name} of #{s}, item #{item.id}\"\n      if confirm message, cost\n        take [item]\n        transaction = make_purchase message, m*vol[:n], l*vol[:n]\n        release [item]\n        if (descriptor[:delete] || vol[:delete] == \"Yes\")\n          item.mark_as_deleted\n        end\n      end\n    else\n      error \"There are no items of #{ot.name}/#{s} in stock\"\n    end \n  end    \n  ###############################################################################################################\n  def batched_chooser \n\n    collections = @object_types.select { |ot| batched? ot }\n    ot = choose_object_from collections\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n  \n    result = show do\n      title \"Choose sample type\" \n      select ot.data_object[:samples].collect { |s| s[:name] }, var: \"choice\", label: \"Choose sample\", default: 0\n    end\n  \n    descriptor = ot.data_object[:samples].find { |d| d[:name] == result[:choice] }\n    m = descriptor[:materials]\n    l = descriptor[:labor] \n    cost = currency((1+@overhead)*(m+(l*labor_rate)))\n  \n    s = Sample.find_by_name(descriptor[:name])\n    collections = ot.items.reject { |i| i.deleted? }.collect { |i| collection_from i }\n    # filter out collections based on user\'s sample input\n    collections.reject! { |c| c.matrix[0][0] != s.id }\n    cids = collections.collect { |c| c.id }\n  \n    if cids.length > 0\n  \n      result = show do \n        title \"Choose #{ot.name} and number of #{s.name.pluralize} (#{cost} each)\"\n        table [ [ \"id\", \"Location\", \"Number of Samples\" ] ] + (collections.collect { |i| [ \"#{i}\", i.location, i.num_samples ] } )\n        select cids, var: \"id\", label: \"Choose collection\", default: 0\n        get \"number\", var: \"n\", label: \"How many #{s.name.pluralize}?\", default: 2\n      end\n      \n      collection = collections.find { |c| c.id == result[:id].to_i }\n      \n      n = [ collection.num_samples, [ 1, result[:n]].max ].min\n      total_cost = currency((1+@overhead)*(n*m+(n*l* labor_rate)))\n      message = \"Purchase #{n} #{s.name.pluralize} from #{ot.name} #{collection.id}\"\n      \n      if confirm message, total_cost \n        take_samples collection, n\n        transaction = make_purchase message, n*m, n*l\n        release [collection]\n        if collection.num_samples == 0\n          collection.mark_as_deleted\n        end\n      end    \n    else\n      error \"There are no #{ot.name} in stock\"\n    end\n  end\n\n  def take_samples collection, n\n   \n    m = collection.matrix\n    x = 0\n  \n    (0..m.length-1).reverse_each do |i|\n      (0..m[i].length-1).reverse_each do |j|\n        if m[i][j] != -1 && x < n\n          m[i][j] = -1\n          x += 1\n        end\n      end\n    end\n  \n    collection.matrix = m\n    collection.save\n    take [collection]\n    \n  end\n\n  def error msg, details=nil\n    show do \n      title msg\n      note details if details\n      note \"Please report this problem to a BIOFAB lab manager.\"\n    end      \n  end\n\n  def confirm message, cost\n    result = show do \n      title message\n      note \"Cost: #{cost}\"\n      select [ \"Ok\", \"Cancel\" ], var: \"choice\", label: \"Ok to purchase?\", default: 0\n    end\n    return (result[:choice] == \"Ok\")\n  end\n\n  def choose_item items, message\n    result = show do \n      title message\n      note \"Please choose which item you would like to use: \"\n      select items.collect { |i| i.id }, var: \"choice\", label: \"Choose item\", default: 0\n    end\n    Item.find(result[:choice])          \n  end\n\n\n  def make_purchase description, mat, lab\n    transaction = {\n      description: description,\n      amount: mat,\n    }\n    \n    @transactions << transaction\n    \n    transaction\n  end\n\n  def valid_sample_descriptor s\n    val = s[:name]      && s[:name].class == String &&\n          s[:materials] && ( s[:materials].class == Float || s[:materials].class == Fixnum ) &&\n          s[:labor]     && ( s[:labor].class == Float     || s[:labor].class == Fixnum ) && \n          s[:unit]      && s[:unit].class == String &&\n          s[:total_volume] && (s[:total_volume].is_a?(Integer))\n    #error(\"Bad descriptor\", s.to_s) unless val #comment this out so user doesn\'t see it\n    val\n  end\n\n  def basic? ot\n    ot.handler != \"sample_container\" && ot.handler != \"collection\"  &&\n    ot.data_object[:materials] && ot.data_object[:labor] && ot.data_object[:unit]     \n  end\n\n  def sample? ot\n    ot.handler == \"sample_container\" && ot.data_object[:samples] && \n    ot.data_object[:samples].each { |s| return nil unless valid_sample_descriptor s }\n  end\n\n  def batched? ot\n    ot.handler == \"collection\" && ot.data_object[:samples] && \n    ot.data_object[:samples].each { |s| return nil unless (s[:materials] && s[:labor] && s[:unit]) }\n  end\n\n  def currency num\n    ActionController::Base.helpers.number_to_currency num\n  end  \n\nend\n',21,'OperationType','2018-07-18 23:43:40','2018-07-18 23:43:40',1),(190,'protocol','needs \"Cloning/StandardCloning\"\n\nclass Protocol\n    \n    include StandardCloning\n\n    def overnight_steps(ops, ot)\n        ops.retrieve.make\n        \n        show do\n            title \"Label and load overnight tubes\"\n            note \"In the Media Bay, collect #{ops.length} 125mL flasks\"\n            note \"Write the overnight id on the corresponding tube and load with the correct media type.\"\n            table ops.start_table\n              .custom_column(heading: \"Media\") { |op| op.input(\"Media\").sample.name }\n              .custom_column(heading: \"Quantity\") { |op| \"25 mL\" }\n              .output_item(\"Overnight\", checkable: true)\n              .end_table\n        end\n    \n        show {\n            title \"Inoculation from #{ot}\"\n            note \"Use 10 l sterile tips to inoculate colonies from plate into 125 mL flask according to the following table.\" \n            check \"Mark each colony on the plate with corresponding overnight id. If the same plate id appears more than once in the table, inoculate different isolated colonies on that plate.\" \n            table ops.start_table\n              .input_item(\"Strain\", heading: ot)\n              .custom_column(heading: \"#{ot} Location\") { |op| op.input(\"Strain\").item.location }\n              .output_item(\"Overnight\", checkable: true)\n              .end_table      \n        } \n    end\n\n  def main\n      \n    operations.retrieve(interactive: false)\n    \n    overnight_steps operations, \"Agar Plate\"\n    \n    \n    operations.running.each do |op|\n        op.output(\"Overnight\").item.move \"37 C shaker incubator\"\n    end\n    \n    operations.store\n    \n    return {}\n\n  end \n  \nend ',22,'OperationType','2018-07-18 23:44:14','2018-07-18 23:44:14',1),(195,'protocol','needs \"Standard Libs/Centrifuge\"\nrequire \'enumerator\'\nclass Protocol\n  include Centrifuge\n  \n  #protocol run\n  def main\n\n    operations.retrieve interactive: false\n    operations.make\n    \n    warm_LB\n    \n    show do \n        title \"wait while LB warms\"\n        timer initial: { hours: 1, minutes: 0, seconds: 0}\n    end\n\n    # much of the preparation is done in this method\n    first_innoculate\n    \n    # allow some time for culture growth, then make sure all culture flasks are above 0.04 before continuing\n    show do \n        title \"wait while culture grows\"\n        timer initial: { hours: 0, minutes: 45, seconds: 0}\n    end\n    operations.each do |op|\n        op.temporary[:good_OD?] = check_OD_initial op\n    end\n    low_od_ops = operations.reject{ |op| op.temporary[:good_OD?] }\n    sufficient_od_ops = operations.select { |op| op.temporary[:good_OD?] }\n    \n    # for the ops with cultures that were measured >= .04 OD, put them in tubes on ice\n    # transfer_to_tubes sufficient_od_ops if sufficient_od_ops.any? \n    # !! This is now instead done inside the centrifuge_resuspend_cycle method\n    \n    # for the ops with cultures that were measured < .04 OD, wait 20 min for extra growth and remeasure\n    while(low_od_ops.any?) do\n        show do \n            title \"OD too low, additional grow time required\"\n            timer initial: { hours: 0, minutes: 20, seconds: 0}\n        end\n        low_od_ops.each do |op|\n            op.temporary[:good_OD?] = check_OD_initial op\n        end\n        low_od_ops = operations.reject{ |op| op.temporary[:good_OD?] }\n        sufficient_od_ops = operations.select { |op| op.temporary[:good_OD?] }\n        # transfer_to_tubes sufficient_od_ops if sufficient_od_ops.any?\n    end\n\n    \n    # at this point, all cultures are chilled and ready for staggered centrifuge cycling\n    opts = Hash.new()\n    opts[:items] = operations.map { |op| op.input(\"Overnight\").item}\n    opts[:start_vol] = 800\n    opts[:tube_vol] = 225\n    opts[:centrifuge_slots] = 4\n    opts[:cycles] = [\n                      {cent_temp: 4, cent_rpm: 2500, cent_time: 15, sus_media: \"DI water\", sus_volume: 200, combine: false},\n                      {cent_temp: 4, cent_rpm: 2500, cent_time: 20, sus_media: \"10% Glycerol\", sus_volume: 100, combine: true},\n                      {cent_temp: 4, cent_rpm: 2500, cent_time: 20, sus_media: \"10% Glycerol\", sus_volume: 8, combine: true},\n                      {cent_temp: 4, cent_rpm: 2500, cent_time: 20, sus_media: \"GYT\", sus_volume: 1.6, combine: false}\n                    ]\n    opts[:cold] = true\n    opts[:cb_extra_instructions] = \"callback\"\n    # variablize_options opts\n    centrifuge_resuspend_cycle(opts)\n    \n    \n    \n    \n    #at this point all operations have undergone 4 centrifuge-resuspend cycles\n    #The only thing left to do is check the optical density,\n    #dilute the cultures if necessary \n    #aliquot finished cultures, and label produced batches\n    \n    operations.each do |op|\n        #OD_value will be nil if the OD is acceptable\n        op.temporary[:OD_value] = check_OD_post op\n    end\n    high_od_ops = operations.reject{ |op| op.temporary[:OD_value].nil? }\n\n    # for the ops with cultures that were measured <= .1 OD, dilute\n    while(high_od_ops.any?) do\n        \n        #dilute cultures down to acceptable density\n        culture_dilution high_od_ops\n        \n        #remeasure OD of diluted cultures\n        make_GYT_tubes high_od_ops.length\n        high_od_ops.each do \n            #OD_value will be nil if the OD is acceptable\n            op.temporary[:OD_value] = check_OD_post op\n        end \n        high_od_ops = operations.reject{ |op| !op.temporary[:OD_value].nil? }\n    end\n    \n    operations.each do |op|\n        #put resulting comp cell cultures into 40ul aliquots by batch\n        aliquot_cultures op\n        \n        #label each batch with strain name, date, your initials, and item ID; store in the m80\n        label_and_store_batches op\n    end\n    clean_up\n    \n    operations.each do |op|\n        op.input(\"Overnight\").item.mark_as_deleted\n        op.input(\"Water\").item.mark_as_deleted\n        op.input(\"Glycerol\").item.mark_as_deleted\n    end\n    \n    #nothing needs to be stored here, because all outputs have been stored and all inputs have been deleted    \n    \n    return {}\n  end\n  \n  #retrieves all the LB bottles needed and immerse them in heat bath\n  def warm_LB\n    agar_items = [];\n    operations.length.times do\n      agar = Item.where(sample_id: Sample.find_by_name(\"LB\"), object_type_id: ObjectType.find_by_name(\"800 mL Liquid\"))\n                  .where(\"location != ?\", \"deleted\").find {|i| !agar_items.member?(i)}\n      if agar.nil?\n        raise \"not enough 800 mL LB bottles available\" \n      end\n      agar_items.push agar\n    end\n    take agar_items\n    #the 800ml LBs will each be completely used up\n    agar_items.each { |i| i.mark_as_deleted }\n    \n    show do\n      title \"Place LB in heat bath.\"\n      note \"Set heat bath to 37C\"\n      note \"Once temperature reaches 37C, immerse all the LB bottles in beads\"\n    end\n  end\n  \n  #transfer overnight to 2L flask, add glycerol, label 2L flask with short id,  label 4 225ml tubes with same short id for each op\n  def first_innoculate\n    show do \n      title \"Grab Inoculation ingredients\"\n      check \"grab #{operations.length} 2000mL  #{\"flask\".pluralize(operations.length)}\"\n      check \"grab #{operations.length} LB  #{\"bottle\".pluralize(operations.length)} from heat bath\"\n      check \"grab  #{\"overnight\".pluralize(operations.length)}: #{operations.map { |op| op.input(\"Overnight\").item}.to_sentence} from the 37C shaker incubater\"\n      check \"grab #{operations.length * 4} 225mL tubes and place in freezer.\"\n    end\n    \n    operations.retrieve interactive: false\n    \n    show do \n        title \"Add LB, overnight, and label\"\n        warning \"Tilt both bottles for sterile pouring during all transfers\"\n        note \"NOTE: If you are confident with this protocol, and you are only making one batch then all future labeling instructions can be safely skipped.\"\n        note \"add one full bottle of liquid LB to each 2000 mL flask\"\n        note \"label the 2000mL #{ \"flask\".pluralize(operations.length) } as #{operations.map { |op| op.input(\"Overnight\").item.id}.to_sentence}\"\n        \n        note \"Transfer overnights to 2000mL flasks according to the following table\"\n        table operations.start_table\n                    .input_item(\"Overnight\")\n                    .custom_column(heading: \"Flask ID\") { |op| op.input(\"Overnight\").item.id }\n                    .end_table \n\n        note \"it is not necessary to pour out all overnight foam\"\n    end\n    \n    show do \n        title \"Return things\"\n        note \"Return 2000mL #{\"flask\".pluralize(operations.length)} to the 37C shaker incubator\"\n        note \"bring empty baffled #{\"flask\".pluralize(operations.length)} and 800mL  #{\"bottle\".pluralize(operations.length)} to dishwasher\"\n    end\n    \n    show do \n        title \"Prepare for spins\"\n        note \"Set large centrifuge to 4C\"\n        note \"Make sure you have #{operations.length * 4} 225mL tubes in freezer\"\n        note \"Find #{operations.length} bottles of 500mL 10% glycerol and 1L sterile DI water, and place in fridge for later use\"\n    end\n  end\n  \n  # get ice from bagely and transfer the cultures from large flasks into the corresponding chilled centrifuge tubes\n  def transfer_to_tubes ops\n    show do \n      title \"Go to Bagley to get ice (Skip if you already have ice)\"\n      note \"Walk to ice machine room on the second floor in Bagley with a large red bucket, fill the bucket  full with ice\"\n      note \"If unable to go to Bagley, use ice cubes to make a water bath (of mostly ice) or use the chilled aluminum bead bucket (if using aluminum bead bucket place it back in freezer between spins)\"\n    end\n\n    show do \n      title \"Transfer culture to chilled centrifuge tubes\"\n      note \"grab the 225 mL tubes from freezer labeled as: #{ops.map { |op| op.temporary[:centri_ID] }.to_sentence(last_word_connector: \", or \")}\"\n      note \"Immerse the 225 mL tubes in the ice bath\"\n      note \"grab the following 2000 mL cultures from shaker/incubator: #{ops.map { |op| op.temporary[:centri_ID] }.to_sentence}\"\n      note \"Carefully pour 200 mL of culture into each centrifuge tube with the same label, keeping tubes immersed in ice as much as possible\"\n      note \"bring empty 2000 mL #{\"flask\".pluralize(operations.length)} to dishwashing station\"\n    end\n  end\n  \n  # While waiting for final centrifuge to finish, instructs the tech to prepare bench for aliquoting and tidy up \n  def prep_and_clean\n    show do\n      title \"While tubes are centrifuging:\"\n      note \"Place an appropriate amount of aluminum tube racks on an ice block, arrange open, empty, chilled 0.6 mL tubes in every other well, and place whole structure in freezer. Freeze an appropriate amount of additional unracked tubes as well\" \n      note \"Pour water out of ice bucket, and fill a smaller bucket with remaining ice.\"\n      note \"Move P1000 pipette, pipette tips, and tip waste to the dishwashing station. Set the P1000 pipette to 1000uL\"\n    end\n  end\n  \n  def culture_dilution ops\n      #If recorded OD > 0.1, add additional GYT according to this calculation:\n            # recorded OD x 10 = actual OD\n            # actual OD x 2.5 x 10^8 cells/mL = concentration of 1:100 dilution\n            # concentration of 1:100 dilution x 100 = concentration of cells\n            # (concentration of cells) x (1.6 mL) / 2.5 x 10 ^ 10 = final volume\n            # Final volume - 1.6 = volume of GYT to add to cells\n    ops.each do |op|\n      od = op.temporary[:OD_value] * 10 #our nanodrop is reliably innacurate by 1/10\n      cell_concentration = od * (2.5 * (10 ** 8)) * 100\n      final_volume = (cell_concentration * 1.6) / (2.5 * (10 ** 10))\n      op.temporary[:GYT_to_add] = final_volume - 1.6\n    end\n    \n    show do \n      title \"Dilute cultures to acceptable concentration\"\n      ops.each do |op|\n        note \"Dilute the 225mL culture tube labeled #{op.input(\"Overnight\").item.id} by adding #{op.temporary[:GYT_to_add]} mL of GYT\"\n      end\n    end\n  end\n  \n  def aliquot_cultures op\n    data = show do\n      title \"Aliquot cells into 0.6mL tubes\"\n      note \"Take ice block, aluminum tube rack, and arranged 0.6 mL tubes out of the freezer.\"\n      note \"Aliquot 40 uL of cells from 225 mL culture tube #{op.input(\"Overnight\").item.id} into each 0.6 mL tube until the tube is empty.\"\n      note \"Vortex the 225 mL tube and change tips periodically, adding more 0.6 mL tubes to the aluminum tube rack if required.\"\n      note \"record how many aliquots will be in this batch\"\n      get \"number\", var: \"aliquots\", label: \"Aliquots made from culture #{op.input(\"Overnight\").item.id}\", default: 40\n    end\n    aliquots = data[:aliquots]\n    batch = op.output(\"Comp Cell\").collection\n    strain = op.output(\"Comp Cell\").sample\n    aliquots.times do\n      batch.add_one strain\n    end\n  end\n  \n  # steps to perform while last centrifuge batch is spinning to make use of time.\n  def callback\n    prep_and_clean\n    make_GYT_tubes operations.length\n  end\n  \n  def label_and_store_batches op\n    op.output(\"Comp Cell\").item.move \"M80\"\n    show do\n      title \"Label and Store\"\n      note \"Take an empty freezer box, and label it with sample id: #{op.output(\"Comp Cell\").sample.name}, the date, your initials, and the item id: #{op.output(\"Comp Cell\").item}.\"\n      note \"QUICKLY transfer the aliquoted tubes to the labeled box, then store them at #{op.output(\"Comp Cell\").item.location}\"\n    end\n    release [op.output(\"Comp Cell\")], interactive: false\n  end\n  \n  def clean_up\n    show do \n      title \"Clean Up\"\n      note \"Dispose of all empty 225 mL centrifuge tubes\"\n      note \"Pour remaining ice into sink at dishwashing station\"\n      note \"Return ice block and aluminum tube rack\"\n    end\n  end\n  \n####################################################\n### Methods for checking culture optical density ###   \n####################################################\n\n  #returns true if the OD of the inoculated culture >= .04\n  def check_OD_initial op\n    show do \n        title \"Grab the following items for OD check\"\n        note \"2 L flask from 37 shaker: #{op.input(\"Overnight\").item.id}\"\n        note \"1.5 mL tube\"\n    end\n\n    show do \n        title \"Make Aliquot\"\n        note \"carefully pipette 100 uL from culture flask into 1.5mL tube.\" \n        note \"swirl the flask before pipetting out culture\"\n        note \"Return 2 L flask to shaker incubator\"\n    end\n\n    cc = show do \n        title \"Nanodrop the 1.5mL tube containing the culture\"\n        note \"Make sure nanodrop is in cell culture mode\"\n        note \"blank with LB\"\n        note \"measure OD 600 of aliquot\"\n        get \"number\", var: \"conc\", label: \"Culture #{op.input(\"Overnight\").item.id}\", default: 0.05\n        note \"discard the used 1.5mL tube\"\n    end\n    return cc[:conc] >= 0.04\n  end\n  \n  #make tubes that are required to nanodrop cultures after they are made competent\n  def make_GYT_tubes number\n      show do\n          title \"make 1:100 GYT dilution for nanodrop\"\n          note \"Take #{number} empty, sterile 1.5 mL #{\"tube\".pluralize(number)} and add 990 uL GYT#{number > 1 ? \" to each\" : \"\"}.\" \n          note \"Label #{number > 1 ? \"each \" : \"\"}tube as 1:100 dilution. \"\n      end\n  end\n  \n  # returns the OD measurement, and assigns op.temp[good_od?] to true if the od <= 0.1\n  # this is run after cultures are made competent\n  def check_OD_post op\n    show do \n        title \"Grab the following items for OD check\"\n        note \"#{op.input(\"Overnight\").item.id} 225mL tube of Resuspended Cells\"\n        note \"a 1.5 mL 1:100 GYT dilution tube\"\n    end\n\n    show do \n        title \"Make Aliquot\"\n        note \'carefully pipette 10 uL of the resuspended cells into the 1.5mL tube labeled \"1:100 dilution\".\' \n    end\n\n    cc = show do \n        title \"Nanodrop the 1.5mL tube containing the culture\"\n        note \"Make sure nanodrop is in cell culture mode\"\n        note \"blank with GYT\"\n        note \"measure OD 600 of aliquot\"\n        get \"number\", var: \"conc\", label: \"Culture #{op.input(\"Overnight\").item.id}\", default: 0.09\n        note \"discard the used 1.5mL tube\"\n    end\n    \n    if cc[:conc] <= 0.1\n        return nil\n    else\n        return cc[:conc]    \n    end\n    \n  end\nend',24,'OperationType','2018-07-18 23:54:47','2018-07-18 23:54:47',1),(197,'protocol','class Protocol\n\n  def main\n    operations.make    \n    operations.each do |op|\n        op.output(\"Batch\").item.mark_as_deleted\n        \n        item_info = show do\n            title \"What type of Collection do you want to create?\"\n            note \"object type name must be exactly correct\"\n            \n            get \"text\", var: \"object_type\", label: \"Object type\", default: \"Stripwell\"\n            get \"text\", var: \"location\", label: \"Location\", default: \"Bench\"\n        end\n         \n        object_type = ObjectType.find_by_name(item_info[:object_type])\n        new_item = produce new_collection object_type.name\n        new_item.matrix = Array.new(object_type.rows) { Array.new(object_type.columns) { -1 } }\n        new_item.save\n        \n        op.output(\"Batch\").set item: new_item\n    \n        show do\n            title \"Collection Created!\"\n            \n            note \"Made new #{op.output(\"Batch\").item.object_type.name}\"\n            note \"Collection link #{op.output(\"Batch\").item}\"\n            note \"Now we will populate the collection with samples of your choice\"\n        end\n        \n        \n        coll = op.output(\"Batch\").collection\n        coll.location = item_info[:location]\n        continue = true\n        while continue\n            add = show do \n                title \"how many samples to add to #{coll.id}\"\n                note \"Make sure to specify sample name exactly correct\"\n                \n                get \"number\", var: \"sample\", label: \"Sample to add\", default: \"Gibson Aliquot\"\n                get \"number\", var: \"add\", label: \"how many to add\", default: 0\n                select [\"Yes\", \"No\"], var: \"continue\", label: \"I want to add a different sample as well\", default: 1\n                note \"Below is a representation of the collection state. -1 means no sample in that slot.\"\n                table coll.matrix\n            end        \n            \n            sample = Sample.find_by_name(add[:sample])\n            \n            add[:add].times do\n                coll.add_one sample\n            end\n            continue = add[:continue] == \"Yes\"\n        end\n        \n        show do \n            title \"Collection finsished and ready to use\"\n            \n            note \"Use the \\\'edit collection\\\' protocol to add or remove samples\"\n            table coll.matrix\n        end\n    end\n    \n    \n    \n    return {}\n    \n  end\n\nend\n',19,'OperationType','2018-07-19 16:41:20','2018-07-19 16:41:20',1),(201,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',25,'OperationType','2018-07-19 16:42:11','2018-07-19 16:42:11',1),(202,'source','# helper functions for uploading files\n# note: data associations should be handled externally\nmodule UploadHelper\n    \n    require \'csv\'\n    require \'open-uri\'\n    \n    # Uploads files \n    #\n    # @params dirname - directory where files are located, or full path including filename\n    # @params expUploadNum - expected number of files to upload\n    # @params tries - max. number of attempts to upload expectedNum files \n    # @return array of Upload items \n    # \n    # EXAMPLES of how to associate correctly:     \n    # data associations - 1st gel image        \n    # up_bef=ups[0]\n    # op.plan.associate \"gel_image_bef\", \"combined gel fragment\", up_bef  # upload association, link \n    # op.input(INPUT).item.associate \"gel_image_bef\", up_bef              # regular association\n    # op.output(OUTPUT).item.associate \"gel_image_bef\", up_bef            # regular association \n    def uploadData(dirname, expUploadNum, tries)\n\n        uploads={}      # holds result of upload block   \n        numUploads=0    # number of uploads in current attempt\n        attempt=0       # number of upload attempts\n            \n        # get uploads\n        loop do\n            #if(numUploads==expUploadNum)  \n            #    show {note \"Upload complete.\"}\n            #end\n            break if ( (attempt>=tries) || (numUploads==expUploadNum) ) # stopping condition\n            attempt=attempt+1;\n            uploads = show do\n                title \"Select <b>#{expUploadNum}</b> file(s)\"\n                note \"File(s) location is: #{dirname}\"\n                if(attempt>1)\n                    warning \"Number of uploaded files (#{numUploads}) was incorrect, please try again! (Attempt #{attempt} of #{tries})\"\n                end\n                upload var: \"files\"\n            end\n            # number of uploads    \n            if(!uploads[:files].nil?)\n                numUploads=uploads[:files].length\n            end\n        end\n        \n        if(numUploads!=expUploadNum)\n            show {note \"Final number of uploads (#{numUploads}) not equal to expected number #{expUploadNum}! Please check.\"}\n            return nil\n        end\n        \n        # format uploads before returning \n        ups=Array.new # array of upload hashes\n        if (!uploads[:files].nil?)\n            uploads[:files].each_with_index do |upload_hash, ii|\n                up=Upload.find(upload_hash[:id]) \n                ups[ii]=up\n            end\n        end\n        \n        # return\n        ups\n        \n    end # def\n    \n    \n    # Opens .csv file upload item using its url and stores it line by line in a matrix\n    #\n    # @params upload [upload_obj] the file that you wish to read from\n    # @return matrix [2D-Array] is the array of arrays of the rows read from file, if csv\n    def read_url(upload)\n        url = upload.url\n        matrix = []\n        CSV.new(open(url)).each {|line| matrix.push(line)}\n        # open(url).each {|line| matrix.push(line.split(\',\')}\n        return matrix\n    end\n    \n    # Provides a upload button in a showblock in order to upload a single file\n    #\n    # @params upload_filename [string] can be the name of the file that you want tech to upload\n    # @return up_show [hash] is the upload hash created in the upload show block\n    # @return up_sym [symbol] is the symbol created in upload show block that will be used to access upload\n    def upload_show(upload_filename)\n        upload_var = \"file\"\n        up_sym = upload_var.to_sym\n        up_show = show do\n            title \"Upload Your Measurements\"\n            note \"Select and Upload: #{upload_filename}\"\n            upload var: \"#{upload_var}\"\n        end\n        return up_show, up_sym\n    end\n    \n    # Retrieves the upload object from upload show block\n    #\n    # @params up_show [hash] is the hash that is created in the upload show block\n    # @params up_sym [symbol] is the symbol created in the upload show block and used to access file uploaded\n    # @return upload [upload_object] is the file that was uploaded in the upload show block\n    def find_upload_from_show(up_show, up_sym)\n        # Makes a query to find the uploaded file by its default :id\n        upload = up_show[up_sym].map {|up_hash| Upload.find(up_hash[:id])}.shift \n        return upload\n    end\n\nend # module\n   ',2,'Library','2018-07-19 16:43:02','2018-07-19 16:43:02',1),(203,'source','# This module is made to cover all common cases of directing the tech to\r\n# centrifuge, decant, and resuspend multiple batches of tubes.\r\n# centrifuge_resuspend_cycle is the public method of this module.\r\n# It allows staggered centrifuging so that the tech can be resuspending\r\n# the previous batch while the next batch is centrifuging.\r\nmodule Centrifuge\r\n  class Batch\r\n    attr_reader :marker, :tubes\r\n\r\n    def initialize(args)\r\n      @marker = args[:marker]\r\n      @tubes = args[:tubes]\r\n    end\r\n\r\n    # Partition the given tubes list into batches.\r\n    # Returns a list of Batch objects, each having a letter marker, and a list\r\n    # of tubes.\r\n    def self.initialize_batches(tubes, centrifuge_slots, protocol)\r\n      @@protocol = protocol # we need this to use show commands in Batch methods\r\n      @@batch_size = centrifuge_slots\r\n      tube_batches = tubes.each_slice(centrifuge_slots).to_a\r\n      batches = []\r\n      tube_batches.each_with_index do |tube_batch, i|\r\n        batch_id = [(i + 65).chr]\r\n        batches.push Batch.new(marker: batch_id, tubes: tube_batch)\r\n      end\r\n      batches\r\n    end\r\n    \r\n    def self.batch_size\r\n      @@batch_size\r\n    end\r\n\r\n    # returns a new list of batches produced by reducing the amount of tubes in\r\n    # each batch and then combining batches, Batches.size will be halved.\r\n    def self.combine_batches(batches)\r\n      paired_batches = batches.each_slice(2).to_a\r\n      batches = []\r\n      paired_batches.each do |pair|\r\n        pair.each_with_index do |batch, i|\r\n          pair[i] = batch.combine_tubes\r\n        end\r\n        batches.push(pair[0].combine_with(pair[1]))\r\n      end\r\n      batches\r\n    end\r\n\r\n    # Instructs tech to reduce the number of tubes in the given batch by a power\r\n    # of 2, combining tubes of the same sample. This only shows the instructions\r\n    # and does not alter the state of batches[].\r\n    # (that happens in combine_batches)\r\n    def combine_tubes_instructions()\r\n      batch = self\r\n      @@protocol.show do\r\n        title \'Combine Tubes\'\r\n        if batch.marker.length == 1\r\n          note \'Reduce the number of tubes in \'\\\r\n               \"<b>batch #{batch.marker.to_sentence}</b> from #{batch.tubes.length} \"\\\r\n               \"to #{batch.tubes.length / 2} by combining tubes.\"\r\n        else\r\n          note \"Together, <b>batches #{batch.marker.to_sentence}</b> have a \"\\\r\n               \"total of #{batch.tubes.length} tubes. Reduce the sum of tubes to \"\\\r\n               \"#{batch.tubes.length / 2} by combining tubes from \"\\\r\n               \"#{batch.marker.length == 2 ? \'both\' : \'all\'} batches.\"\r\n        end\r\n        note \'Combine tubes by carefully pouring one tube into tube \'\\\r\n             \'that shares the same id.\'\r\n        note \'All tubes after combination should have the same volume. \'\\\r\n             \'Do not \"double combine\" any tubes.\'\r\n        batch.tubes.uniq.each do |tube|\r\n          note \"Combine each tube labeled <b>#{tube}</b> \"\\\r\n               \"with another tube labeled <b>#{tube}</b>.\"\r\n        end\r\n        if Cycle.cold?\r\n          warning \'Once finished with combining, \'\\\r\n                  \'immediately place tubes in ice bath.\'\r\n        end\r\n      end\r\n    end\r\n\r\n    # instructions to place tubes from batch into the centrifuge\r\n    def centrifuge(centrifuge_instructions)\r\n      rpm = centrifuge_instructions[:rpm]\r\n      time = centrifuge_instructions[:time]\r\n      temp = centrifuge_instructions[:temp]\r\n      batch = self\r\n      @@protocol.show do\r\n        title \'centrifuge tubes\'\r\n        note \"Set the centrifuge to #{rpm} rpm for #{time} minutes at \"\\\r\n             \"#{temp} C. Ensure correct centrifuge tube holders are in place.\"\r\n        note \"Move all tubes from <b>#{\'batch\'.pluralize(batch.marker.length)} \"\\\r\n             \"#{batch.marker.to_sentence}</b> to centrifuge and press start.\"\r\n        if batch.tubes.length.odd?\r\n          warning \'Balance the centrifuge with a dummy tube that is filled \'\\\r\n                  \'with the same volume of liquid as the other tubes.\'\r\n        end\r\n      end\r\n    end\r\n\r\n    # instructions to remove tubes from the centrifuge\r\n    # after it has finished a spin\r\n    def remove_tubes()\r\n      batch = self\r\n      @@protocol.show do\r\n        title \'Remove Tubes from Centrifuge\'\r\n        note \'Wait for centrifuge to finish\'\r\n        note \'Once the centrifuge has finished its spin, \'\\\r\n             \'remove tubes from centrifuge.\'\r\n        note \"The removed tubes should be marked as \"\\\r\n             \"<b>#{\'batch\'.pluralize(batch.marker.length)} \"\\\r\n             \"#{batch.marker.to_sentence}</b>.\"\r\n        if Cycle.cold?\r\n          warning \'Once removed from centrifuge, \'\\\r\n                \'immediately place tubes in ice bath.\'\r\n        end\r\n      end\r\n    end\r\n\r\n    # instructions to resuspend tubes\r\n    def resuspend(resuspend_instructions)\r\n      volume = resuspend_instructions[:volume]\r\n      media = resuspend_instructions[:media]\r\n\r\n      decant()\r\n\r\n      batch = self\r\n      @@protocol.show do\r\n        title \"Resuspend cells in #{volume}mL of #{media}\"\r\n        note \"Grab bottle of #{media} from fridge.\"\r\n        note \"Carefully pour #{volume}mL of #{media} into each tube from <b>\"\\\r\n             \"#{\'batch\'.pluralize(batch.marker.length)} #{batch.marker.to_sentence}</b>.\"\r\n        note \'Shake and vortex tubes until pellet is completely resuspended.\'\r\n        warning \'When not actively shaking or vortexing keep tubes in ice, \'\\\r\n                \'and place all tubes in ice once resuspended.\' if Cycle.cold?\r\n        note \"At next opportunity, bring #{media} back to fridge, \"\\\r\n             \'or to dishwasher if empty.\'\r\n      end\r\n    end\r\n\r\n    def decant()\r\n      batch = self\r\n      @@protocol.show do\r\n        title \'Decant tubes\'\r\n        note \"Take #{Cycle.cold? ? \'ice bucket\' : \'tubes\'} to the \"\\\r\n             \"dishwasing station, and pour out supernatant of tubes from <b>\"\\\r\n             \"#{\'batch\'.pluralize(batch.marker.length)} #{batch.marker.to_sentence}</b>.\"\r\n        note \'Place tubes in ice immediately after decanting.\' if Cycle.cold?\r\n      end\r\n    end\r\n\r\n    # returns new batch which is the combination of this batch\r\n    # and the other batch\r\n    # helper for combine_batches\r\n    def combine_with(other)\r\n      if other\r\n        new_marker = marker.concat other.marker\r\n        new_tubes = tubes.concat other.tubes\r\n        return Batch.new(marker: new_marker, tubes: new_tubes)\r\n      else\r\n        return self\r\n      end\r\n    end\r\n\r\n    # returns a new batch with a half the tubes, where like tubes have been\r\n    # combined.\r\n    # helper for combine_batches\r\n    def combine_tubes\r\n      new_tubes = []\r\n      new_tubes.concat(tubes)\r\n      batch = Batch.new(marker: marker,tubes: [])\r\n      tubes.uniq.each do |short_id|\r\n        sameids = new_tubes.select { |tube| tube == short_id }\r\n        batch.tubes.concat(sameids[0, sameids.length / 2])\r\n      end\r\n      batch\r\n    end\r\n  end\r\n\r\n  class Cycle\r\n    attr_reader :centrifuge_instructions, :resuspend_instructions\r\n    def initialize(cycle_instructions)\r\n      @centrifuge_instructions = { temp: cycle_instructions[:cent_temp],\r\n                                   rpm: cycle_instructions[:cent_rpm],\r\n                                   time: cycle_instructions[:cent_time] }\r\n\r\n      @resuspend_instructions = { media: cycle_instructions[:sus_media],\r\n                                  volume: cycle_instructions[:sus_volume] }\r\n\r\n      @combine = cycle_instructions[:combine]\r\n    end\r\n\r\n    def self.initialize_cycles(cycles_data, cold)\r\n      @@cold = cold\r\n      cycles = cycles_data.map do |cycle_data|\r\n        Cycle.new(cycle_data)\r\n      end\r\n      cycles\r\n    end\r\n\r\n    def self.cold?\r\n      @@cold\r\n    end\r\n\r\n    def combine?\r\n      @combine\r\n    end\r\n  end\r\n\r\n  ##\r\n  # @param [Hash] opts  The parameters which indicate cycling behaivor\r\n  # @option [Array<Item>] items  The array of items for which each will\r\n  #           be split into smaller tubes and then centrifuge cycled on.\r\n  # @option [Float] start_vol  Volume of liquid that each item begins with.\r\n  # @option [Float] tube_vol  Volume of centrifuge tubes that\r\n  #           start_vol will be divided amongst\r\n  # @option [Integer] centrifuge_slots  Number of slots in the centrifuge.\r\n  #           Must be an even number.\r\n  # @option [Array<Hash>] cycles  Instructions for each cycle of centrifuging.\r\n  #           Cycles.length indicates how many centrifuge/wash cycles.\r\n  #           Elements of cycles contain instructions for the centrifuging\r\n  #           and resuspension settings for that cycle.\r\n  # @option [Boolean] :cold  Indicate if centrifuge cycling is done on ice.\r\n  #           Default: no\r\n  # @option [Symbol] :cb_extra_instructions  Extra instructions for tech\r\n  #           while waiting for final centrifuge batch to finish,\r\n  #           for example, tidying up workspace. Default: none\r\n  # @effects  This method Instructs tech to do cycles of centrifuging,\r\n  #           decanting, and resuspending on each item\r\n  #           as per the instructions stored in cycles.\r\n  def centrifuge_resuspend_cycle(opts = {})\r\n    # Bench setup is required before we begin centrifuging\r\n    # During setup, the items will be aliquoted into tubes,\r\n    # and each aliquoted tube will be marked with a short id.\r\n    # This maps tubes to the item they originated from, and will\r\n    # keep track of which tubes contain the same substance.\r\n    # the index of the parent item in the items[] is used\r\n    # for the short id.\r\n    # Also, tubes are grouped into batches that will fit in centrifuge,\r\n    # and marked with a capital letter batch identifier, in addition to their\r\n    # short id that indicates their ancestry.\r\n\r\n    # computation\r\n    tubes = initialize_tubes(opts)\r\n    batches = Batch.initialize_batches(tubes, opts[:centrifuge_slots], self)\r\n    cycles = Cycle.initialize_cycles(opts[:cycles], opts[:cold])\r\n\r\n    # tech instructions\r\n    setup_steps(cycles, batches,\r\n              opts[:start_vol], opts[:tube_vol], opts[:items])\r\n\r\n    # Loop through each cycle of centrifuging and resuspending found in cycles[]\r\n    # and perform that cycle on each batch of tubes in found in batches[]\r\n    this_batch = nil\r\n    cycles.each_with_index do |cycle, i|\r\n      prev_cycle = cycles[i - 1]\r\n      \r\n      # Reconfigure batches array to be shortened by combing batches\r\n      # so each batch has enough tubes to fill centrifuge.\r\n      batches = Batch.combine_batches(batches) if prev_cycle.combine?\r\n\r\n      batch_iterator = batches.each\r\n      first_batch = batch_iterator.next\r\n      if i.zero?\r\n        # first batch of first cycle, the centrifuge is empty\r\n        first_batch.centrifuge(cycle.centrifuge_instructions)\r\n      else\r\n        this_batch.remove_tubes\r\n        if batches.length == 1\r\n          # this_batch == first_batch || first_batch contains this_batch\r\n          this_batch.resuspend(prev_cycle.resuspend_instructions)\r\n          this_batch.combine_tubes_instructions if prev_cycle.combine?\r\n          first_batch.centrifuge(cycle.centrifuge_instructions)\r\n        else\r\n          # first_batch and this_batch are not associated,\r\n          # we can start centrifuging first_batch before we resuspend this_batch\r\n          first_batch.centrifuge(cycle.centrifuge_instructions)\r\n          this_batch.resuspend(prev_cycle.resuspend_instructions)\r\n          this_batch.combine_tubes_instructions if prev_cycle.combine?\r\n        end\r\n      end\r\n\r\n      this_batch = first_batch\r\n      while has_next? batch_iterator\r\n        next_batch = batch_iterator.next\r\n        this_batch.remove_tubes\r\n        next_batch.centrifuge(cycle.centrifuge_instructions)\r\n        this_batch.resuspend(cycle.resuspend_instructions)\r\n        this_batch.combine_tubes_instructions if cycle.combine?\r\n        this_batch = next_batch\r\n      end\r\n    end\r\n\r\n    # Show any extra steps specified by client to do\r\n    # while waiting for last spin to finish.\r\n    extra_instructions(opts[:cb_extra_instructions])\r\n\r\n    final_cycle = cycles.last\r\n    this_batch.remove_tubes\r\n    this_batch.resuspend(final_cycle.resuspend_instructions)\r\n    if final_cycle.combine?\r\n      this_batch.combine_tubes_instructions\r\n      batches = Batch.combine_batches(batches)\r\n    end\r\n\r\n    # On remaining tubes,\r\n    # replaces the short id with the id of original parent item.\r\n    relabel_tubes(batches, opts[:items])\r\n  end\r\n\r\n  private\r\n\r\n  # Ensures state of variables is acceptable\r\n  # TODO add more checks\r\n  def error_checks(cycles, batches, opts)\r\n    raise \'odd slot centrifuge not supported\' if Batch.batch_size.odd?\r\n    raise \'wrong cycle amount\' if cycles.length != opts[:cycles].length\r\n    raise \'wrong batch size\' if Batch.batch_size != opts[:centrifuge_slots]\r\n  end\r\n\r\n  # Initializes array of integers that represent tubes\r\n  # identified by their short_id which corresponds to the parent item.\r\n  # Also returns\r\n  def initialize_tubes(opts)\r\n    combination_occurs = opts[:cycles].any? { |cycle| cycle[:combine] == true }\r\n    tubes_per_item = (opts[:start_vol] / opts[:tube_vol]).floor\r\n    tubes_per_item += 1 if tubes_per_item.odd? && combination_occurs\r\n    tubes = []\r\n    opts[:items].each_with_index do |_item, i|\r\n      tubes_per_item.times do\r\n        tubes.push (i + 1)\r\n      end\r\n    end\r\n    tubes\r\n  end\r\n\r\n  # Gives the tech instructions to prepare for centrifuging.\r\n  def setup_steps(cycles, batches, start_vol, tube_vol, items)\r\n    tubes = batches.map { |batch| batch.tubes }.flatten\r\n\r\n    fetch_supplies(cycles, tubes.length, tube_vol)\r\n    if Cycle.cold?\r\n      prepare_ice_bath\r\n      chill_tubes(tubes.length, tube_vol)\r\n    end\r\n    aliquot_items_to_tubes(items, tubes, start_vol, tube_vol)\r\n    batch_tubes_instructions(batches)\r\n  end\r\n\r\n  # Instructs tech to fetch all the media and tubes that will be required.\r\n  def fetch_supplies(cycles, num_tubes, tube_vol)\r\n    media_to_volume = calculate_media_volumes(cycles, num_tubes)\r\n\r\n    media_location = \'on bench\'\r\n    tube_location = \'on bench\'\r\n    if Cycle.cold?\r\n      media_location = \'in fridge\'\r\n      tube_location = \'in freezer\'\r\n    end\r\n\r\n    show do\r\n      title \'Grab required suspension media\'\r\n      note \'For the following set of centrifuging instructions, you will need\'\\\r\n           \' the following supplies: \'\r\n      media_to_volume.each do |media, volume|\r\n        check \"At least #{volume}mL of #{media}\"\r\n      end\r\n      note \"Place all media bottles #{media_location}\"\\\r\n           \' in preparation for centrifuge.\'\r\n      note \"Place #{num_tubes} #{tube_vol}mL tubes #{tube_location}\"\\\r\n           \' in preparation for centrifuge.\'\r\n    end\r\n  end\r\n\r\n  def calculate_media_volumes(cycles, num_tubes)\r\n    media_to_volume = Hash.new\r\n    media_list = cycles.map do |cycle|\r\n      cycle.resuspend_instructions[:media]\r\n    end.uniq\r\n\r\n    media_list.each do |media|\r\n      volumes = cycles.select { |cycle|\r\n        cycle.resuspend_instructions[:media] == media\r\n      }.map { |cycle|\r\n        cycle.resuspend_instructions[:volume]\r\n      }\r\n      total_volume = volumes.sum * num_tubes\r\n      media_to_volume[media] = total_volume\r\n    end\r\n    media_to_volume\r\n  end\r\n\r\n  # Instructs tech to make an ice bath and immerse empty tubes in it.\r\n  def prepare_ice_bath\r\n    show do\r\n      title \'Go to Bagley to get ice (Skip if you already have ice)\'\r\n      note \'Walk to ice machine room on the second floor in Bagley with a \'\\\r\n           \'large red bucket, fill the bucket ¾ full with ice.\'\r\n      note \'If unable to go to Bagley, use ice cubes to make a water bath (of \'\\\r\n           \'mostly ice) or use the chilled aluminum bead bucket. (if using \'\\\r\n           \'aluminum bead bucket place it back in freezer between spins)\'\r\n    end\r\n  end\r\n\r\n  def chill_tubes(num_tubes, tube_vol)\r\n    show do\r\n      title \'Prepare chilled tubes\'\r\n      note \"Take the #{num_tubes} #{tube_vol}mL \"\\\r\n            \"#{\'tube\'.pluralize(num_tubes)} from the freezer \"\\\r\n            \'and immerse in ice bath.\'\r\n    end\r\n  end\r\n\r\n  # Instructs the tech to divide the volume of each item in items[] into\r\n  # equivolume aliquots for centrifuging.\r\n  def aliquot_items_to_tubes(items, tubes, start_vol, tube_vol)\r\n    tubes_per_item = tubes.length / items.length\r\n    aliquot_amount = [start_vol / tubes_per_item, tube_vol].min\r\n\r\n    show do\r\n      title \"Aliquot items into #{tube_vol}mL tubes for centrifuging\"\r\n      note \'You should have \'\\\r\n           \"#{items.length * tubes_per_item} #{tube_vol}mL tubes.\"\r\n      if Cycle.cold?\r\n        note \'While labeling and pouring, \'\\\r\n             \'leave tubes in ice bath as much as possible.\'\r\n      end\r\n      items.each_with_index do |item, i|\r\n        note \"Label #{tubes_per_item} tubes with short id: <b>#{i + 1}</b>\"\r\n        note \"Carefully pour #{aliquot_amount}mL from #{item} \"\\\r\n             \"into each tube labeled as <b>#{i + 1}</b>.\"\r\n      end\r\n    end\r\n  end\r\n  \r\n  # Instructs the tech to group tubes into batches\r\n  # that will fit into the centrifuge\r\n  def batch_tubes_instructions(batches)\r\n    show do\r\n      title \"separate tubes into batches of #{Batch.batch_size} or less\"\r\n      note \'Group tubes into batches as shown and mark each tube \'\\\r\n           \'with its alphabetic batch identifier.\'\r\n      batches.each do |batch|\r\n        check \"<b>#{batch.tubes.to_sentence}</b>: \"\\\r\n              \"batch <b>#{batch.marker}</b>\"\r\n      end\r\n    end\r\n  end\r\n  \r\n  # Callback which runs client specified method during the time when\r\n  # the tech is waiting for the last batch of tubes to finish centrifuging.\r\n  def extra_instructions(method_name)\r\n    method(method_name.to_sym).call if method_name && (method_name != \'\')\r\n  end\r\n\r\n  # After centrifuging finishes, instruct tech to relabel the resulting tubes\r\n  # with the id of the item that they originated from, for convienence.\r\n  def relabel_tubes(batches, items)\r\n    result_tubes = batches.map { |batch| batch.tubes }.flatten\r\n    show do\r\n      title \'Label Finished Tubes\'\r\n      note \'Tubes with the following ids remain: \'\\\r\n           \"<b>#{result_tubes.to_sentence}</b>.\"\r\n      note \'Label each tube with the item id \'\\\r\n           \'of the item that they originated from.\'\r\n      items.each_with_index do |item, i|\r\n        note \"The tube(s) labeled as <b>#{i + 1}</b> \"\\\r\n             \"should be relabeled as <b>#{item.id}</b>.\"\r\n      end\r\n    end\r\n  end\r\n\r\n  # Helper method that allows manual iteration like in java\r\n  # when used alongside enumerator.next()\r\n  def has_next?(enum)\r\n    enum.peek\r\n    return true\r\n  rescue StopIteration\r\n    return false\r\n  end\r\nend\r\n',5,'Library','2018-07-19 16:43:08','2018-07-19 16:43:08',1);
/*!40000 ALTER TABLE `codes` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `collections`
--

DROP TABLE IF EXISTS `collections`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `collections` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `project` varchar(255) DEFAULT NULL,
  `object_type_id` int(11) DEFAULT NULL,
  `rows` int(11) DEFAULT NULL,
  `columns` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `collections`
--

LOCK TABLES `collections` WRITE;
/*!40000 ALTER TABLE `collections` DISABLE KEYS */;
/*!40000 ALTER TABLE `collections` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `data_associations`
--

DROP TABLE IF EXISTS `data_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `data_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) DEFAULT NULL,
  `key` varchar(255) DEFAULT NULL,
  `upload_id` int(11) DEFAULT NULL,
  `object` text,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_data_associations_on_upload_id` (`upload_id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `data_associations`
--

LOCK TABLES `data_associations` WRITE;
/*!40000 ALTER TABLE `data_associations` DISABLE KEYS */;
INSERT INTO `data_associations` VALUES (1,95,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 2 crashed\"}','2018-07-19 18:54:05','2018-07-19 18:54:05'),(2,96,'Operation','aborted',NULL,'{\"aborted\":\"Operation was canceled when job 4 was aborted\"}','2018-07-19 19:45:09','2018-07-19 19:45:09'),(3,96,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 4 crashed\"}','2018-07-19 19:45:09','2018-07-19 19:45:09');
/*!40000 ALTER TABLE `data_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `field_types`
--

DROP TABLE IF EXISTS `field_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `field_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `ftype` varchar(255) DEFAULT NULL,
  `choices` varchar(255) DEFAULT NULL,
  `array` tinyint(1) DEFAULT NULL,
  `required` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `parent_class` varchar(255) DEFAULT NULL,
  `role` varchar(255) DEFAULT NULL,
  `part` tinyint(1) DEFAULT NULL,
  `routing` varchar(255) DEFAULT NULL,
  `preferred_operation_type_id` int(11) DEFAULT NULL,
  `preferred_field_type_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_field_types_on_sample_type_id` (`parent_id`)
) ENGINE=InnoDB AUTO_INCREMENT=82 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `field_types`
--

LOCK TABLES `field_types` WRITE;
/*!40000 ALTER TABLE `field_types` DISABLE KEYS */;
INSERT INTO `field_types` VALUES (1,1,'Overhang Sequence','string',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(2,1,'Anneal Sequence','string',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(3,1,'T Anneal','number',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(4,2,'Sequence','url',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(5,2,'Sequence Verification','url',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(6,2,'Bacterial Marker','string','Amp,Kan,Amp + Kan,Spec,Kan + Spec,Chlor,NA,Other',0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(7,2,'Yeast Marker','string','HIS,TRP,URA,LEU,NatMX,KanMX,HygMX,BleoMX,5FOA,NA,Other',0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(8,2,'Length','number',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(9,2,'Sequencing Primers','sample',NULL,1,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(10,3,'Sequence','url',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(11,3,'Length','number',NULL,0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(12,3,'Template','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(13,3,'Forward Primer','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(14,3,'Reverse Primer','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(15,3,'Restriction Enzyme(s)','string',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(16,3,'Yeast Marker','string',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(17,4,'Parent','sample',NULL,NULL,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(18,5,'Parent','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(19,5,'Integrant','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(20,5,'Plasmid','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(21,5,'Integrated Marker(s)','string',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(22,5,'Plasmid Marker(s)','string',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(23,5,'Mating Type','string','MATa,MATalpha,Diploid',0,1,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(24,5,'QC Primer1','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(25,5,'QC Primer2','sample',NULL,0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(26,5,'QC_length','number','',0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(27,5,'Comp_cell_limit','string','Yes,No',0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(28,5,'Has this strain passed QC?','string','No,Yes',0,0,'2018-07-17 20:29:15','2018-07-17 20:29:15','SampleType',NULL,NULL,NULL,NULL,NULL),(29,1,'Forward Primer','sample',NULL,0,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16','OperationType','input',0,'FP',329,1813),(30,1,'Reverse Primer','sample',NULL,0,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16','OperationType','input',0,'RP',329,1813),(31,1,'Template','sample',NULL,0,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16','OperationType','input',0,'T',NULL,NULL),(32,1,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:16','2018-07-17 20:29:16','OperationType','output',1,'F',NULL,NULL),(33,2,'Lane','sample',NULL,0,NULL,'2018-07-17 20:29:24','2018-07-17 20:29:24','OperationType','output',1,'G',NULL,NULL),(34,3,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:32','2018-07-17 20:29:32','OperationType','output',1,'F',NULL,NULL),(35,3,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:32','2018-07-17 20:29:32','OperationType','input',1,'F',NULL,NULL),(36,3,'Gel','sample',NULL,0,NULL,'2018-07-17 20:29:32','2018-07-17 20:29:32','OperationType','input',1,'L',NULL,NULL),(37,4,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:38','2018-07-17 20:29:38','OperationType','input',1,'F',72,865),(38,4,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:38','2018-07-17 20:29:38','OperationType','output',0,'F',NULL,NULL),(39,5,'Gel','sample',NULL,0,NULL,'2018-07-17 20:29:44','2018-07-17 20:29:44','OperationType','input',0,'F',NULL,5424),(40,5,'Fragment','sample',NULL,0,NULL,'2018-07-17 20:29:44','2018-07-17 20:29:44','OperationType','output',0,'F',NULL,NULL),(41,6,'Fragment','sample',NULL,1,NULL,'2018-07-17 20:29:57','2018-07-17 20:29:57','OperationType','input',0,'F',332,1822),(42,6,'Assembled Plasmid','sample',NULL,0,NULL,'2018-07-17 20:29:57','2018-07-17 20:29:57','OperationType','output',0,'P',NULL,NULL),(43,7,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:30:08','2018-07-17 20:30:08','OperationType','input',0,'P',333,1824),(44,7,'Transformed E Coli','sample',NULL,0,NULL,'2018-07-17 20:30:08','2018-07-17 20:30:08','OperationType','output',0,'P',NULL,NULL),(45,7,'Comp Cells','sample',NULL,0,NULL,'2018-07-17 20:30:08','2018-07-17 20:30:08','OperationType','input',1,'C',NULL,NULL),(46,8,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:30:21','2018-07-17 20:30:21','OperationType','input',0,'P',334,1826),(47,8,'Plate','sample',NULL,0,NULL,'2018-07-17 20:30:21','2018-07-17 20:30:21','OperationType','output',0,'P',NULL,NULL),(48,9,'Plate','sample',NULL,0,NULL,'2018-07-17 20:30:28','2018-07-17 20:30:28','OperationType','input',0,'P',335,1829),(49,9,'Plate','sample',NULL,0,NULL,'2018-07-17 20:30:28','2018-07-17 20:30:28','OperationType','output',0,'P',NULL,NULL),(50,10,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:30:41','2018-07-17 20:30:41','OperationType','input',0,'P',336,1831),(51,10,'Overnight','sample',NULL,0,NULL,'2018-07-17 20:30:42','2018-07-17 20:30:42','OperationType','output',0,'P',NULL,NULL),(52,11,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:30:50','2018-07-17 20:30:50','OperationType','input',0,'P',337,1833),(53,11,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:30:50','2018-07-17 20:30:50','OperationType','output',0,'P',NULL,NULL),(54,12,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:31:01','2018-07-17 20:31:01','OperationType','input',0,'P',347,1851),(55,12,'Sequencing Primer','sample',NULL,0,NULL,'2018-07-17 20:31:01','2018-07-17 20:31:01','OperationType','input',0,'SP',329,1813),(56,12,'Plasmid for Sequencing','sample',NULL,0,NULL,'2018-07-17 20:31:01','2018-07-17 20:31:01','OperationType','output',1,'P',NULL,NULL),(57,13,'Plasmid','sample',NULL,0,NULL,'2018-07-17 20:31:08','2018-07-17 20:31:08','OperationType','input',1,'P',807,2980),(58,14,'Stock','sample',NULL,0,NULL,'2018-07-17 20:31:17','2018-07-17 20:31:17','OperationType','input',0,'P',NULL,NULL),(59,14,'Plate','sample',NULL,0,NULL,'2018-07-17 20:31:17','2018-07-17 20:31:17','OperationType','input',0,'P',NULL,NULL),(60,15,'Overnight','sample',NULL,0,NULL,'2018-07-17 20:31:24','2018-07-17 20:31:24','OperationType','input',0,'P',NULL,NULL),(61,15,'Stock','sample',NULL,0,NULL,'2018-07-17 20:31:24','2018-07-17 20:31:24','OperationType','output',0,'P',NULL,NULL),(62,15,'Needs Sequencing Results?','string','No, Yes',0,NULL,'2018-07-17 20:31:24','2018-07-17 21:50:57','OperationType','input',0,NULL,NULL,NULL),(63,16,'gBlock Fragment','sample',NULL,0,NULL,'2018-07-17 20:31:36','2018-07-17 20:31:36','OperationType','output',0,'F',NULL,NULL),(64,16,'Bases','json',NULL,0,NULL,'2018-07-17 20:31:36','2018-07-17 20:31:36','OperationType','input',0,NULL,NULL,NULL),(65,17,'Primer','sample',NULL,0,NULL,'2018-07-17 20:31:41','2018-07-17 20:31:41','OperationType','output',0,'P',NULL,NULL),(66,17,'Urgent?','string',NULL,0,NULL,'2018-07-17 20:31:41','2018-07-17 20:31:41','OperationType','input',0,NULL,NULL,NULL),(67,18,'Default','string',NULL,0,NULL,'2018-07-17 20:31:56','2018-07-17 20:31:56','OperationType','input',0,NULL,NULL,NULL),(68,6,'Vendor Info','url',NULL,0,0,'2018-07-18 17:23:51','2018-07-18 17:23:51','SampleType',NULL,NULL,NULL,NULL,NULL),(69,19,'Batch','sample',NULL,0,NULL,'2018-07-18 17:53:29','2018-07-18 17:53:29','OperationType','output',0,'B',NULL,NULL),(70,20,'Media','sample',NULL,0,NULL,'2018-07-18 22:24:59','2018-07-18 22:24:59','OperationType','input',0,'A',572,2478),(71,20,'Plate Batch','sample',NULL,0,NULL,'2018-07-18 22:24:59','2018-07-18 22:24:59','OperationType','output',0,'A',NULL,NULL),(72,22,'Strain','sample',NULL,0,NULL,'2018-07-18 23:22:06','2018-07-18 23:22:06','OperationType','input',0,'s',NULL,NULL),(73,22,'Overnight','sample',NULL,0,NULL,'2018-07-18 23:22:06','2018-07-18 23:22:06','OperationType','output',0,'s',NULL,NULL),(74,22,'Media','sample',NULL,0,NULL,'2018-07-18 23:22:06','2018-07-18 23:22:06','OperationType','input',0,'m',NULL,NULL),(75,23,'Glycerol','sample',NULL,0,NULL,'2018-07-18 23:23:13','2018-07-18 23:23:13','OperationType','output',0,'g',NULL,NULL),(76,23,'Water','sample',NULL,0,NULL,'2018-07-18 23:23:13','2018-07-18 23:23:13','OperationType','output',0,'w',NULL,NULL),(77,24,'Overnight','sample',NULL,0,NULL,'2018-07-18 23:23:21','2018-07-18 23:23:21','OperationType','input',0,'s',NULL,NULL),(78,24,'Glycerol','sample',NULL,0,NULL,'2018-07-18 23:23:21','2018-07-18 23:23:21','OperationType','input',0,'g',NULL,NULL),(79,24,'Comp Cell','sample',NULL,0,NULL,'2018-07-18 23:23:21','2018-07-18 23:23:21','OperationType','output',0,'s',NULL,NULL),(80,24,'Water','sample',NULL,0,NULL,'2018-07-18 23:23:21','2018-07-18 23:23:21','OperationType','input',0,NULL,NULL,NULL),(81,25,'Item ID','number',NULL,0,NULL,'2018-07-19 16:42:11','2018-07-19 16:42:11','OperationType','input',0,NULL,NULL,NULL);
/*!40000 ALTER TABLE `field_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `field_values`
--

DROP TABLE IF EXISTS `field_values`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `field_values` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `value` varchar(255) DEFAULT NULL,
  `child_sample_id` int(11) DEFAULT NULL,
  `child_item_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  `parent_class` varchar(255) DEFAULT NULL,
  `role` varchar(255) DEFAULT NULL,
  `field_type_id` int(11) DEFAULT NULL,
  `row` int(11) DEFAULT NULL,
  `column` int(11) DEFAULT NULL,
  `allowable_field_type_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_field_values_on_sample_id` (`parent_id`),
  KEY `index_field_values_on_field_type_id` (`field_type_id`),
  KEY `index_field_values_on_allowable_field_type_id` (`allowable_field_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=90 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `field_values`
--

LOCK TABLES `field_values` WRITE;
/*!40000 ALTER TABLE `field_values` DISABLE KEYS */;
INSERT INTO `field_values` VALUES (10,6,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plasmid','Operation','input',43,NULL,NULL,32),(11,6,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Transformed E Coli','Operation','output',44,NULL,NULL,36),(12,6,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Comp Cells','Operation','input',45,NULL,NULL,37),(13,7,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plasmid','Operation','input',46,NULL,NULL,38),(14,7,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plate','Operation','output',47,NULL,NULL,39),(15,8,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plate','Operation','input',48,NULL,NULL,40),(16,8,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plate','Operation','output',49,NULL,NULL,41),(17,9,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Plasmid','Operation','input',50,NULL,NULL,42),(18,9,NULL,NULL,NULL,'2018-07-17 21:40:02','2018-07-17 21:40:02','Overnight','Operation','output',51,NULL,NULL,44),(19,10,NULL,NULL,NULL,'2018-07-17 21:41:56','2018-07-17 21:41:56','Plasmid','Operation','input',54,NULL,NULL,47),(20,10,NULL,NULL,NULL,'2018-07-17 21:41:56','2018-07-17 21:41:56','Sequencing Primer','Operation','input',55,NULL,NULL,49),(21,10,NULL,NULL,NULL,'2018-07-17 21:41:56','2018-07-17 21:41:56','Plasmid for Sequencing','Operation','output',56,NULL,NULL,50),(22,11,NULL,NULL,NULL,'2018-07-17 21:41:56','2018-07-17 21:41:56','Plasmid','Operation','input',57,NULL,NULL,52),(23,1,NULL,NULL,NULL,'2018-07-17 21:46:31','2018-07-17 21:46:31','Parent','Sample',NULL,NULL,NULL,NULL,NULL),(24,12,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',43,NULL,NULL,32),(25,12,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Transformed E Coli','Operation','output',44,NULL,NULL,36),(26,12,NULL,1,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Comp Cells','Operation','input',45,NULL,NULL,37),(27,13,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',46,NULL,NULL,38),(28,13,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plate','Operation','output',47,NULL,NULL,39),(29,14,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plate','Operation','input',48,NULL,NULL,40),(30,14,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plate','Operation','output',49,NULL,NULL,41),(31,15,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',50,NULL,NULL,42),(32,15,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Overnight','Operation','output',51,NULL,NULL,44),(33,16,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Fragment','Operation','input',41,NULL,NULL,30),(34,16,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Assembled Plasmid','Operation','output',42,NULL,NULL,31),(35,17,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Overnight','Operation','input',60,NULL,NULL,55),(36,17,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Stock','Operation','output',61,NULL,NULL,56),(37,17,' Yes',NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:51:44','Needs Sequencing Results?','Operation','input',62,NULL,NULL,NULL),(38,18,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',52,NULL,NULL,45),(39,18,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','output',53,NULL,NULL,46),(40,19,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',54,NULL,NULL,47),(41,19,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Sequencing Primer','Operation','input',55,NULL,NULL,49),(42,19,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid for Sequencing','Operation','output',56,NULL,NULL,50),(43,20,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',57,NULL,NULL,52),(44,21,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',54,NULL,NULL,47),(45,21,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Sequencing Primer','Operation','input',55,NULL,NULL,49),(46,21,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid for Sequencing','Operation','output',56,NULL,NULL,50),(47,22,NULL,NULL,NULL,'2018-07-17 21:50:01','2018-07-17 21:50:01','Plasmid','Operation','input',57,NULL,NULL,52),(48,23,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plasmid','Operation','input',43,NULL,NULL,32),(49,23,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Transformed E Coli','Operation','output',44,NULL,NULL,36),(50,23,NULL,1,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Comp Cells','Operation','input',45,NULL,NULL,37),(51,24,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plasmid','Operation','input',46,NULL,NULL,38),(52,24,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plate','Operation','output',47,NULL,NULL,39),(53,25,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plate','Operation','input',48,NULL,NULL,40),(54,25,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plate','Operation','output',49,NULL,NULL,41),(55,26,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Plasmid','Operation','input',50,NULL,NULL,42),(56,26,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Overnight','Operation','output',51,NULL,NULL,44),(57,27,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Fragment','Operation','input',41,NULL,NULL,30),(58,27,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Assembled Plasmid','Operation','output',42,NULL,NULL,31),(59,28,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Overnight','Operation','input',60,NULL,NULL,55),(60,28,NULL,NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Stock','Operation','output',61,NULL,NULL,56),(61,28,'No',NULL,NULL,'2018-07-17 21:52:41','2018-07-17 21:52:41','Needs Sequencing Results?','Operation','input',62,NULL,NULL,NULL),(62,2,'http://please.link.your.sequences.com',NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(63,2,'100.0',NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Length','Sample',NULL,NULL,NULL,NULL,NULL),(64,2,NULL,NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Template','Sample',NULL,NULL,NULL,NULL,NULL),(65,2,NULL,NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Forward Primer','Sample',NULL,NULL,NULL,NULL,NULL),(66,2,NULL,NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Reverse Primer','Sample',NULL,NULL,NULL,NULL,NULL),(67,2,'',NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Restriction Enzyme(s)','Sample',NULL,NULL,NULL,NULL,NULL),(68,2,'',NULL,NULL,'2018-07-17 21:58:07','2018-07-17 21:58:07','Yeast Marker','Sample',NULL,NULL,NULL,NULL,NULL),(69,3,'http://please.link.your.sequences.com',NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(70,3,'200.0',NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Length','Sample',NULL,NULL,NULL,NULL,NULL),(71,3,NULL,NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Template','Sample',NULL,NULL,NULL,NULL,NULL),(72,3,NULL,NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Forward Primer','Sample',NULL,NULL,NULL,NULL,NULL),(73,3,NULL,NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Reverse Primer','Sample',NULL,NULL,NULL,NULL,NULL),(74,3,'',NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Restriction Enzyme(s)','Sample',NULL,NULL,NULL,NULL,NULL),(75,3,'',NULL,NULL,'2018-07-17 21:58:37','2018-07-17 21:58:37','Yeast Marker','Sample',NULL,NULL,NULL,NULL,NULL),(76,4,'http://please.link.your.sequences.com',NULL,NULL,'2018-07-17 21:59:39','2018-07-17 21:59:39','Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(77,4,'http://please.link.your.sequences.com',NULL,NULL,'2018-07-17 21:59:39','2018-07-17 21:59:39','Sequence Verification','Sample',NULL,NULL,NULL,NULL,NULL),(78,4,'Amp',NULL,NULL,'2018-07-17 21:59:39','2018-07-17 21:59:39','Bacterial Marker','Sample',NULL,NULL,NULL,NULL,NULL),(79,4,'HIS',NULL,NULL,'2018-07-17 21:59:39','2018-07-17 21:59:39','Yeast Marker','Sample',NULL,NULL,NULL,NULL,NULL),(80,4,'300.0',NULL,NULL,'2018-07-17 21:59:39','2018-07-17 21:59:39','Length','Sample',NULL,NULL,NULL,NULL,NULL),(81,5,'',NULL,NULL,'2018-07-17 22:00:22','2018-07-17 22:00:22','Overhang Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(82,5,'',NULL,NULL,'2018-07-17 22:00:22','2018-07-17 22:00:22','Anneal Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(83,5,'50.0',NULL,NULL,'2018-07-17 22:00:22','2018-07-17 22:00:22','T Anneal','Sample',NULL,NULL,NULL,NULL,NULL),(84,6,'',NULL,NULL,'2018-07-17 22:00:42','2018-07-17 22:00:42','Overhang Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(85,6,'',NULL,NULL,'2018-07-17 22:00:42','2018-07-17 22:00:42','Anneal Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(86,6,'60.0',NULL,NULL,'2018-07-17 22:00:42','2018-07-17 22:00:42','T Anneal','Sample',NULL,NULL,NULL,NULL,NULL),(87,7,'https://www.neb.com/products/n3232-1-kb-dna-ladder',NULL,NULL,'2018-07-18 17:27:09','2018-07-18 17:27:09','Vendor Info','Sample',NULL,NULL,NULL,NULL,NULL),(88,8,'https://www.neb.com/products/n3231-100-bp-dna-ladder',NULL,NULL,'2018-07-18 17:27:57','2018-07-18 17:27:57','Vendor Info','Sample',NULL,NULL,NULL,NULL,NULL),(89,9,'http://www.lifetechnologies.com/order/catalog/product/10821015',NULL,NULL,'2018-07-18 17:29:35','2018-07-18 17:29:35','Vendor Info','Sample',NULL,NULL,NULL,NULL,NULL);
/*!40000 ALTER TABLE `field_values` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `groups`
--

DROP TABLE IF EXISTS `groups`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `groups` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=238 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `groups`
--

LOCK TABLES `groups` WRITE;
/*!40000 ALTER TABLE `groups` DISABLE KEYS */;
INSERT INTO `groups` VALUES (1,'admin','These users can use administrative functions (make users, etc)','2013-11-15 21:37:36','2013-11-15 21:37:36'),(235,'technicians','People who run jobs','2017-10-02 17:50:56','2017-10-02 17:50:56'),(237,'neptune','','2018-07-19 19:44:44','2018-07-19 19:44:44');
/*!40000 ALTER TABLE `groups` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `invoices`
--

DROP TABLE IF EXISTS `invoices`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `invoices` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `year` int(11) DEFAULT NULL,
  `month` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `status` varchar(255) DEFAULT NULL,
  `notes` text,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `invoices`
--

LOCK TABLES `invoices` WRITE;
/*!40000 ALTER TABLE `invoices` DISABLE KEYS */;
/*!40000 ALTER TABLE `invoices` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `items`
--

DROP TABLE IF EXISTS `items`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `items` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `location` varchar(255) DEFAULT NULL,
  `quantity` int(11) DEFAULT NULL,
  `object_type_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `inuse` int(11) DEFAULT '0',
  `sample_id` int(11) DEFAULT NULL,
  `data` mediumtext,
  `locator_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_items_on_object_type_id` (`object_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `items`
--

LOCK TABLES `items` WRITE;
/*!40000 ALTER TABLE `items` DISABLE KEYS */;
INSERT INTO `items` VALUES (1,'M20.0.0.0',1,1,'2018-07-17 22:01:33','2018-07-17 22:04:15',0,5,NULL,1),(2,'M20.0.0.1',1,1,'2018-07-17 22:04:34','2018-07-17 22:04:34',0,6,NULL,2),(3,'M20.0.0.2',1,3,'2018-07-17 22:04:46','2018-07-17 22:04:46',0,2,NULL,3),(4,'M20.0.0.3',1,3,'2018-07-17 22:04:52','2018-07-17 22:04:52',0,3,NULL,4),(5,'Reagent Shelf',1,27,'2018-07-18 23:17:05','2018-07-18 23:55:07',0,11,NULL,NULL),(6,'M20.0.0.5',1,28,'2018-07-18 23:17:13','2018-07-18 23:17:13',0,13,NULL,12),(7,'Reagent Shelf',1,22,'2018-07-18 23:17:27','2018-07-18 23:55:36',0,9,NULL,NULL),(8,'Reagent Shelf',1,22,'2018-07-18 23:17:30','2018-07-18 23:55:44',0,8,NULL,NULL),(9,'Reagent Shelf',1,25,'2018-07-18 23:18:47','2018-07-18 23:55:21',0,10,NULL,NULL),(10,'M20.0.0.7',1,23,'2018-07-18 23:33:54','2018-07-18 23:33:54',0,5,NULL,14),(11,'Reagent Shelf',1,31,'2018-07-18 23:49:52','2018-07-18 23:54:18',0,14,NULL,NULL);
/*!40000 ALTER TABLE `items` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `job_associations`
--

DROP TABLE IF EXISTS `job_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `job_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `job_associations`
--

LOCK TABLES `job_associations` WRITE;
/*!40000 ALTER TABLE `job_associations` DISABLE KEYS */;
INSERT INTO `job_associations` VALUES (1,2,95,'2018-07-19 18:53:46','2018-07-19 18:53:46'),(2,4,96,'2018-07-19 19:45:05','2018-07-19 19:45:05');
/*!40000 ALTER TABLE `job_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `jobs`
--

DROP TABLE IF EXISTS `jobs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `jobs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(255) DEFAULT NULL,
  `arguments` text,
  `state` longtext,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `path` varchar(255) DEFAULT NULL,
  `pc` int(11) DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `submitted_by` int(11) DEFAULT NULL,
  `desired_start_time` datetime DEFAULT NULL,
  `latest_start_time` datetime DEFAULT NULL,
  `metacol_id` int(11) DEFAULT NULL,
  `successor_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `jobs`
--

LOCK TABLES `jobs` WRITE;
/*!40000 ALTER TABLE `jobs` DISABLE KEYS */;
/*!40000 ALTER TABLE `jobs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `libraries`
--

DROP TABLE IF EXISTS `libraries`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `libraries` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `category` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `libraries`
--

LOCK TABLES `libraries` WRITE;
/*!40000 ALTER TABLE `libraries` DISABLE KEYS */;
INSERT INTO `libraries` VALUES (1,'GradientPCR','Cloning','2018-07-17 20:53:51','2018-07-17 20:54:43'),(2,'UploadHelper','Standard Libs','2018-07-17 21:10:43','2018-07-17 21:11:25'),(3,'Preconditions','Standard Libs','2018-07-17 21:11:35','2018-07-17 21:11:55'),(4,'StandardCloning','Cloning','2018-07-17 21:13:25','2018-07-17 21:13:46'),(5,'Centrifuge','Standard Libs','2018-07-18 23:24:00','2018-07-18 23:24:15');
/*!40000 ALTER TABLE `libraries` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `locators`
--

DROP TABLE IF EXISTS `locators`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `locators` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `wizard_id` int(11) DEFAULT NULL,
  `item_id` int(11) DEFAULT NULL,
  `number` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `locators`
--

LOCK TABLES `locators` WRITE;
/*!40000 ALTER TABLE `locators` DISABLE KEYS */;
INSERT INTO `locators` VALUES (1,1,1,0,'2018-07-17 22:04:15','2018-07-17 22:04:15'),(2,1,2,1,'2018-07-17 22:04:34','2018-07-17 22:04:34'),(3,1,3,2,'2018-07-17 22:04:46','2018-07-17 22:04:46'),(4,1,4,3,'2018-07-17 22:04:52','2018-07-17 22:04:52'),(11,1,34,4,'2018-07-18 22:58:06','2018-07-18 22:58:06'),(12,1,6,5,'2018-07-18 23:17:13','2018-07-18 23:17:13'),(13,1,12,6,'2018-07-18 23:31:33','2018-07-18 23:31:33'),(14,1,10,7,'2018-07-18 23:33:54','2018-07-18 23:33:54');
/*!40000 ALTER TABLE `locators` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `logs`
--

DROP TABLE IF EXISTS `logs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `logs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `user_id` varchar(255) DEFAULT NULL,
  `entry_type` varchar(255) DEFAULT NULL,
  `data` text,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `logs`
--

LOCK TABLES `logs` WRITE;
/*!40000 ALTER TABLE `logs` DISABLE KEYS */;
/*!40000 ALTER TABLE `logs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `memberships`
--

DROP TABLE IF EXISTS `memberships`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `memberships` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=545 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `memberships`
--

LOCK TABLES `memberships` WRITE;
/*!40000 ALTER TABLE `memberships` DISABLE KEYS */;
INSERT INTO `memberships` VALUES (541,1,1,'2017-10-02 16:21:25','2017-10-02 16:21:25'),(542,1,235,'2017-10-02 17:50:59','2017-10-02 17:50:59'),(544,1,237,'2018-07-19 19:44:50','2018-07-19 19:44:50');
/*!40000 ALTER TABLE `memberships` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `object_types`
--

DROP TABLE IF EXISTS `object_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `object_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `min` int(11) DEFAULT NULL,
  `max` int(11) DEFAULT NULL,
  `handler` varchar(255) DEFAULT NULL,
  `safety` text,
  `cleanup` text,
  `data` text,
  `vendor` text,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `unit` varchar(255) DEFAULT NULL,
  `cost` float DEFAULT NULL,
  `release_method` varchar(255) DEFAULT NULL,
  `release_description` text,
  `sample_type_id` int(11) DEFAULT NULL,
  `image` varchar(255) DEFAULT NULL,
  `prefix` varchar(255) DEFAULT NULL,
  `rows` int(11) DEFAULT NULL,
  `columns` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=34 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `object_types`
--

LOCK TABLES `object_types` WRITE;
/*!40000 ALTER TABLE `object_types` DISABLE KEYS */;
INSERT INTO `object_types` VALUES (1,'Primer Aliquot','Primers at low concentration for every day use',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:16','2018-07-17 20:45:50','Primer',0.01,'return','',1,'','M20',NULL,NULL),(2,'Plasmid Stock','A 1.5 mL tube containing purified plasmid DNA',0,1,'sample_container','No safety information','No cleanup information','concentration:','No vendor information','2018-07-17 20:29:16','2018-07-17 20:45:39','Plasmid',2,'return','',2,'','M20',NULL,NULL),(3,'Fragment Stock','Fragment stock in 1.5 mL tube, usually stored in M20 fridge.',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:16','2018-07-17 20:42:46','Fragment',50,'return','',3,'','M20',NULL,NULL),(4,'Unverified Plasmid Stock','A plasmid stock that has yet to be sequenced verified',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:16','2018-07-17 20:47:11','Plasmid',0.01,'return','',2,'','M20',NULL,NULL),(5,'1 ng/µL Plasmid Stock','Diluted stock for use as a template in PCR',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:16','2018-07-17 20:41:40','Plasmid',0.01,'query','If this is an aliquot for the \"Transformation Efficiency Project\", dispose of it. Otherwise, return it.',2,'','M20',NULL,NULL),(6,'1 ng/µL Fragment Stock','A diluted fragment stock to use as a PCR template',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:16','2018-07-17 20:41:25','Fragment',0.01,'return','',3,'','M20',NULL,NULL),(7,'Stripwell','Stripwell',0,10000,'collection','No safety information','No cleanup information','  {\r\n    \"materials\": 10.48,\r\n    \"labor\": 10\r\n  }','No vendor information','2018-07-17 20:29:16','2018-07-17 22:58:18','stripwell',1,'query','',NULL,'','',1,12),(8,'50 mL 0.8 Percent Agarose Gel in Gel Box','Used to run gels;',0,100,'collection','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:24','2018-07-17 22:57:20','box',0.01,'return','Return this item',NULL,'','',2,6),(9,'Gel Slice','Gel Slice cut from a gel lane after gel was run. Often placed in a 1.5 mL tube.',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:37','2018-07-17 20:43:49','Fragment',10,'dispose','',3,'','M20',NULL,NULL),(10,'Gibson Reaction Result','A plasmid that was made from Gibson reaction and stayed in the Gibson reaction tube. One can use this to do transform and extract the plasmid.',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:29:57','2018-07-17 20:44:01','Plasmid',10,'return','',2,'','M20',NULL,NULL),(11,'Ligation product','A low concentration, possibly multi-species, product of a ligation reaction. Suitable for transformation or use as a PCR template. ',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:08','2018-07-17 20:44:31','Plasmid stock',0.01,'return','',2,'','M20',NULL,NULL),(12,'Transformed E. coli Aliquot','An aliquot containing transformed E. coli - usually in a 1.5 mL tube',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:08','2018-07-17 20:46:52','Plasmid',0.01,'dispose','',2,'','',NULL,NULL),(13,'E. coli Comp Cell Batch','E. coli Comp Cell Batch',0,100,'collection','No safety information','No cleanup information','{ \"samples\": [ \r\n    {\"name\": \"DH5alpha\", \"materials\": 0.58, \"labor\": 2.39, \"unit\": \"cell\" }\r\n] }','No vendor information','2018-07-17 20:30:08','2018-07-17 22:57:49','batch',0.01,'return','',NULL,'','',10,10),(14,'E coli Plate of Plasmid','A plate containing E. coli transformed with a plasmid',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:21','2018-07-17 20:42:34','Plasmid',0.01,'return','',2,'','DFP',NULL,NULL),(15,'Checked E coli Plate of Plasmid','It\'s a checked plate',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:28','2018-07-17 20:42:00','plate',0.01,'return','',2,'','',NULL,NULL),(16,'Plasmid Glycerol Stock','Glycerol Stock of E. coli (usually DH5alpha) containing plasmid DNA stock',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:41','2018-07-17 20:45:30','Plasmid',5,'return','',2,'','M80',NULL,NULL),(17,'TB Overnight of Plasmid','An overnight of E. coli transformed with a plasmid in TB + antibiotic',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:30:41','2018-07-17 20:46:17','Plasmid',0.01,'return','',2,'','DFO',NULL,NULL),(18,'Sequencing Stripwell','Sequencing stripwell',0,100000,'collection','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:31:01','2018-07-17 22:58:10','stripwell',0.01,'query','',NULL,'','',1,12),(19,'Lyophilized Fragment','Lyophilized fragment, as in a IDT gBlock',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-17 20:31:36','2018-07-17 20:45:07','Fragment',0.01,'return','',3,'','',NULL,NULL),(20,'Lyophilized Primer','Some barely visible white powder',1,10000,'sample_container','','','','','2018-07-17 20:31:41','2018-07-17 20:45:19','tube',5,'return','',1,'','',NULL,NULL),(21,'Gibson Aliquot Batch','A batch of Gibson aliquots',0,10000,'collection','No safety information','No cleanup information','No data','No vendor information','2018-07-17 23:01:33','2018-07-18 22:37:49','batch',228,'return','',NULL,'','',10,10),(22,'Ladder Aliquot','Diluted ladder mixed with loading dye, for direct use with gels.',0,100,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 17:25:09','2018-07-18 17:25:09','Ladder',0.01,'return','',6,'','SF2',NULL,NULL),(23,'Primer Stock','rehydrated primer in tube',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 17:32:34','2018-07-18 17:32:34','Primer',0.01,'return','',1,'','M20',NULL,NULL),(25,'800 mL Agar','800 mL Agar',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 22:24:59','2018-07-18 23:18:09','Media',0.01,'return','',7,'','',NULL,NULL),(26,'Agar Plate Batch',' A new agar plate batch. ',0,100,'collection','No safety information','No cleanup information','  {\r\n    \"samples\": [\r\n      { \"name\": \"LB + Amp\", \"materials\": 0.70, \"labor\": 0.16 },\r\n      { \"name\": \"LB + Kan\", \"materials\": 0.70, \"labor\": 0.16 },\r\n      { \"name\": \"LB\", \"materials\": 0.31, \"labor\": 0.16 },\r\n      { \"name\": \"SDO -His\", \"materials\": 0.80, \"labor\": 0.22 },\r\n      { \"name\": \"SDO -Leu\", \"materials\": 0.80, \"labor\": 0.22  },\r\n      { \"name\": \"SDO -Trp\", \"materials\": 0.80, \"labor\": 0.22  },\r\n      { \"name\": \"SDO -Ura\", \"materials\": 0.80, \"labor\": 0.22 },\r\n      { \"name\": \"YPAD\", \"materials\": 0.48, \"labor\": 0.22  },\r\n      { \"name\": \"Spec\", \"materials\": 0.70, \"labor\": 0.16 },\r\n      { \"name\": \"Chlor\", \"materials\": 0.70, \"labor\": 0.16 },\r\n      { \"name\": \"5-FOA\", \"materials\": 2.02, \"labor\": 1.31 }\r\n    ]\r\n  }','No vendor information','2018-07-18 22:24:59','2018-07-18 22:24:59','batches',0.01,'return','',NULL,NULL,'MBF',NULL,NULL),(27,'Screw Cap Tube','1.5 mL Screw Cap Tube',0,100,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 22:48:30','2018-07-18 22:48:30','Reagents',0.01,'return','',8,'','',NULL,NULL),(28,'Enzyme Stock','Enzyme stocks in their original containers from the vendor',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 22:54:29','2018-07-18 22:54:29','Enzyme',0.01,'return','',9,'','M20',NULL,NULL),(29,'Agar plate','Plated cells on an agar plate',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 23:22:06','2018-07-18 23:48:47','E coli strain',3,'return','',4,'','',NULL,NULL),(30,'Overnight suspension','A liquid culture of bacteria for immediate use',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 23:22:06','2018-07-18 23:22:06','E coli strain',2,'return','',NULL,NULL,NULL,NULL,NULL),(31,'800 mL Liquid','800 mL Bottle',0,10000,'sample_container','No safety information','No cleanup information',' {\r\n    \"samples\": [\r\n      { \"name\": \"SC\",   \"materials\": 9.64, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"SDO\",  \"materials\": 8.75, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"50% Glycerol\",   \"materials\": 8.97, \"labor\": 2.62, \"delete\": true },\r\n      { \"name\": \"TB\",   \"materials\": 5.99, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"TB + Amp\",   \"materials\": 18.71, \"labor\": 5.25, \"delete\": true },\r\n      { \"name\": \"LB\",   \"materials\": 2.28, \"labor\": 1.75, \"delete\": true },     \r\n      { \"name\": \"YPAD\", \"materials\": 4.48, \"labor\": 3.50, \"delete\": true }\r\n    ]\r\n  }','No vendor information','2018-07-18 23:22:06','2018-07-18 23:49:42','Media',0.01,'return','',7,'','',NULL,NULL),(32,'500 mL Liquid','500 mL Liquid',0,1,'sample_container','No safety information','No cleanup information','  {\r\n    \"samples\": [\r\n      { \"name\": \"Histidine Solution\",   \"materials\": 13.85, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"Leucine Solution\",  \"materials\": 13.06, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"Tryptophan Solution\",   \"materials\": 16.67, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"Uracil Solution\",   \"materials\": 11.79, \"labor\": 3.50, \"delete\": true },\r\n      { \"name\": \"10% Glycerol\", \"materials\": 0.20, \"labor\": 3.50, \"delete\": true }\r\n    ]\r\n  }','No vendor information','2018-07-18 23:23:13','2018-07-18 23:48:19','Media',0.01,'return','',7,'','',NULL,NULL),(33,'1 L Liquid','1 L Liquid',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-07-18 23:23:13','2018-07-18 23:23:13','Media',0.01,'return','',NULL,NULL,'',NULL,NULL);
/*!40000 ALTER TABLE `object_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `operation_types`
--

DROP TABLE IF EXISTS `operation_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `operation_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `category` varchar(255) DEFAULT NULL,
  `deployed` tinyint(1) DEFAULT NULL,
  `on_the_fly` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_operation_types_on_category_and_name` (`category`,`name`)
) ENGINE=InnoDB AUTO_INCREMENT=26 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `operation_types`
--

LOCK TABLES `operation_types` WRITE;
/*!40000 ALTER TABLE `operation_types` DISABLE KEYS */;
INSERT INTO `operation_types` VALUES (1,'Make PCR Fragment','Cloning',1,0,'2018-07-17 20:29:16','2018-07-17 20:48:18'),(2,'Pour Gel','Cloning',1,1,'2018-07-17 20:29:24','2018-07-17 20:48:24'),(3,'Run Gel','Cloning',1,0,'2018-07-17 20:29:32','2018-07-17 20:48:28'),(4,'Extract Gel Slice','Cloning',1,0,'2018-07-17 20:29:38','2018-07-17 20:48:32'),(5,'Purify Gel Slice','Cloning',1,0,'2018-07-17 20:29:44','2018-07-17 20:48:36'),(6,'Assemble Plasmid','Cloning',1,0,'2018-07-17 20:29:57','2018-07-17 20:48:40'),(7,'Transform Cells','Cloning',1,0,'2018-07-17 20:30:08','2018-07-17 20:48:44'),(8,'Plate Transformed Cells','Cloning',1,0,'2018-07-17 20:30:21','2018-07-17 20:48:48'),(9,'Check Plate','Cloning',1,0,'2018-07-17 20:30:28','2018-07-17 20:48:52'),(10,'Make Overnight Suspension','Cloning',1,0,'2018-07-17 20:30:41','2018-07-17 20:48:55'),(11,'Make Miniprep','Cloning',1,0,'2018-07-17 20:30:50','2018-07-17 20:48:59'),(12,'Send to Sequencing','Cloning',1,0,'2018-07-17 20:31:01','2018-07-17 20:49:02'),(13,'Upload Sequencing Results','Cloning',1,0,'2018-07-17 20:31:08','2018-07-17 20:49:07'),(14,'Clean Up Sequencing','Cloning',1,0,'2018-07-17 20:31:17','2018-07-17 20:49:10'),(15,'Make Glycerol Stock','Cloning',1,0,'2018-07-17 20:31:24','2018-07-17 20:49:14'),(16,'Order gBlock','Cloning',1,0,'2018-07-17 20:31:36','2018-07-17 20:49:18'),(17,'Order Primer','Cloning',1,0,'2018-07-17 20:31:41','2018-07-17 20:49:23'),(19,'Make Collection','Manager',1,0,'2018-07-18 17:53:29','2018-07-18 17:53:44'),(20,'Pour Plates','Manager',1,0,'2018-07-18 22:24:59','2018-07-18 22:25:26'),(21,'Direct Purchase','Manager',1,0,'2018-07-18 22:39:59','2018-07-18 23:25:28'),(22,'Overnight for Comp Cell Batch','Manager',1,0,'2018-07-18 23:22:06','2018-07-18 23:23:34'),(23,'Media for Ecoli Comp Cell Batch','Manager',1,0,'2018-07-18 23:23:13','2018-07-18 23:23:38'),(24,'Produce E. coli Comp Cell Batch','Manager',1,0,'2018-07-18 23:23:21','2018-07-18 23:23:42'),(25,'Edit Collection','Manager',1,0,'2018-07-19 16:42:11','2018-07-19 16:42:19');
/*!40000 ALTER TABLE `operation_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `operations`
--

DROP TABLE IF EXISTS `operations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `operations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `operation_type_id` int(11) DEFAULT NULL,
  `status` varchar(255) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `x` float DEFAULT NULL,
  `y` float DEFAULT NULL,
  `parent_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_operations_on_operation_type_id` (`operation_type_id`),
  KEY `index_operations_on_user_id` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `operations`
--

LOCK TABLES `operations` WRITE;
/*!40000 ALTER TABLE `operations` DISABLE KEYS */;
/*!40000 ALTER TABLE `operations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `parameters`
--

DROP TABLE IF EXISTS `parameters`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `parameters` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `key` varchar(255) DEFAULT NULL,
  `value` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=20 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `parameters`
--

LOCK TABLES `parameters` WRITE;
/*!40000 ALTER TABLE `parameters` DISABLE KEYS */;
INSERT INTO `parameters` VALUES (1,'email','joe@nasa.gov','2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(2,'phone','8675309','2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(3,'biofab',NULL,'2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(4,'aquarium',NULL,'2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(5,'Make new samples private',NULL,'2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(6,'Lab Name',NULL,'2018-07-17 20:15:40','2018-07-17 20:15:40',NULL,1),(7,'email','joe@nasa.gov','2018-07-17 20:15:46','2018-07-17 20:15:46',NULL,1),(8,'phone','8675309','2018-07-17 20:15:46','2018-07-17 20:15:46',NULL,1),(9,'biofab','true','2018-07-17 20:15:46','2018-07-17 20:15:46',NULL,1),(10,'aquarium','true','2018-07-17 20:15:46','2018-07-17 20:15:48',NULL,1),(11,'Make new samples private',NULL,'2018-07-17 20:15:46','2018-07-17 20:15:46',NULL,1),(12,'Lab Name',NULL,'2018-07-17 20:15:46','2018-07-17 20:15:46',NULL,1),(13,'Genewiz User','N/A','2018-07-17 21:33:24','2018-07-17 21:33:24','',NULL),(14,'Genewiz Password','N/A','2018-07-17 21:33:39','2018-07-17 21:33:39','',NULL),(15,'IDT User','N/A','2018-07-17 21:33:48','2018-07-17 21:33:48','',NULL),(17,'IDT Password','N/A','2018-07-17 21:34:06','2018-07-17 21:34:06','',NULL),(18,'URL','www.aquarium.url','2018-07-18 23:29:39','2018-07-18 23:30:08','',NULL),(19,'markup rate','0.0','2018-07-19 18:53:56','2018-07-19 18:53:56','Edit me',NULL);
/*!40000 ALTER TABLE `parameters` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `parts`
--

DROP TABLE IF EXISTS `parts`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `parts` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `collection_id` int(11) DEFAULT NULL,
  `item_id` int(11) DEFAULT NULL,
  `row` int(11) DEFAULT NULL,
  `column` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `parts`
--

LOCK TABLES `parts` WRITE;
/*!40000 ALTER TABLE `parts` DISABLE KEYS */;
/*!40000 ALTER TABLE `parts` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `plan_associations`
--

DROP TABLE IF EXISTS `plan_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `plan_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `plan_id` int(11) DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_plan_associations_on_plan_id` (`plan_id`),
  KEY `index_plan_associations_on_operation_id` (`operation_id`)
) ENGINE=InnoDB AUTO_INCREMENT=68 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `plan_associations`
--

LOCK TABLES `plan_associations` WRITE;
/*!40000 ALTER TABLE `plan_associations` DISABLE KEYS */;
INSERT INTO `plan_associations` VALUES (1,1,2,'2018-07-17 21:39:52','2018-07-17 21:39:52'),(2,1,3,'2018-07-17 21:39:52','2018-07-17 21:39:52'),(3,1,4,'2018-07-17 21:39:52','2018-07-17 21:39:52'),(4,1,5,'2018-07-17 21:39:52','2018-07-17 21:39:52'),(5,2,6,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(6,2,7,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(7,2,8,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(8,2,9,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(9,3,10,'2018-07-17 21:41:56','2018-07-17 21:41:56'),(10,3,11,'2018-07-17 21:41:56','2018-07-17 21:41:56'),(11,4,12,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(12,4,13,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(13,4,14,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(14,4,15,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(15,4,16,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(16,4,17,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(17,4,18,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(18,4,19,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(19,4,20,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(20,4,21,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(21,4,22,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(22,5,23,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(23,5,24,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(24,5,25,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(25,5,26,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(26,5,27,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(27,5,28,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(28,6,29,'2018-07-18 23:24:57','2018-07-18 23:24:57'),(29,7,30,'2018-07-18 23:25:18','2018-07-18 23:25:18'),(53,31,75,'2018-07-18 23:45:38','2018-07-18 23:45:38'),(63,41,92,'2018-07-18 23:57:17','2018-07-18 23:57:17'),(64,42,93,'2018-07-19 18:39:01','2018-07-19 18:39:01'),(65,43,94,'2018-07-19 18:44:39','2018-07-19 18:44:39'),(66,44,95,'2018-07-19 18:53:46','2018-07-19 18:53:46'),(67,45,96,'2018-07-19 19:45:05','2018-07-19 19:45:05');
/*!40000 ALTER TABLE `plan_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `plans`
--

DROP TABLE IF EXISTS `plans`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `plans` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `status` varchar(255) DEFAULT NULL,
  `cost_limit` float DEFAULT NULL,
  `folder` varchar(255) DEFAULT NULL,
  `layout` text,
  PRIMARY KEY (`id`),
  KEY `index_plans_on_user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `plans`
--

LOCK TABLES `plans` WRITE;
/*!40000 ALTER TABLE `plans` DISABLE KEYS */;
INSERT INTO `plans` VALUES (2,1,'2018-07-17 21:40:02','2018-07-17 21:43:10',NULL,'Transform and Grow','system_template',NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":[{\"id\":1,\"parent_id\":0,\"name\":\"Transform and Grow\",\"x\":160,\"y\":112,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":1,\"x\":272,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":2,\"x\":336,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":[{\"id\":0,\"x\":304,\"y\":96,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"documentation\":\"This module transforms a Plasmid onto a competent cell strain of your choice. This module will then produce an Overnight Suspension of the Transformed Cells.\",\"children\":null,\"wires\":[{\"to_module\":{\"id\":1},\"from_op\":{\"id\":9},\"from\":{\"record_type\":\"FieldValue\",\"id\":18},\"to\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":1},\"to_op\":{\"id\":6},\"to\":{\"record_type\":\"FieldValue\",\"id\":10},\"from\":{\"record_type\":\"ModuleIO\",\"id\":1}},{\"from_module\":{\"id\":1},\"to_op\":{\"id\":6},\"to\":{\"record_type\":\"FieldValue\",\"id\":12},\"from\":{\"record_type\":\"ModuleIO\",\"id\":2}}],\"text_boxes\":null}],\"wires\":null,\"text_boxes\":null}'),(3,1,'2018-07-17 21:41:56','2018-07-17 21:42:46',NULL,'Sequence DNA','system_template',NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":[{\"id\":1,\"parent_id\":0,\"name\":\"Sequence DNA\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":0,\"x\":240,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":1,\"x\":304,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":null,\"documentation\":\"This module takes in a Plasmid Stock to be sequenced, and an Aliquot of Primer that will be used to sequence it.\\n\\nAfter this module has completed, the sequencing results for this Plasmid/Primer will be associated with: your plan, the plasmid stock, the overnight used to produce the stock, and all other progeny items of that overnight.\",\"children\":null,\"wires\":[{\"from_module\":{\"id\":1},\"to_op\":{\"id\":10},\"to\":{\"record_type\":\"FieldValue\",\"id\":19},\"from\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":1},\"to_op\":{\"id\":10},\"to\":{\"record_type\":\"FieldValue\",\"id\":20},\"from\":{\"record_type\":\"ModuleIO\",\"id\":1}}],\"text_boxes\":null}],\"wires\":null,\"text_boxes\":null}'),(4,1,'2018-07-17 21:50:01','2018-07-17 21:51:53',NULL,'Make Glycerol Stock from Assembled Plasmid with QC','system_template',NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":[{\"id\":2,\"parent_id\":0,\"name\":\"Transform and Grow\",\"x\":240,\"y\":320,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":0,\"x\":272,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":1,\"x\":336,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":[{\"id\":2,\"x\":304,\"y\":96,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"documentation\":\"This module transforms a Plasmid onto a competent cell strain of your choice. This module will then produce an Overnight Suspension of the Transformed Cells.\",\"children\":null,\"wires\":[{\"to_module\":{\"id\":2},\"from_op\":{\"id\":15},\"from\":{\"record_type\":\"FieldValue\",\"id\":32},\"to\":{\"record_type\":\"ModuleIO\",\"id\":2}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":12},\"to\":{\"record_type\":\"FieldValue\",\"id\":24},\"from\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":12},\"to\":{\"record_type\":\"FieldValue\",\"id\":26},\"from\":{\"record_type\":\"ModuleIO\",\"id\":1}}],\"text_boxes\":null},{\"id\":4,\"parent_id\":0,\"name\":\"Sequence DNA\",\"x\":448,\"y\":320,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":3,\"x\":240,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":4,\"x\":304,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":null,\"documentation\":\"This module takes in a Plasmid Stock to be sequenced, and an Aliquot of Primer that will be used to sequence it.\\n\\nAfter this module has completed, the sequencing results for this Plasmid/Primer will be associated with: your plan, the plasmid stock, the overnight used to produce the stock, and all other progeny items of that overnight.\",\"children\":null,\"wires\":[{\"from_module\":{\"id\":4},\"to_op\":{\"id\":19},\"to\":{\"record_type\":\"FieldValue\",\"id\":40},\"from\":{\"record_type\":\"ModuleIO\",\"id\":3}},{\"from_module\":{\"id\":4},\"to_op\":{\"id\":19},\"to\":{\"record_type\":\"FieldValue\",\"id\":41},\"from\":{\"record_type\":\"ModuleIO\",\"id\":4}}],\"text_boxes\":null},{\"id\":6,\"parent_id\":0,\"name\":\"Sequence DNA\",\"x\":640,\"y\":320,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":5,\"x\":240,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":6,\"x\":304,\"y\":320,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":null,\"documentation\":\"This module takes in a Plasmid Stock to be sequenced, and an Aliquot of Primer that will be used to sequence it.\\n\\nAfter this module has completed, the sequencing results for this Plasmid/Primer will be associated with: your plan, the plasmid stock, the overnight used to produce the stock, and all other progeny items of that overnight.\",\"children\":null,\"wires\":[{\"from_module\":{\"id\":6},\"to_op\":{\"id\":21},\"to\":{\"record_type\":\"FieldValue\",\"id\":44},\"from\":{\"record_type\":\"ModuleIO\",\"id\":5}},{\"from_module\":{\"id\":6},\"to_op\":{\"id\":21},\"to\":{\"record_type\":\"FieldValue\",\"id\":45},\"from\":{\"record_type\":\"ModuleIO\",\"id\":6}}],\"text_boxes\":null}],\"wires\":[{\"to_module\":{\"id\":2},\"from_op\":{\"id\":16},\"from\":{\"record_type\":\"FieldValue\",\"id\":34},\"to\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":17},\"to\":{\"record_type\":\"FieldValue\",\"id\":35},\"from\":{\"record_type\":\"ModuleIO\",\"id\":2}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":18},\"to\":{\"record_type\":\"FieldValue\",\"id\":38},\"from\":{\"record_type\":\"ModuleIO\",\"id\":2}},{\"to_module\":{\"id\":4},\"from_op\":{\"id\":18},\"from\":{\"record_type\":\"FieldValue\",\"id\":39},\"to\":{\"record_type\":\"ModuleIO\",\"id\":3}},{\"to_module\":{\"id\":6},\"from_op\":{\"id\":18},\"from\":{\"record_type\":\"FieldValue\",\"id\":39},\"to\":{\"record_type\":\"ModuleIO\",\"id\":5}}],\"text_boxes\":null}'),(5,1,'2018-07-17 21:52:41','2018-07-17 21:52:52',NULL,'Make Glycerol Stock from Assembled Plasmid','system_template',NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":[{\"id\":2,\"parent_id\":0,\"name\":\"Transform and Grow\",\"x\":240,\"y\":320,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":[{\"id\":0,\"x\":272,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}},{\"id\":1,\"x\":336,\"y\":416,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"output\":[{\"id\":2,\"x\":304,\"y\":96,\"width\":32,\"height\":32,\"model\":{\"model\":\"ModuleIO\"}}],\"documentation\":\"This module transforms a Plasmid onto a competent cell strain of your choice. This module will then produce an Overnight Suspension of the Transformed Cells.\",\"children\":null,\"wires\":[{\"to_module\":{\"id\":2},\"from_op\":{\"id\":26},\"from\":{\"record_type\":\"FieldValue\",\"id\":56},\"to\":{\"record_type\":\"ModuleIO\",\"id\":2}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":23},\"to\":{\"record_type\":\"FieldValue\",\"id\":48},\"from\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":23},\"to\":{\"record_type\":\"FieldValue\",\"id\":50},\"from\":{\"record_type\":\"ModuleIO\",\"id\":1}}],\"text_boxes\":null}],\"wires\":[{\"to_module\":{\"id\":2},\"from_op\":{\"id\":27},\"from\":{\"record_type\":\"FieldValue\",\"id\":58},\"to\":{\"record_type\":\"ModuleIO\",\"id\":0}},{\"from_module\":{\"id\":2},\"to_op\":{\"id\":28},\"to\":{\"record_type\":\"FieldValue\",\"id\":59},\"from\":{\"record_type\":\"ModuleIO\",\"id\":2}}],\"text_boxes\":null}');
/*!40000 ALTER TABLE `plans` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `sample_types`
--

DROP TABLE IF EXISTS `sample_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `sample_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `sample_types`
--

LOCK TABLES `sample_types` WRITE;
/*!40000 ALTER TABLE `sample_types` DISABLE KEYS */;
INSERT INTO `sample_types` VALUES (1,'Primer','A short double stranded piece of DNA for PCR and sequencing','2018-07-17 20:29:15','2018-07-17 20:29:15'),(2,'Plasmid','A circular piece of double stranded DNA','2018-07-17 20:29:15','2018-07-17 20:29:15'),(3,'Fragment','A linear double stranded piece of DNA from PCR or Restriction Digest','2018-07-17 20:29:15','2018-07-17 20:29:15'),(4,'E coli strain','A strain of E coli distinguished from others by genomic (not plasmid) modifications.','2018-07-17 20:29:15','2018-07-17 20:29:15'),(5,'Yeast Strain','A strain of yeast distinguished from others by genomic or plasmid modifications','2018-07-17 20:29:15','2018-07-17 20:29:15'),(6,'Ladder','DNA Ladder for Gel Electrophoresis','2018-07-18 17:23:51','2018-07-18 17:23:51'),(7,'Media','Media for yeast and E. coli','2018-07-18 17:33:24','2018-07-18 17:33:24'),(8,'Reagents','Additional misc. ingredients needed for lab work','2018-07-18 22:47:26','2018-07-18 22:47:26'),(9,'Enzyme','Enzymes shipped in from external vendors','2018-07-18 22:52:08','2018-07-18 22:52:08');
/*!40000 ALTER TABLE `sample_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `samples`
--

DROP TABLE IF EXISTS `samples`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `samples` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `sample_type_id` int(11) DEFAULT NULL,
  `project` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `user_id` int(11) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `data` text,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `samples`
--

LOCK TABLES `samples` WRITE;
/*!40000 ALTER TABLE `samples` DISABLE KEYS */;
INSERT INTO `samples` VALUES (1,'DH5alpha',4,'N/A','2018-07-17 21:46:31','2018-07-17 21:46:31',1,'General use Strain for transformation plasmid extraction',NULL),(2,'First Fragment',3,'First Project','2018-07-17 21:58:07','2018-07-17 21:58:07',1,'This Sample is for testing and does not represent real inventory',NULL),(3,'Second Fragment',3,'First Project','2018-07-17 21:58:37','2018-07-17 21:58:37',1,'This Sample is for testing and does not represent real inventory',NULL),(4,'First Plasmid',2,'First Project','2018-07-17 21:59:39','2018-07-17 21:59:39',1,'This Sample is for testing and does not represent real inventory.',NULL),(5,'First Primer',1,'First Project','2018-07-17 22:00:22','2018-07-17 22:00:22',1,'This Sample is for testing and does not represent real inventory',NULL),(6,'Second Primer',1,'First Project','2018-07-17 22:00:42','2018-07-17 22:00:42',1,'This Sample is for testing and does not represent real inventory',NULL),(7,'1 kb Ladder',6,'N/A','2018-07-18 17:27:09','2018-07-18 17:27:09',1,'Ladder used for most gels.',NULL),(8,'100 bp Ladder',6,'N/A','2018-07-18 17:27:57','2018-07-18 17:27:57',1,'Medium sized DNA Ladder.',NULL),(9,'10 bp Ladder',6,'N/A','2018-07-18 17:29:35','2018-07-18 17:29:35',1,'Short DNA Ladder.',NULL),(10,'LB + Amp',7,'N/A','2018-07-18 17:56:15','2018-07-18 23:18:24',1,'LB with Ampicillin','{\"note\":\"\"}'),(11,'6X Loading Dye',8,'N/A','2018-07-18 22:49:48','2018-07-18 22:49:48',1,'6X Loading Dye used for running gels',NULL),(12,'Gibson Aliquot',8,'N/A','2018-07-18 22:50:34','2018-07-18 22:50:34',1,'A small mix of enzymes necessary for a Gibson',NULL),(13,'Kapa HF Master Mix',9,'N/A','2018-07-18 22:55:19','2018-07-18 22:55:19',1,'Kapa Master Mix with HF Buffer',NULL),(14,'LB',7,'N/A','2018-07-18 23:46:41','2018-07-18 23:46:41',1,'LB media',NULL);
/*!40000 ALTER TABLE `samples` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `schema_migrations`
--

DROP TABLE IF EXISTS `schema_migrations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `schema_migrations` (
  `version` varchar(255) NOT NULL,
  UNIQUE KEY `unique_schema_migrations` (`version`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `schema_migrations`
--

LOCK TABLES `schema_migrations` WRITE;
/*!40000 ALTER TABLE `schema_migrations` DISABLE KEYS */;
INSERT INTO `schema_migrations` VALUES ('20131029153603'),('20131029153634');
/*!40000 ALTER TABLE `schema_migrations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `timings`
--

DROP TABLE IF EXISTS `timings`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `timings` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) DEFAULT NULL,
  `days` varchar(255) DEFAULT NULL,
  `start` int(11) DEFAULT NULL,
  `stop` int(11) DEFAULT NULL,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `timings`
--

LOCK TABLES `timings` WRITE;
/*!40000 ALTER TABLE `timings` DISABLE KEYS */;
INSERT INTO `timings` VALUES (1,1,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',870,930,1,'2018-07-17 20:29:16','2018-07-17 20:29:16'),(2,2,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',480,510,1,'2018-07-17 20:29:24','2018-07-17 20:29:24'),(3,3,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',510,540,1,'2018-07-17 20:29:32','2018-07-17 20:29:32'),(4,4,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',570,630,1,'2018-07-17 20:29:38','2018-07-17 20:29:38'),(5,5,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',600,720,1,'2018-07-17 20:29:45','2018-07-17 20:29:45'),(6,6,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',690,750,1,'2018-07-17 20:29:57','2018-07-17 20:29:57'),(7,7,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',750,840,1,'2018-07-17 20:30:08','2018-07-17 20:30:08'),(8,8,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',780,900,1,'2018-07-17 20:30:21','2018-07-17 20:30:21'),(9,9,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',480,510,1,'2018-07-17 20:30:28','2018-07-17 20:30:28'),(10,10,'OperationType','[\"Su\",\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',900,1050,1,'2018-07-17 20:30:42','2018-07-17 20:30:42'),(11,11,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\",\"Sa\"]',480,540,1,'2018-07-17 20:30:50','2018-07-17 20:30:50'),(12,12,'OperationType','[\"Su\",\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',540,660,1,'2018-07-17 20:31:01','2018-07-17 20:31:01'),(13,13,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\",\"Sa\"]',480,510,1,'2018-07-17 20:31:08','2018-07-17 20:31:08'),(14,17,'OperationType','[\"Mo\",\"Tu\",\"We\",\"Th\",\"Fr\"]',960,990,1,'2018-07-17 20:31:41','2018-07-17 20:31:41');
/*!40000 ALTER TABLE `timings` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `uploads`
--

DROP TABLE IF EXISTS `uploads`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `uploads` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `upload_file_name` varchar(255) DEFAULT NULL,
  `upload_content_type` varchar(255) DEFAULT NULL,
  `upload_file_size` int(11) DEFAULT NULL,
  `upload_updated_at` datetime DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `uploads`
--

LOCK TABLES `uploads` WRITE;
/*!40000 ALTER TABLE `uploads` DISABLE KEYS */;
/*!40000 ALTER TABLE `uploads` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `user_budget_associations`
--

DROP TABLE IF EXISTS `user_budget_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `user_budget_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `quota` float DEFAULT NULL,
  `disabled` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `user_budget_associations`
--

LOCK TABLES `user_budget_associations` WRITE;
/*!40000 ALTER TABLE `user_budget_associations` DISABLE KEYS */;
INSERT INTO `user_budget_associations` VALUES (1,1,1,1000,0,'2018-07-17 22:10:10','2018-07-17 22:10:10');
/*!40000 ALTER TABLE `user_budget_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `login` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `password_digest` varchar(255) DEFAULT NULL,
  `remember_token` varchar(255) DEFAULT NULL,
  `admin` tinyint(1) DEFAULT '0',
  `key` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_users_on_login` (`login`),
  KEY `index_users_on_remember_token` (`remember_token`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES (1,'Joe Neptune','neptune','2013-06-16 17:26:54','2017-10-19 04:59:18','$2a$10$HxgxLX5/ITcYpII1InAL1.jUYAiHk/rMftHniPJVvauy43VDoo8yW','TYmoWfyV42AL7dSoYcgmug',1,'VHzz9IW3xnNx8O3cA_P0rKsUWmTVH_Qz9mHKqgE-hNI');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `wires`
--

DROP TABLE IF EXISTS `wires`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `wires` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `from_id` int(11) DEFAULT NULL,
  `to_id` int(11) DEFAULT NULL,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `wires`
--

LOCK TABLES `wires` WRITE;
/*!40000 ALTER TABLE `wires` DISABLE KEYS */;
INSERT INTO `wires` VALUES (4,11,13,1,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(5,14,15,1,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(6,16,17,1,'2018-07-17 21:40:02','2018-07-17 21:40:02'),(7,21,22,1,'2018-07-17 21:41:56','2018-07-17 21:41:56'),(8,25,27,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(9,28,29,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(10,30,31,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(11,34,24,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(12,32,38,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(13,32,35,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(14,42,43,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(15,46,47,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(16,39,40,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(17,39,44,1,'2018-07-17 21:50:01','2018-07-17 21:50:01'),(18,49,51,1,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(19,52,53,1,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(20,54,55,1,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(21,58,48,1,'2018-07-17 21:52:41','2018-07-17 21:52:41'),(22,56,59,1,'2018-07-17 21:52:41','2018-07-17 21:52:41');
/*!40000 ALTER TABLE `wires` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `wizards`
--

DROP TABLE IF EXISTS `wizards`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `wizards` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `specification` varchar(255) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `wizards`
--

LOCK TABLES `wizards` WRITE;
/*!40000 ALTER TABLE `wizards` DISABLE KEYS */;
INSERT INTO `wizards` VALUES (1,'M20','{\"fields\":{\"0\":{\"name\":\"Hotel\",\"capacity\":\"-1\"},\"1\":{\"name\":\"Box\",\"capacity\":\"16\"},\"2\":{\"name\":\"Slot\",\"capacity\":\"81\"}}}','2018-07-17 22:03:22','2018-07-17 22:03:22','The -20C Freezer'),(2,'M80','{\"fields\":{\"0\":{\"name\":\"Hotel\",\"capacity\":\"-1\"},\"1\":{\"name\":\"Box\",\"capacity\":\"16\"},\"2\":{\"name\":\"Slot\",\"capacity\":\"81\"}}}','2018-07-17 22:03:55','2018-07-17 22:03:55','The -80C Freezer');
/*!40000 ALTER TABLE `wizards` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2018-07-19 20:00:08
